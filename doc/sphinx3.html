<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Sphinx 3 manual</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style>
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; } /* Alert */
code span.an { color: #008000; } /* Annotation */
code span.at { } /* Attribute */
code span.bu { } /* BuiltIn */
code span.cf { color: #0000ff; } /* ControlFlow */
code span.ch { color: #008080; } /* Char */
code span.cn { } /* Constant */
code span.co { color: #008000; } /* Comment */
code span.cv { color: #008000; } /* CommentVar */
code span.do { color: #008000; } /* Documentation */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.im { } /* Import */
code span.in { color: #008000; } /* Information */
code span.kw { color: #0000ff; } /* Keyword */
code span.op { } /* Operator */
code span.ot { color: #ff4000; } /* Other */
code span.pp { color: #ff4000; } /* Preprocessor */
code span.sc { color: #008080; } /* SpecialChar */
code span.ss { color: #008080; } /* SpecialString */
code span.st { color: #008080; } /* String */
code span.va { } /* Variable */
code span.vs { color: #008080; } /* VerbatimString */
code span.wa { color: #008000; font-weight: bold; } /* Warning */
  </style>
  <style type="text/css">
  
  /* based on https://gist.github.com/dashed/6714393 */
  /*! normalize.css v2.1.3 | MIT License | git.io/normalize */
  
  /* ==========================================================================
     HTML5 display definitions
     ========================================================================== */
  
  /**
   * Correct `block` display not defined in IE 8/9.
   */
  
  article,
  aside,
  details,
  figcaption,
  figure,
  footer,
  header,
  hgroup,
  main,
  nav,
  section,
  summary {
      display: block;
  }
  
  /**
   * Correct `inline-block` display not defined in IE 8/9.
   */
  
  audio,
  canvas,
  video {
      display: inline-block;
  }
  
  /**
   * Prevent modern browsers from displaying `audio` without controls.
   * Remove excess height in iOS 5 devices.
   */
  
  audio:not([controls]) {
      display: none;
      height: 0;
  }
  
  /**
   * Address `[hidden]` styling not present in IE 8/9.
   * Hide the `template` element in IE, Safari, and Firefox < 22.
   */
  
  [hidden],
  template {
      display: none;
  }
  
  /* ==========================================================================
     Base
     ========================================================================== */
  
  /**
   * 1. Set default font family to sans-serif.
   * 2. Prevent iOS text size adjust after orientation change, without disabling
   *    user zoom.
   */
  
  html {
      font-family: sans-serif; /* 1 */
      -ms-text-size-adjust: 100%; /* 2 */
      -webkit-text-size-adjust: 100%; /* 2 */
  }
  
  /**
   * Remove default margin.
   */
  
  body {
      margin: 0;
  }
  
  /* ==========================================================================
     Links
     ========================================================================== */
  
  /**
   * Remove the gray background color from active links in IE 10.
   */
  
  a {
      background: transparent;
  }
  
  /**
   * Address `outline` inconsistency between Chrome and other browsers.
   */
  
  a:focus {
      outline: thin dotted;
  }
  
  /**
   * Improve readability when focused and also mouse hovered in all browsers.
   */
  
  a:active,
  a:hover {
      outline: 0;
  }
  
  /* ==========================================================================
     Typography
     ========================================================================== */
  
  /**
   * Address variable `h1` font-size and margin within `section` and `article`
   * contexts in Firefox 4+, Safari 5, and Chrome.
   */
  
  h1 {
      font-size: 2em;
      margin: 0.67em 0;
  }
  
  /**
   * Address styling not present in IE 8/9, Safari 5, and Chrome.
   */
  
  abbr[title] {
      border-bottom: 1px dotted;
  }
  
  /**
   * Address style set to `bolder` in Firefox 4+, Safari 5, and Chrome.
   */
  
  b,
  strong {
      font-weight: bold;
  }
  
  /**
   * Address styling not present in Safari 5 and Chrome.
   */
  
  dfn {
      font-style: italic;
  }
  
  /**
   * Address differences between Firefox and other browsers.
   */
  
  hr {
      -moz-box-sizing: content-box;
      box-sizing: content-box;
      height: 0;
  }
  
  /**
   * Address styling not present in IE 8/9.
   */
  
  mark {
      background: #ff0;
      color: #000;
  }
  
  /**
   * Correct font family set oddly in Safari 5 and Chrome.
   */
  
  code,
  kbd,
  pre,
  samp {
      font-family: monospace, serif;
      font-size: 1em;
  }
  
  /**
   * Improve readability of pre-formatted text in all browsers.
   */
  
  pre {
      white-space: pre-wrap;
  }
  
  /**
   * Set consistent quote types.
   */
  
  q {
      quotes: "\201C" "\201D" "\2018" "\2019";
  }
  
  /**
   * Address inconsistent and variable font size in all browsers.
   */
  
  small {
      font-size: 80%;
  }
  
  /**
   * Prevent `sub` and `sup` affecting `line-height` in all browsers.
   */
  
  sub,
  sup {
      font-size: 75%;
      line-height: 0;
      position: relative;
      vertical-align: baseline;
  }
  
  sup {
      top: -0.5em;
  }
  
  sub {
      bottom: -0.25em;
  }
  
  /* ==========================================================================
     Embedded content
     ========================================================================== */
  
  /**
   * Remove border when inside `a` element in IE 8/9.
   */
  
  img {
      border: 0;
  }
  
  /**
   * Correct overflow displayed oddly in IE 9.
   */
  
  svg:not(:root) {
      overflow: hidden;
  }
  
  /* ==========================================================================
     Figures
     ========================================================================== */
  
  /**
   * Address margin not present in IE 8/9 and Safari 5.
   */
  
  figure {
      margin: 0;
  }
  
  /* ==========================================================================
     Forms
     ========================================================================== */
  
  /**
   * Define consistent border, margin, and padding.
   */
  
  fieldset {
      border: 1px solid #c0c0c0;
      margin: 0 2px;
      padding: 0.35em 0.625em 0.75em;
  }
  
  /**
   * 1. Correct `color` not being inherited in IE 8/9.
   * 2. Remove padding so people aren't caught out if they zero out fieldsets.
   */
  
  legend {
      border: 0; /* 1 */
      padding: 0; /* 2 */
  }
  
  /**
   * 1. Correct font family not being inherited in all browsers.
   * 2. Correct font size not being inherited in all browsers.
   * 3. Address margins set differently in Firefox 4+, Safari 5, and Chrome.
   */
  
  button,
  input,
  select,
  textarea {
      font-family: inherit; /* 1 */
      font-size: 100%; /* 2 */
      margin: 0; /* 3 */
  }
  
  /**
   * Address Firefox 4+ setting `line-height` on `input` using `!important` in
   * the UA stylesheet.
   */
  
  button,
  input {
      line-height: normal;
  }
  
  /**
   * Address inconsistent `text-transform` inheritance for `button` and `select`.
   * All other form control elements do not inherit `text-transform` values.
   * Correct `button` style inheritance in Chrome, Safari 5+, and IE 8+.
   * Correct `select` style inheritance in Firefox 4+ and Opera.
   */
  
  button,
  select {
      text-transform: none;
  }
  
  /**
   * 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio`
   *    and `video` controls.
   * 2. Correct inability to style clickable `input` types in iOS.
   * 3. Improve usability and consistency of cursor style between image-type
   *    `input` and others.
   */
  
  button,
  html input[type="button"], /* 1 */
  input[type="reset"],
  input[type="submit"] {
      -webkit-appearance: button; /* 2 */
      cursor: pointer; /* 3 */
  }
  
  /**
   * Re-set default cursor for disabled elements.
   */
  
  button[disabled],
  html input[disabled] {
      cursor: default;
  }
  
  /**
   * 1. Address box sizing set to `content-box` in IE 8/9/10.
   * 2. Remove excess padding in IE 8/9/10.
   */
  
  input[type="checkbox"],
  input[type="radio"] {
      box-sizing: border-box; /* 1 */
      padding: 0; /* 2 */
  }
  
  /**
   * 1. Address `appearance` set to `searchfield` in Safari 5 and Chrome.
   * 2. Address `box-sizing` set to `border-box` in Safari 5 and Chrome
   *    (include `-moz` to future-proof).
   */
  
  input[type="search"] {
      -webkit-appearance: textfield; /* 1 */
      -moz-box-sizing: content-box;
      -webkit-box-sizing: content-box; /* 2 */
      box-sizing: content-box;
  }
  
  /**
   * Remove inner padding and search cancel button in Safari 5 and Chrome
   * on OS X.
   */
  
  input[type="search"]::-webkit-search-cancel-button,
  input[type="search"]::-webkit-search-decoration {
      -webkit-appearance: none;
  }
  
  /**
   * Remove inner padding and border in Firefox 4+.
   */
  
  button::-moz-focus-inner,
  input::-moz-focus-inner {
      border: 0;
      padding: 0;
  }
  
  /**
   * 1. Remove default vertical scrollbar in IE 8/9.
   * 2. Improve readability and alignment in all browsers.
   */
  
  textarea {
      overflow: auto; /* 1 */
      vertical-align: top; /* 2 */
  }
  
  /* ==========================================================================
     Tables
     ========================================================================== */
  
  /**
   * Remove most spacing between table cells.
   */
  
  table {
      border-collapse: collapse;
      border-spacing: 0;
  }
  
  .go-top {
  position: fixed;
  bottom: 2em;
  right: 2em;
  text-decoration: none;
  background-color: #E0E0E0;
  font-size: 12px;
  padding: 1em;
  display: inline;
  }
  
  /* Github css */
  
  html,body{color:black;}
  *:not('#mkdbuttons'){margin:0;padding:0}
  body{font:13.34px -apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif;-webkit-font-smoothing:subpixel-antialiased;}
  body{background-color:#fff;padding:0px;margin:30px 50px;font-size:16px;line-height:1.7}
  body>*:first-child{margin-top:0!important}
  body>*:last-child{margin-bottom:0!important}
  
  a{color:#4183c4;text-decoration:none}
  a code{color:#4183c4;}
  p code, li code, h1 code, h2 code, h3 code, h4 code {background-color: #f3f4f4;}
  
  h1,h2,h3,h4,h5,h6{margin:20px 0 10px;padding:0;font-weight:600;-webkit-font-smoothing:subpixel-antialiased;cursor:text}
  h1{font-size:32px;color:#000}
  h2{font-size:24px;border-bottom:1px solid #ccc;color:#000}
  h3{font-size:20px;color:#333}
  h4{font-size:18px;color:#333}
  h5{font-size:16px;color:#333}
  h6{font-size:14px;color:#777}
  
  p,blockquote,table,pre{margin:15px 0}
  ul{padding-left:30px}ol{padding-left:30px}
  ol li ul:first-of-type{margin-top:0}
  hr{background:transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAEAQMAAACXytwAAAAABlBMVEUAAAAAAAClZ7nPAAAAAnRSTlMzAIL4qAgAAAAQSURBVAjXY3jAcIShh0EGAAu8Ak3MBNBbAAAAAElFTkSuQmCC) repeat-x 0 0;border:0 none;color:#ccc;height:4px;padding:0}
  body>h2:first-child{margin-top:0;padding-top:0}
  body>h1:first-child{margin-top:0;padding-top:0}
  body>h1:first-child+h2{margin-top:0;padding-top:0}
  body>h3:first-child,body>h4:first-child,body>h5:first-child,body>h6:first-child{margin-top:0;padding-top:0}
  a:first-child h1,a:first-child h2,a:first-child h3,a:first-child h4,a:first-child h5,a:first-child h6{margin-top:0;padding-top:0}
  h1+p,h2+p,h3+p,h4+p,h5+p,h6+p,ul li>:first-child,ol li>:first-child{margin-top:0}
  dl{padding:0}
  dl dt{font-size:14px;font-weight:bold;font-style:italic;padding:0;margin:15px 0 5px}
  dl dt:first-child{padding:0}dl dt>:first-child{margin-top:0}dl dt>:last-child{margin-bottom:0}
  dl dd{margin:0 0 15px;padding:0 15px}dl dd>:first-child{margin-top:0}
  dl dd>:last-child{margin-bottom:0}
  blockquote{border-left:4px solid #DDD;padding:0 15px;color:#777}
  blockquote>:first-child{margin-top:0}
  blockquote>:last-child{margin-bottom:0}
  table{border-collapse:collapse;border-spacing:0;font-size:100%;font:inherit}
  table th{font-weight:bold;border:1px solid #ccc;padding:6px 13px}
  table td{border:1px solid #ccc;padding:6px 13px}
  table tr{border-top:1px solid #ccc;background-color:#fff}
  table tr:nth-child(2n){background-color:#f6f8fa}
  img{max-width:100%}
  code,tt{margin:0 2px;padding:0 5px;white-space:nowrap;border:1px solid #eaeaea;background-color:#f6f8fa;border-radius:3px;font-family:Consolas,'Liberation Mono',Courier,monospace;font-size:85%;color:#333;}
  pre>code{margin:0;padding:0;white-space:pre;border:0;background:transparent}
  .highlight pre{background-color:#f6f8fa;border:1px solid #ccc;line-height:19px;overflow:auto;padding:6px 10px;border-radius:3px}
  pre{background-color:#f6f8fa;border:none;line-height:19px;overflow:auto;padding:16px;border-radius:3px}
  pre code,pre tt{background-color:transparent;border:0}
  .poetry pre{font-family:Georgia,Garamond,serif!important;font-style:italic;font-size:110%!important;line-height:1.6em;display:block;margin-left:1em}
  .poetry pre code{font-family:Georgia,Garamond,serif!important;word-break:break-all;word-break:break-word;-webkit-hyphens:auto;-moz-hyphens:auto;hyphens:auto;white-space:pre-wrap}
  sup,sub,a.footnote{font-size:1.4ex;height:0;line-height:1;vertical-align:super;position:relative}
  sub{vertical-align:sub;top:-1px}
  
  @media print{
  	body{background:#fff}
  	img,pre,blockquote,table,figure{page-break-inside:avoid}
  	body{background:#fff;border:0}
  	code{background-color:#fff;color:#333!important;padding:0 .2em;border:1px solid #dedede}
  	pre{background:#fff}
  	pre code{background-color:white!important;overflow:visible}}
  @media screen{
  	body.inverted{color:#eee!important;border-color:#555;box-shadow:none}
  	.inverted body,.inverted hr .inverted p,.inverted td,.inverted li,.inverted h1,.inverted h2,.inverted h3,.inverted h4,.inverted h5,.inverted h6,.inverted th,.inverted .math,.inverted caption,.inverted dd,.inverted dt,.inverted blockquote{color:#eee!important;border-color:#555;box-shadow:none}
  	.inverted td,.inverted th{background:#333}
  	.inverted h2{border-color:#555}
  	.inverted hr{border-color:#777;border-width:1px!important}
  	::selection{background:rgba(157,193,200,0.5)}
  	h1::selection{background-color:rgba(45,156,208,0.3)}
  	h2::selection{background-color:rgba(90,182,224,0.3)}
  	h3::selection,h4::selection,h5::selection,h6::selection,li::selection,ol::selection{background-color:rgba(133,201,232,0.3)}
  	code::selection{background-color:rgba(0,0,0,0.7);color:#eee}
  	code span::selection{background-color:rgba(0,0,0,0.7)!important;color:#eee!important}
  	a::selection{background-color:rgba(255,230,102,0.2)}
  	.inverted a::selection{background-color:rgba(255,230,102,0.6)}
  	td::selection,th::selection,caption::selection{background-color:rgba(180,237,95,0.5)}
  	.inverted{background:#0b2531;background:#252a2a}
  	.inverted body{background:#252a2a}
  	.inverted a{color:#acd1d5}}
  
  .highlight .c{color:#998;font-style:italic}
  .highlight .err{color:#a61717;background-color:#e3d2d2}
  .highlight .k,.highlight .o{font-weight:bold}
  .highlight .cm{color:#998;font-style:italic}
  .highlight .cp{color:#999;font-weight:bold}
  .highlight .c1{color:#998;font-style:italic}
  .highlight .cs{color:#999;font-weight:bold;font-style:italic}
  .highlight .gd{color:#000;background-color:#fdd}
  .highlight .gd .x{color:#000;background-color:#faa}
  .highlight .ge{font-style:italic}
  .highlight .gr{color:#a00}
  .highlight .gh{color:#999}
  .highlight .gi{color:#000;background-color:#dfd}
  .highlight .gi .x{color:#000;background-color:#afa}
  .highlight .go{color:#888}
  .highlight .gp{color:#555}
  .highlight .gs{font-weight:bold}
  .highlight .gu{color:#800080;font-weight:bold}
  .highlight .gt{color:#a00}
  .highlight .kc,.highlight .kd,.highlight .kn,.highlight .kp,.highlight .kr{font-weight:bold}
  .highlight .kt{color:#458;font-weight:bold}
  .highlight .m{color:#099}
  .highlight .s{color:#d14}
  .highlight .na{color:#008080}
  .highlight .nb{color:#0086b3}
  .highlight .nc{color:#458;font-weight:bold}
  .highlight .no{color:#008080}
  .highlight .ni{color:#800080}
  .highlight .ne,.highlight .nf{color:#900;font-weight:bold}
  .highlight .nn{color:#555}
  .highlight .nt{color:#000080}
  .highlight .nv{color:#008080}
  .highlight .ow{font-weight:bold}
  .highlight .w{color:#bbb}
  .highlight .mf,.highlight .mh,.highlight .mi,.highlight .mo{color:#099}
  .highlight .sb,.highlight .sc,.highlight .sd,.highlight .s2,.highlight .se,.highlight .sh,.highlight .si,.highlight .sx{color:#d14}
  .highlight .sr{color:#009926}
  .highlight .s1{color:#d14}
  .highlight .ss{color:#990073}
  .highlight .bp{color:#999}
  .highlight .vc,.highlight .vg,.highlight .vi{color:#008080}
  .highlight .il{color:#099}
  .highlight .gc{color:#999;background-color:#eaf2f5}
  .type-csharp .highlight .k,.type-csharp .highlight .kt{color:#00F}
  .type-csharp .highlight .nf{color:#000;font-weight:normal}
  .type-csharp .highlight .nc{color:#2b91af}
  .type-csharp .highlight .nn{color:#000}
  .type-csharp .highlight .s,.type-csharp .highlight .sc{color:#a31515}
  
  /* Sphinx3 specific highlighting hacks here
   * kw == keyword, st == string, dv == decimal value, fl == float?, dt == datatype, ot == other, fu == function
   */
  code span.kw {color: #07a}
  code span.st {color: #690}
  code span.dv {color: #905}
  code span.fl {color: #905}
  code span.dt {color: #07a}
  code span.ot {color: #888}
  code span.fu {color: #d46}
    
  nav {
  	display: block;
  	position: fixed;
  	top: 0px;
  	bottom: 0px;
  	left: 0px;
  	width: 300px;
  	height: 100%;
  	overflow-y: auto;
  	overflow-x: hidden;
  }
  @media print{nav{display:none;}}
  
  .docbody {
  	display: block;
  	margin: 0 0 0 300px;
  	padding: 40px;
  	max-width: 66em;
  	border-radius:3px;-moz-border-radius:3px;-webkit-border-radius:3px;
  }
  @media screen{.docbody{box-shadow:0 0 0 1px #cacaca,0 0 0 4px #eee}}
  @media print{.docbody{margin:30px;}}
  
  </style>
</head>
<body>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#sphinx-3">Sphinx 3</a><ul>
<li><a href="#features-overview">Features overview</a></li>
<li><a href="#features-cheat-sheet">Features cheat sheet</a></li>
<li><a href="#getting-started">Getting started</a><ul>
<li><a href="#getting-started-on-linux-and-macos">Getting started on Linux (and MacOS)</a></li>
<li><a href="#getting-started-on-windows">Getting started on Windows</a></li>
<li><a href="#running-queries-via-mysql-shell">Running queries via MySQL shell</a></li>
<li><a href="#writing-your-first-config">Writing your first config</a></li>
<li><a href="#running-queries-from-php-python-etc">Running queries from PHP, Python, etc</a></li>
<li><a href="#running-queries-via-http">Running queries via HTTP</a></li>
<li><a href="#installing-indexer-sql-drivers-on-linux">Installing <code>indexer</code> SQL drivers on Linux</a></li>
</ul></li>
<li><a href="#main-concepts">Main concepts</a><ul>
<li><a href="#indexes">Indexes</a></li>
<li><a href="#documents">Documents</a></li>
<li><a href="#fields">Fields</a></li>
<li><a href="#attributes">Attributes</a></li>
</ul></li>
<li><a href="#using-docstore">Using DocStore</a></li>
<li><a href="#using-attribute-indexes">Using attribute indexes</a><ul>
<li><a href="#query-optimizer-and-index-hints">Query optimizer, and index hints</a></li>
<li><a href="#create-and-drop-index-performance">CREATE and DROP index performance</a></li>
</ul></li>
<li><a href="#using-k-batches">Using k-batches</a></li>
<li><a href="#doing-bulk-data-loads">Doing bulk data loads</a></li>
<li><a href="#using-json">Using JSON</a><ul>
<li><a href="#json-comparison-quirks">JSON comparison quirks</a></li>
</ul></li>
<li><a href="#using-array-attributes">Using array attributes</a></li>
<li><a href="#using-mappings">Using mappings</a><ul>
<li><a href="#pre-morph-mappings">Pre-morph mappings</a></li>
<li><a href="#post-morph-mappings">Post-morph mappings</a></li>
<li><a href="#document-only-mappings">Document-only mappings</a></li>
</ul></li>
<li><a href="#using-morphdict">Using morphdict</a></li>
<li><a href="#migrating-legacy-wordforms">Migrating legacy wordforms</a></li>
<li><a href="#using-udfs">Using UDFs</a><ul>
<li><a href="#udfs-overview">UDFs overview</a></li>
<li><a href="#udf-programming-introduction">UDF programming introduction</a></li>
<li><a href="#udf-argument-and-return-types">UDF argument and return types</a></li>
<li><a href="#udf-call-batching">UDF call batching</a></li>
<li><a href="#using-factors-in-udfs">Using <code>FACTORS()</code> in UDFs</a></li>
<li><a href="#udf-calls-sequences">UDF calls sequences</a></li>
</ul></li>
<li><a href="#indexing-csv-and-tsv-files">Indexing: CSV and TSV files</a></li>
<li><a href="#indexing-special-chars-blended-tokens-and-mixed-codes">Indexing: special chars, blended tokens, and mixed codes</a><ul>
<li><a href="#blended-tokens-with-special-characters">Blended tokens (with special characters)</a></li>
<li><a href="#mixed-codes-with-letters-and-digits">Mixed codes (with letters and digits)</a></li>
<li><a href="#blending-modes">Blending modes</a></li>
<li><a href="#searching-vs-blended-tokens-and-mixed-codes">Searching vs blended tokens and mixed codes</a></li>
</ul></li>
<li><a href="#searching-query-syntax">Searching: query syntax</a><ul>
<li><a href="#operators">Operators</a></li>
<li><a href="#modifiers">Modifiers</a></li>
<li><a href="#cheat-sheet">Cheat sheet</a></li>
<li><a href="#keyword-modifiers">Keyword modifiers</a></li>
<li><a href="#boolean-operators-brackets-and-or-not">Boolean operators (brackets, AND, OR, NOT)</a></li>
<li><a href="#phrase-operator">Phrase operator</a></li>
<li><a href="#maybe-operator">MAYBE operator</a></li>
<li><a href="#term-or-operator">Term-OR operator</a></li>
<li><a href="#field-and-position-limit-operator">Field and position limit operator</a></li>
<li><a href="#proximity-and-near-operators">Proximity and NEAR operators</a></li>
<li><a href="#quorum-operator">Quorum operator</a></li>
<li><a href="#strict-order-operator-before">Strict order operator (BEFORE)</a></li>
<li><a href="#sentence-and-paragraph-operators">SENTENCE and PARAGRAPH operators</a></li>
<li><a href="#zone-and-zonespan-operators">ZONE and ZONESPAN operators</a></li>
</ul></li>
<li><a href="#searching-geosearches">Searching: geosearches</a></li>
<li><a href="#searching-vector-searches">Searching: vector searches</a></li>
<li><a href="#ranking-factors">Ranking: factors</a><ul>
<li><a href="#factor-aggregation-functions">Factor aggregation functions</a></li>
<li><a href="#keyword-flags">Keyword flags</a></li>
<li><a href="#query-level-ranking-factors">Query-level ranking factors</a></li>
<li><a href="#document-level-ranking-factors">Document-level ranking factors</a></li>
<li><a href="#field-level-ranking-factors">Field-level ranking factors</a></li>
</ul></li>
<li><a href="#ranking-builtin-ranker-formulas">Ranking: builtin ranker formulas</a></li>
<li><a href="#ranking-idf-magics">Ranking: IDF magics</a><ul>
<li><a href="#how-sphinx-computes-idf">How Sphinx computes IDF</a></li>
</ul></li>
<li><a href="#ranking-picking-fields-with-rank_fields">Ranking: picking fields with <code>rank_fields</code></a></li>
<li><a href="#ranking-trigrams">Ranking: trigrams</a></li>
<li><a href="#siege-mode">Operations: “siege mode”, temporary global query limits</a></li>
<li><a href="#operations-network-internals">Operations: network internals</a><ul>
<li><a href="#incoming-client-queries">Incoming (client) queries</a></li>
<li><a href="#outgoing-distributed-queries">Outgoing (distributed) queries</a></li>
</ul></li>
<li><a href="#sphinxql-reference">SphinxQL reference</a><ul>
<li><a href="#bulk-update-syntax">BULK UPDATE syntax</a></li>
<li><a href="#create-index-syntax">CREATE INDEX syntax</a></li>
<li><a href="#drop-index-syntax">DROP INDEX syntax</a></li>
<li><a href="#kill-syntax">KILL syntax</a></li>
<li><a href="#select-syntax">SELECT syntax</a></li>
<li><a href="#show-index-agent-status-syntax">SHOW INDEX AGENT STATUS syntax</a></li>
<li><a href="#show-index-from-syntax">SHOW INDEX FROM syntax</a></li>
<li><a href="#show-status-syntax">SHOW STATUS syntax</a></li>
<li><a href="#show-variables-syntax">SHOW VARIABLES syntax</a></li>
</ul></li>
<li><a href="#functions-reference">Functions reference</a><ul>
<li><a href="#coalesce-function"><code>COALESCE()</code> function</a></li>
<li><a href="#dot-function"><code>DOT()</code> function</a></li>
<li><a href="#fvec-function"><code>FVEC()</code> function</a></li>
<li><a href="#pp-function"><code>PP()</code> function</a></li>
<li><a href="#slice-functions">Slice functions</a></li>
<li><a href="#strpos-function"><code>STRPOS()</code> function</a></li>
<li><a href="#uint-function"><code>UINT()</code> function</a></li>
</ul></li>
<li><a href="#server-variables-reference">Server variables reference</a><ul>
<li><a href="#attrindex_thresh-variable"><code>attrindex_thresh</code> variable</a></li>
<li><a href="#log_debug_filter-variable"><code>log_debug_filter</code> variable</a></li>
<li><a href="#log_level-variable"><code>log_level</code> variable</a></li>
<li><a href="#net_spin_msec-variable"><code>net_spin_msec</code> variable</a></li>
<li><a href="#query_log_format-variable"><code>query_log_format</code> variable</a></li>
<li><a href="#query_log_min_msec-variable"><code>query_log_min_msec</code> variable</a></li>
<li><a href="#sql_fail_filter-variable"><code>sql_fail_filter</code> variable</a></li>
<li><a href="#sql_log_file-variable"><code>sql_log_file</code> variable</a></li>
</ul></li>
<li><a href="#changes-in-3.x">Changes in 3.x</a><ul>
<li><a href="#version-3.4.1-09-jul-2021">Version 3.4.1, 09 jul 2021</a></li>
<li><a href="#version-3.3.1-06-jul-2020">Version 3.3.1, 06 jul 2020</a></li>
<li><a href="#version-3.2.1-31-jan-2020">Version 3.2.1, 31 jan 2020</a></li>
<li><a href="#version-3.1.1-17-oct-2018">Version 3.1.1, 17 oct 2018</a></li>
<li><a href="#version-3.0.3-30-mar-2018">Version 3.0.3, 30 mar 2018</a></li>
<li><a href="#version-3.0.2-25-feb-2018">Version 3.0.2, 25 feb 2018</a></li>
<li><a href="#version-3.0.1-18-dec-2017">Version 3.0.1, 18 dec 2017</a></li>
</ul></li>
<li><a href="#changes-since-v.2.x">Changes since v.2.x</a></li>
<li><a href="#copyrights">Copyrights</a></li>
</ul></li>
</ul>
</nav>
<div class="docbody">
<h1 id="sphinx-3">Sphinx 3</h1>
<p>Sphinx is a free, dual-licensed search server. Sphinx is written in C++, and focuses on query performance and search relevance.</p>
<p>The primary client API is currently SphinxQL, a dialect of SQL. Almost any MySQL connector should work. Additionally, basic HTTP/JSON API and native APIs for a number of languages (PHP, Python, Ruby, C, Java) are provided.</p>
<p>This document is an effort to build a better documentation for Sphinx v.3.x and up. Think of it as a book or a tutorial which you could actually <em>read</em>; think of the previous “reference manual” as of a “dictionary” where you look up specific syntax features. The two might (and should) eventually converge.</p>
<h2 id="features-overview">Features overview</h2>
<p>Top level picture, what does Sphinx offer?</p>
<ul>
<li>SQL, HTTP/JSON, and custom native SphinxAPI access APIs</li>
<li>NRT (Near Real Time) and offline batch indexing</li>
<li>Full-text and non-text (parameter) searching</li>
<li>Relevance ranking, from basic formulas to ML models</li>
<li>Federated results from multiple servers</li>
<li>Decent performance</li>
</ul>
<p>Other things that seem worth mentioning (this list is probably incomplete at all times, and definitely in random order):</p>
<ul>
<li>Morphology and text-processing tools
<ul>
<li>Fully flexible tokenization (see <code>charset_table</code> and <code>exceptions</code>)</li>
<li>Proper morphology (lemmatizer) for English, Russian, and German (see <code>morphology</code>)</li>
<li>Basic morphology (stemmer) for many other languages</li>
<li>User-specified mappings, <code>core 2 duo =&gt; c2d</code></li>
</ul></li>
<li>Native JSON support</li>
<li>Geosearch support</li>
<li>Fast expressions engine</li>
<li>Query suggestions</li>
<li>Snippets builder</li>
<li>…</li>
</ul>
<p>And, of course, there is always stuff that we know we currently lack!</p>
<ul>
<li>Index replication</li>
<li>…</li>
</ul>
<h2 id="features-cheat-sheet">Features cheat sheet</h2>
<p>This section is supposed to provide a bit more detail on all the available features; to cover them more or less fully; and give you some further pointers into the specific reference sections (on the related config directives and SphinxQL statements).</p>
<ul>
<li>Full-text search queries, see <code>SELECT ... WHERE MATCH('this')</code> SphinxQL statement
<ul>
<li>Boolean matching operators (implicit AND, explicit OR, NOT, and brackets), as in <code>(one two) | (three !four)</code></li>
<li>Boolean matching optimizations, see <code>OPTION boolean_simplify=1</code> in <code>SELECT</code> statement</li>
<li>Advanced text matching operators
<ul>
<li>Field restrictions, <code>@title hello world</code> or <code>@!title hello</code> or <code>@(title,body) any of the two</code> etc</li>
<li>In-field position restrictions, <code>@title[50] hello</code></li>
<li>MAYBE operator for optional keyword matching, <code>cat MAYBE dog</code></li>
<li>phrase matching, <code>"roses are red"</code></li>
<li>quorum matching, <code>"pick any 3 keywords out of this entire set"/3</code></li>
<li>proximity matching, <code>"within 10 positions all terms in yoda order"~10</code> or <code>hello NEAR/3 world NEAR/4 "my test"</code></li>
<li>strict order matching, <code>(bag of words) &lt;&lt; "exact phrase" &lt;&lt; this|that</code></li>
<li>sentence matching, <code>all SENTENCE words SENTENCE "in one sentence"</code></li>
<li>paragraph matching, <code>"Bill Gates" PARAGRAPH "Steve Jobs"</code></li>
<li>zone and zone-span matching, <code>ZONE:(h3,h4) in any of these title tags</code> and <code>ZONESPAN:(h2) only in a single instance</code></li>
</ul></li>
<li>Keyword modifiers (that can usually be used within operators)
<ul>
<li>exact (pre-morphology) form modifier, <code>raining =cats and =dogs</code></li>
<li>field-start and field-end modifiers, <code>^hello world$</code></li>
<li>IDF (ranking) boost, <code>boosted^1.234</code></li>
</ul></li>
<li>Substring and wildcard searches
<ul>
<li>see <code>min_prefix_len</code> and <code>min_infix_len</code> directives</li>
<li>use <code>th?se three keyword% wild*cards *verywher*</code> (<code>?</code> = 1 char exactly; <code>%</code> = 0 or 1 char; <code>*</code> = 0 or more chars)</li>
</ul></li>
</ul></li>
<li>…</li>
</ul>
<p>TODO: describe more, add links!</p>
<h2 id="getting-started">Getting started</h2>
<p>That should now be rather simple. No magic installation required! On any platform, the <em>sufficient</em> thing to do is:</p>
<ol type="1">
<li>Get the binaries.</li>
<li>Run <code>searchd</code></li>
<li>Create indexes.</li>
<li>Run queries.</li>
</ol>
<p>See more details on that (running in config-less mode) just below.</p>
<p>Or alternatively, you can ETL your data offline, using the <code>indexer</code> tool:</p>
<ol type="1">
<li>Get the binaries.</li>
<li>Create <code>sphinx.conf</code>, with at least 1 <code>index</code> section.</li>
<li>Run <code>indexer --all</code> once, to initially create the indexes.</li>
<li>Run <code>searchd</code></li>
<li>Run queries.</li>
<li>Run <code>indexer --all --rotate</code> regularly, to update the indexes.</li>
</ol>
<p>Note that instead of inserting the data into indexes online, the <code>indexer</code> tool instead creates a shadow copy of the specified index(es) offline, and then sends a signal to <code>searchd</code> to pick up that copy. So you should <em>never</em> get a partially populated index with <code>indexer</code>; it’s always all-or-nothing.</p>
<p>More details on running with configs are also below, refer to the <a href="#writing-your-first-config">“Writing your first config”</a> section.</p>
<h3 id="getting-started-on-linux-and-macos">Getting started on Linux (and MacOS)</h3>
<p>Versions and file names <em>will</em> vary, and you most likely <em>will</em> want to configure Sphinx at least a little, but for an immediate quickstart:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1"></a>$ <span class="fu">wget</span> -q http://sphinxsearch.com/files/sphinx-3.0.2-2592786-linux-amd64.tar.gz</span>
<span id="cb1-2"><a href="#cb1-2"></a>$ <span class="fu">tar</span> zxf sphinx-3.0.2-2592786-linux-amd64.tar.gz</span>
<span id="cb1-3"><a href="#cb1-3"></a>$ <span class="bu">cd</span> sphinx-3.0.2-2592786-linux-amd64/bin</span>
<span id="cb1-4"><a href="#cb1-4"></a>$ <span class="ex">./searchd</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="ex">Sphinx</span> 3.0.2 (commit 2592786)</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="ex">Copyright</span> (c) <span class="ex">2001-2018</span>, Andrew Aksyonoff</span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="ex">Copyright</span> (c) <span class="ex">2008-2016</span>, Sphinx Technologies Inc (http://sphinxsearch.com)</span>
<span id="cb1-8"><a href="#cb1-8"></a></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="ex">listening</span> on all interfaces, port=9312</span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="ex">listening</span> on all interfaces, port=9306</span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="ex">WARNING</span>: No extra index definitions found in data folder</span>
<span id="cb1-12"><a href="#cb1-12"></a>$</span></code></pre></div>
<p>That’s it; the daemon should now be running and accepting connections on port 9306. And you can connect to it using MySQL CLI (see below for more details, or just try <code>mysql -P9306</code> right away).</p>
<h3 id="getting-started-on-windows">Getting started on Windows</h3>
<p>Pretty much the same story, except that on Windows <code>searchd</code> will not automatically go into background:</p>
<pre><code>C:\Sphinx\&gt;searchd.exe
Sphinx 3.0-dev (c3c241f)
...
accepting connections
prereaded 0 indexes in 0.000 sec</code></pre>
<p>This is alright. Do not kill it. Just switch to a separate session and start querying.</p>
<h3 id="running-queries-via-mysql-shell">Running queries via MySQL shell</h3>
<p>Run the MySQL CLI and point it to a port 9306. For example on Windows:</p>
<pre><code>C:\&gt;mysql -h127.0.0.1 -P9306
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 1
Server version: 3.0-dev (c3c241f)
...</code></pre>
<p>I have intentionally used <code>127.0.0.1</code> in this example for two reasons (both caused by MySQL CLI quirks, not Sphinx):</p>
<ul>
<li>sometimes, an IP address is required to use the <code>-P9306</code> switch, not <code>localhost</code></li>
<li>sometimes, <code>localhost</code> works but causes a connection delay</li>
</ul>
<p>But in the simplest case even just <code>mysql -P9306</code> should work fine.</p>
<p>And from there, just run SphinxQL queries:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb4-1"><a href="#cb4-1"></a>mysql<span class="op">&gt;</span> <span class="kw">CREATE</span> <span class="kw">TABLE</span> test (gid uint, title field stored,</span>
<span id="cb4-2"><a href="#cb4-2"></a>    <span class="op">-&gt;</span> content field stored);</span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="kw">Query</span> OK, <span class="dv">0</span> <span class="kw">rows</span> affected (<span class="fl">0.00</span> sec)</span>
<span id="cb4-4"><a href="#cb4-4"></a></span>
<span id="cb4-5"><a href="#cb4-5"></a>mysql<span class="op">&gt;</span> <span class="kw">INSERT</span> <span class="kw">INTO</span> test (<span class="kw">id</span>, title) <span class="kw">VALUES</span> (<span class="dv">123</span>, <span class="st">&#39;hello world&#39;</span>);</span>
<span id="cb4-6"><a href="#cb4-6"></a><span class="kw">Query</span> OK, <span class="dv">1</span> <span class="kw">row</span> affected (<span class="fl">0.00</span> sec)</span>
<span id="cb4-7"><a href="#cb4-7"></a></span>
<span id="cb4-8"><a href="#cb4-8"></a>mysql<span class="op">&gt;</span> <span class="kw">INSERT</span> <span class="kw">INTO</span> test (<span class="kw">id</span>, gid, content) <span class="kw">VALUES</span> (<span class="dv">234</span>, <span class="dv">345</span>, <span class="st">&#39;empty title&#39;</span>);</span>
<span id="cb4-9"><a href="#cb4-9"></a><span class="kw">Query</span> OK, <span class="dv">1</span> <span class="kw">row</span> affected (<span class="fl">0.00</span> sec)</span>
<span id="cb4-10"><a href="#cb4-10"></a></span>
<span id="cb4-11"><a href="#cb4-11"></a>mysql<span class="op">&gt;</span> <span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> test;</span>
<span id="cb4-12"><a href="#cb4-12"></a><span class="op">+</span><span class="co">------+------+-------------+-------------+</span></span>
<span id="cb4-13"><a href="#cb4-13"></a>| <span class="kw">id</span>   | gid  | title       | content     |</span>
<span id="cb4-14"><a href="#cb4-14"></a><span class="op">+</span><span class="co">------+------+-------------+-------------+</span></span>
<span id="cb4-15"><a href="#cb4-15"></a>|  <span class="dv">123</span> |    <span class="dv">0</span> | hello world |             |</span>
<span id="cb4-16"><a href="#cb4-16"></a>|  <span class="dv">234</span> |  <span class="dv">345</span> |             | <span class="kw">empty</span> title |</span>
<span id="cb4-17"><a href="#cb4-17"></a><span class="op">+</span><span class="co">------+------+-------------+-------------+</span></span>
<span id="cb4-18"><a href="#cb4-18"></a><span class="dv">2</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span>
<span id="cb4-19"><a href="#cb4-19"></a></span>
<span id="cb4-20"><a href="#cb4-20"></a>mysql<span class="op">&gt;</span> <span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> test <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello&#39;</span>);</span>
<span id="cb4-21"><a href="#cb4-21"></a><span class="op">+</span><span class="co">------+------+-------------+---------+</span></span>
<span id="cb4-22"><a href="#cb4-22"></a>| <span class="kw">id</span>   | gid  | title       | content |</span>
<span id="cb4-23"><a href="#cb4-23"></a><span class="op">+</span><span class="co">------+------+-------------+---------+</span></span>
<span id="cb4-24"><a href="#cb4-24"></a>|  <span class="dv">123</span> |    <span class="dv">0</span> | hello world |         |</span>
<span id="cb4-25"><a href="#cb4-25"></a><span class="op">+</span><span class="co">------+------+-------------+---------+</span></span>
<span id="cb4-26"><a href="#cb4-26"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span>
<span id="cb4-27"><a href="#cb4-27"></a></span>
<span id="cb4-28"><a href="#cb4-28"></a>mysql<span class="op">&gt;</span> <span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> test <span class="kw">WHERE</span> MATCH(<span class="st">&#39;@content hello&#39;</span>);</span>
<span id="cb4-29"><a href="#cb4-29"></a><span class="kw">Empty</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>SphinxQL is our own SQL dialect, described in more detail in the respective <a href="#sphinxql-reference">SphinxQL Reference</a> section.</p>
<h3 id="writing-your-first-config">Writing your first config</h3>
<p>All those easy examples above were utilizing a config-less mode, where <code>searchd</code> stores and manages all the data and settings <code>./sphinxdata</code> data folder, and you have to manage everything via <code>searchd</code> itself.</p>
<p>However, because as of v.3.x the config-less mode is not yet complete (certain settings and tools are still missing), many instances would likely still want to specify their indexes and settings via ye good olde <code>sphinx.conf</code> config file.</p>
<p>You can begin with <code>etc/sphinx-min.conf.dist</code> example as a starting point. That example shows how to use both RT indexes that you would populate on the fly, and plain indexes that you would populate from your database. For the latter, there also is a tiny matching <code>etc/example.sql</code> MySQL dump with a few sample tables and rows that the <code>test1</code> index from <code>sphinx-min.conf.dist</code> would access.</p>
<p>However, even that small sample is not really minimal. The minimal config only requires you to specify 2 paths for log and pid files, and define 1 index:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1"></a><span class="ex">searchd</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="kw">{</span></span>
<span id="cb5-3"><a href="#cb5-3"></a>    <span class="ex">log</span> = ./data/searchd.log</span>
<span id="cb5-4"><a href="#cb5-4"></a>    <span class="ex">pid_file</span> = ./data/searchd.pid</span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="kw">}</span></span>
<span id="cb5-6"><a href="#cb5-6"></a></span>
<span id="cb5-7"><a href="#cb5-7"></a><span class="ex">index</span> mydocs</span>
<span id="cb5-8"><a href="#cb5-8"></a><span class="kw">{</span></span>
<span id="cb5-9"><a href="#cb5-9"></a>    <span class="bu">type</span> = rt</span>
<span id="cb5-10"><a href="#cb5-10"></a>    <span class="ex">path</span> = ./data/mydocs</span>
<span id="cb5-11"><a href="#cb5-11"></a>    <span class="ex">rt_field</span> = title</span>
<span id="cb5-12"><a href="#cb5-12"></a>    <span class="ex">rt_attr_json</span> = j</span>
<span id="cb5-13"><a href="#cb5-13"></a><span class="kw">}</span></span></code></pre></div>
<p>And with just that, you can start <code>searchd</code> in config mode and start firing queries right away. (Do not forget to create the <code>data</code> directory though.)</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1"></a>$ <span class="fu">mkdir</span> data</span>
<span id="cb6-2"><a href="#cb6-2"></a></span>
<span id="cb6-3"><a href="#cb6-3"></a>$ <span class="ex">./searchd</span></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="ex">Sphinx</span> 3.3.1-dev (commit 00642f6c)</span>
<span id="cb6-5"><a href="#cb6-5"></a><span class="ex">Copyright</span> (c) <span class="ex">2001-2020</span>, Andrew Aksyonoff</span>
<span id="cb6-6"><a href="#cb6-6"></a><span class="ex">Copyright</span> (c) <span class="ex">2008-2016</span>, Sphinx Technologies Inc (http://sphinxsearch.com)</span>
<span id="cb6-7"><a href="#cb6-7"></a></span>
<span id="cb6-8"><a href="#cb6-8"></a><span class="ex">using</span> config file <span class="st">&#39;./sphinx.conf&#39;</span>...</span>
<span id="cb6-9"><a href="#cb6-9"></a><span class="ex">listening</span> on all interfaces, port=9306</span>
<span id="cb6-10"><a href="#cb6-10"></a><span class="ex">precaching</span> index <span class="st">&#39;mydocs&#39;</span></span>
<span id="cb6-11"><a href="#cb6-11"></a><span class="ex">precached</span> 1 indexes using 1 threads in 0.0 sec</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb7-1"><a href="#cb7-1"></a>$ mysql <span class="op">-</span>h127.<span class="dv">0</span>.<span class="fl">0.1</span> <span class="op">-</span>P9306</span>
<span id="cb7-2"><a href="#cb7-2"></a>mysql<span class="op">&gt;</span> <span class="kw">insert</span> <span class="kw">into</span> mydocs <span class="kw">values</span>(<span class="dv">111</span>, <span class="st">&#39;hello world&#39;</span>, <span class="st">&#39;{&quot;foo&quot;:&quot;bar&quot;}&#39;</span>);</span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="kw">Query</span> OK, <span class="dv">1</span> <span class="kw">row</span> affected (<span class="fl">0.01</span> sec)</span>
<span id="cb7-4"><a href="#cb7-4"></a></span>
<span id="cb7-5"><a href="#cb7-5"></a>mysql<span class="op">&gt;</span> <span class="kw">select</span> <span class="op">*</span> <span class="kw">from</span> mydocs <span class="kw">where</span> match(<span class="st">&#39;hello&#39;</span>);</span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="op">+</span><span class="co">------+---------------+</span></span>
<span id="cb7-7"><a href="#cb7-7"></a>| <span class="kw">id</span>   | j             |</span>
<span id="cb7-8"><a href="#cb7-8"></a><span class="op">+</span><span class="co">------+---------------+</span></span>
<span id="cb7-9"><a href="#cb7-9"></a>|  <span class="dv">111</span> | {<span class="ot">&quot;foo&quot;</span>:<span class="ot">&quot;bar&quot;</span>} |</span>
<span id="cb7-10"><a href="#cb7-10"></a><span class="op">+</span><span class="co">------+---------------+</span></span>
<span id="cb7-11"><a href="#cb7-11"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<h3 id="running-queries-from-php-python-etc">Running queries from PHP, Python, etc</h3>
<div class="sourceCode" id="cb8"><pre class="sourceCode php"><code class="sourceCode php"><span id="cb8-1"><a href="#cb8-1"></a><span class="kw">&lt;?php</span></span>
<span id="cb8-2"><a href="#cb8-2"></a></span>
<span id="cb8-3"><a href="#cb8-3"></a><span class="kw">$conn</span> = <span class="fu">mysqli_connect</span><span class="ot">(</span><span class="st">&quot;127.0.0.1:9306&quot;</span><span class="ot">,</span> <span class="st">&quot;&quot;</span><span class="ot">,</span> <span class="st">&quot;&quot;</span><span class="ot">,</span> <span class="st">&quot;&quot;</span><span class="ot">);</span></span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="kw">if</span> <span class="ot">(</span><span class="fu">mysqli_connect_errno</span><span class="ot">())</span></span>
<span id="cb8-5"><a href="#cb8-5"></a>    <span class="kw">die</span><span class="ot">(</span><span class="st">&quot;failed to connect to Sphinx: &quot;</span> . <span class="fu">mysqli_connect_error</span><span class="ot">());</span></span>
<span id="cb8-6"><a href="#cb8-6"></a></span>
<span id="cb8-7"><a href="#cb8-7"></a><span class="kw">$res</span> = <span class="fu">mysqli_query</span><span class="ot">(</span><span class="kw">$conn</span><span class="ot">,</span> <span class="st">&quot;SHOW VARIABLES&quot;</span><span class="ot">);</span></span>
<span id="cb8-8"><a href="#cb8-8"></a><span class="kw">while</span> <span class="ot">(</span><span class="kw">$row</span> = <span class="fu">mysqli_fetch_row</span><span class="ot">(</span><span class="kw">$res</span><span class="ot">))</span></span>
<span id="cb8-9"><a href="#cb8-9"></a>    <span class="kw">print</span> <span class="st">&quot;</span><span class="kw">$row[0]</span><span class="st">: </span><span class="kw">$row[1]\n</span><span class="st">&quot;</span><span class="ot">;</span></span></code></pre></div>
<p>TODO: examples</p>
<h3 id="running-queries-via-http">Running queries via HTTP</h3>
<p>TODO: examples</p>
<h3 id="installing-indexer-sql-drivers-on-linux">Installing <code>indexer</code> SQL drivers on Linux</h3>
<p>This only affects <code>indexer</code> ETL tool only. If you never bulk load data from SQL sources using it (of course CSV and XML sources are still fine), you can safely skip this section. (And on Windows all the drivers come with the package.)</p>
<p>Depending on your OS, the required package names may vary. Here are some current (as of Mar 2018) package names for Ubuntu and CentOS:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1"></a><span class="ex">ubuntu</span>$ apt-get install libmysqlclient-dev libpq-dev unixodbc-dev</span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="ex">ubuntu</span>$ apt-get install libmariadb-client-lgpl-dev-compat</span>
<span id="cb9-3"><a href="#cb9-3"></a></span>
<span id="cb9-4"><a href="#cb9-4"></a><span class="ex">centos</span>$ yum install mariadb-devel postgresql-devel unixODBC-devel</span></code></pre></div>
<p>Why might these be needed, and how they work?</p>
<p><code>indexer</code> natively supports MySQL (or MariaDB), PostgreSQL, and UnixODBC drivers. Meaning it can natively connect to those databases, run SQL queries, extract results, and create full-text indexes from that. Binaries now always come with that <em>support</em> enabled.</p>
<p>However, you still need to have a specific driver <em>library</em> installed on your system, so that <code>indexer</code> could dynamically load it, and access the database. Depending on the specific database and OS you use, the package names might be different, but here go a few common pointers.</p>
<p>The driver libraries are loaded by name. The following names are attempted:</p>
<ul>
<li>MySQL: <code>libmysqlclient.so</code> or <code>libmariadb.so</code></li>
<li>PostgreSQL: <code>libpq.so</code></li>
<li>ODBC: <code>libodbc.so</code></li>
</ul>
<p>To support MacOS, <code>.dylib</code> extension (in addition to <code>.so</code>) is also tried.</p>
<h2 id="main-concepts">Main concepts</h2>
<p>Alas, many projects tend to reinvent their own dictionary, and Sphinx is no exception. Sometimes that probably creates confusion for no apparent reason. For one, what SQL guys call “tables” (or even “relations” if they are old enough to remember Edgar Codd), and MongoDB guys call “collections”, we the text search guys tend to call “indexes”, and not really out of mischief and malice either, but just because for us, those things <em>are</em> primarily FT (full-text) indexes. Thankfully, most of the concepts are close enough, so our personal little Sphinx dictionary is tiny. Let’s see.</p>
<p>Short cheat sheet!</p>
<table>
<thead>
<tr class="header">
<th>Sphinx</th>
<th>Closest SQL equivalent</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Index</td>
<td>Table</td>
</tr>
<tr class="even">
<td>Document</td>
<td>Row</td>
</tr>
<tr class="odd">
<td>Field or attribute</td>
<td>Column and/or a FULLTEXT index</td>
</tr>
<tr class="even">
<td>Indexed field</td>
<td><em>Just</em> a FULLTEXT index on a text column</td>
</tr>
<tr class="odd">
<td>Stored field</td>
<td>Text column <em>and</em> a FULLTEXT index on it</td>
</tr>
<tr class="even">
<td>Attribute</td>
<td>Column</td>
</tr>
<tr class="odd">
<td>MVA</td>
<td>Column with an INT_SET type</td>
</tr>
<tr class="even">
<td>JSON attribute</td>
<td>Column with a JSON type</td>
</tr>
<tr class="odd">
<td>Attribute index</td>
<td>Index</td>
</tr>
<tr class="even">
<td>Document ID, docid</td>
<td>Column called “id”, with a BIGINT type</td>
</tr>
<tr class="odd">
<td>Row ID, rowid</td>
<td>Internal Sphinx row number</td>
</tr>
</tbody>
</table>
<p>And now for a little more elaborate explanation.</p>
<h3 id="indexes">Indexes</h3>
<p>Sphinx indexes are semi-structured collections of documents. They may seem closer to SQL tables than to Mongo collections, but in their core, they really are neither. The primary, foundational data structure here is a <em>full-text index</em>. It is a special structure that lets us respond very quickly to a query like “give me the (internal) identifiers of all the documents that mention This or That keyword”. And everything else (any extra attributes, or document storage, or even the SQL or HTTP querying dialects, and so on) that Sphinx provides is essentially some kind of an addition on top of that base data structure. Well, hence the “index” name.</p>
<p>Schema-wise, Sphinx indexes try to combine the best of schemaful and schemaless worlds. For “columns” where you know the type upfront, you can use the statically typed attributes, and get the absolute efficiency. For more dynamic data, you can put it all into a JSON attribute, and still get quite decent performance.</p>
<p>So in a sense, Sphinx indexes == SQL tables, except (a) full-text searches are fast and come with a lot of full-text-search specific tweaking options; (b) JSON “columns” (attributes) are quite natively supported, so you can go schemaless; and (c) for full-text indexed fields, you can choose to store <em>just</em> the full-text index and ditch the original values.</p>
<h3 id="documents">Documents</h3>
<p>Documents are essentially just a list of named text fields, and arbitrary-typed attributes. Quite similar to SQL rows; almost indistiguishable, actually.</p>
<p>As of v.3.0.1, Sphinx still requires a unique <code>id</code> attribute, and implicitly injects an <code>id BIGINT</code> column into indexes (as you probably noticed in the <a href="#getting-started">Getting started</a> section). We still use those docids to identify specific rows in <code>DELETE</code> and other statements. However, unlike in v.2.x, we no longer use docids to identify documents internally. Thus, zero and negative docids are already allowed.</p>
<h3 id="fields">Fields</h3>
<p>Fields are the texts that Sphinx indexes and makes keyword-searchable. They always are <em>indexed</em>, as in full-text indexed. Their original, unindexed contents can also be <em>stored</em> into the index for later retrieval. By default, they are not, and Sphinx is going to return attributes only, and <em>not</em> the contents. However, if you explicitly mark them as stored (either with a <code>stored</code> flag in <code>CREATE TABLE</code> or in the ETL config file using <code>stored_fields</code> directive), you can also fetch the fields back:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb10-1"><a href="#cb10-1"></a>mysql<span class="op">&gt;</span> <span class="kw">CREATE</span> <span class="kw">TABLE</span> test1 (title field);</span>
<span id="cb10-2"><a href="#cb10-2"></a>mysql<span class="op">&gt;</span> <span class="kw">INSERT</span> <span class="kw">INTO</span> test1 <span class="kw">VALUES</span> (<span class="dv">123</span>, <span class="st">&#39;hello&#39;</span>);</span>
<span id="cb10-3"><a href="#cb10-3"></a>mysql<span class="op">&gt;</span> <span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> test1 <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello&#39;</span>);</span>
<span id="cb10-4"><a href="#cb10-4"></a><span class="op">+</span><span class="co">------+</span></span>
<span id="cb10-5"><a href="#cb10-5"></a>| <span class="kw">id</span>   |</span>
<span id="cb10-6"><a href="#cb10-6"></a><span class="op">+</span><span class="co">------+</span></span>
<span id="cb10-7"><a href="#cb10-7"></a>|  <span class="dv">123</span> |</span>
<span id="cb10-8"><a href="#cb10-8"></a><span class="op">+</span><span class="co">------+</span></span>
<span id="cb10-9"><a href="#cb10-9"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span>
<span id="cb10-10"><a href="#cb10-10"></a></span>
<span id="cb10-11"><a href="#cb10-11"></a>mysql<span class="op">&gt;</span> <span class="kw">CREATE</span> <span class="kw">TABLE</span> test2 (title field stored);</span>
<span id="cb10-12"><a href="#cb10-12"></a>mysql<span class="op">&gt;</span> <span class="kw">INSERT</span> <span class="kw">INTO</span> test2 <span class="kw">VALUES</span> (<span class="dv">123</span>, <span class="st">&#39;hello&#39;</span>);</span>
<span id="cb10-13"><a href="#cb10-13"></a>mysql<span class="op">&gt;</span> <span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> test2 <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello&#39;</span>);</span>
<span id="cb10-14"><a href="#cb10-14"></a><span class="op">+</span><span class="co">------+-------+</span></span>
<span id="cb10-15"><a href="#cb10-15"></a>| <span class="kw">id</span>   | title |</span>
<span id="cb10-16"><a href="#cb10-16"></a><span class="op">+</span><span class="co">------+-------+</span></span>
<span id="cb10-17"><a href="#cb10-17"></a>|  <span class="dv">123</span> | hello |</span>
<span id="cb10-18"><a href="#cb10-18"></a><span class="op">+</span><span class="co">------+-------+</span></span>
<span id="cb10-19"><a href="#cb10-19"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>Stored fields contents are stored in a special index component called document storage, or DocStore for short.</p>
<h3 id="attributes">Attributes</h3>
<p>Sphinx supports the following attribute types:</p>
<ul>
<li>UINT, unsigned 32-bit integer</li>
<li>BIGINT, signed 64-bit integer</li>
<li>FLOAT, 32-bit (single precision) floating point</li>
<li>BOOL, 1-bit boolean</li>
<li>STRING, a text string</li>
<li>JSON, a JSON document</li>
<li>MVA, an order-insensitive set of unique INTEGERs</li>
<li>MVA64, an order-insensitive set of unique BIGINTs</li>
</ul>
<p>All of these should be pretty straightforward. However, there are a couple Sphinx specific JSON performance tricks worth mentioning:</p>
<ul>
<li>All scalar values (integers, floats, doubles) are converted and internally stored natively.</li>
<li>All scalar value <em>arrays</em> are detected and also internally stored natively.</li>
<li>You can use <code>123.45f</code> syntax extension to mark 32-bit floats (by default all floating point values in JSON are 64-bit doubles).</li>
</ul>
<p>For example, when the following document is stored into a JSON column in Sphinx:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb11-1"><a href="#cb11-1"></a><span class="fu">{</span><span class="dt">&quot;title&quot;</span><span class="fu">:</span><span class="st">&quot;test&quot;</span><span class="fu">,</span> <span class="dt">&quot;year&quot;</span><span class="fu">:</span><span class="dv">2017</span><span class="fu">,</span> <span class="dt">&quot;tags&quot;</span><span class="fu">:</span><span class="ot">[</span><span class="dv">13</span><span class="ot">,</span><span class="dv">8</span><span class="ot">,</span><span class="dv">5</span><span class="ot">,</span><span class="dv">1</span><span class="ot">,</span><span class="dv">2</span><span class="ot">,</span><span class="dv">3</span><span class="ot">]</span><span class="fu">}</span></span></code></pre></div>
<p>Sphinx detects that the “tags” array consists of integers only, and stores the array data using 24 bytes exactly, using just 4 bytes per each of the 6 values. Of course, there still are the overheads of storing the JSON keys, and the general document structure, so the <em>entire</em> document will take more than that. Still, when it comes to storing bulk data into Sphinx index for later use, just provide a consistently typed JSON array, and that data will be stored - and processed! - with maximum efficiency.</p>
<p>Attributes are supposed to fit into RAM, and Sphinx is optimized towards that case. Ideally, of course, all your index data should fit into RAM, while being backed by a fast enough SSD for persistence.</p>
<p>Now, there are <em>fixed-width</em> and <em>variable-width</em> attributes among the supported types. Naturally, scalars like <code>UINT</code> and <code>FLOAT</code> will always occupy exactly 4 bytes each, while <code>STRING</code> and <code>JSON</code> types can be as short as, well, empty; or as long as several megabytes. How does that work internally? Or in other words, why don’t I just save everything as JSON?</p>
<p>The answer is performance. Internally, Sphinx has two separate storages for those row parts. Fixed-width attributes, including hidden system ones, are essentially stored in big static NxM matrix, where N is the number of rows, and M is the number of fixed-width attributes. Any accesses to those are very quick. All the variable-width attributes for a single row are grouped together, and stored in a separate storage. A single offset into that second storage (or “vrow” storage, short for “variable-width row part” storage) is stored as hidden fixed-width attribute. Thus, as you see, accessing a string or a JSON or an MVA value, let alone a JSON key, is somewhat more complicated. For example, to access that <code>year</code> JSON key from the example just above, Sphinx would need to:</p>
<ul>
<li>read <code>vrow_offset</code> from a hidden attribute</li>
<li>access the vrow part using that offset</li>
<li>decode the vrow, and find the needed JSON attribute start</li>
<li>decode the JSON, and find the <code>year</code> key start</li>
<li>check the key type, just in case it needs conversion to integer</li>
<li>finally, read the <code>year</code> value</li>
</ul>
<p>Of course, optimizations are done on every step here, but still, if you access a <em>lot</em> of those values (for sorting or filtering the query results), there will be a performance impact. Also, the deeper the key is buried into that JSON, the worse. For example, using a tiny test with 1,000,000 rows and just 4 integer attributes plus exactly the same 4 values stored in a JSON, computing a sum yields the following:</p>
<table>
<thead>
<tr class="header">
<th>Attribute</th>
<th>Time</th>
<th>Slowdown</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Any UINT</td>
<td>0.032 sec</td>
<td>-</td>
</tr>
<tr class="even">
<td>1st JSON key</td>
<td>0.045 sec</td>
<td>1.4x</td>
</tr>
<tr class="odd">
<td>2nd JSON key</td>
<td>0.052 sec</td>
<td>1.6x</td>
</tr>
<tr class="even">
<td>3rd JSON key</td>
<td>0.059 sec</td>
<td>1.8x</td>
</tr>
<tr class="odd">
<td>4th JSON key</td>
<td>0.065 sec</td>
<td>2.0x</td>
</tr>
</tbody>
</table>
<p>And with more attributes it would eventually slowdown even worse than 2x times, especially if we also throw in more complicated attributes, like strings or nested objects.</p>
<p>So bottom line, why not JSON everything? As long as your queries only touch a handful of rows each, that is fine, actually! However, if you have a <em>lot</em> of data, you should try to identify some of the “busiest” columns for your queries, and store them as “regular” typed columns, that somewhat improves performance.</p>
<h2 id="using-docstore">Using DocStore</h2>
<p>Storing fields into your indexes is easy, just list those fields in a <code>stored_fields</code> directive and you’re all set:</p>
<pre><code>index mytest
{
    type = rt
    path = data/mytest

    rt_field = title
    rt_field = content
    stored_fields = title, content
    # hl_fields = title, content

    rt_attr_uint = gid
}</code></pre>
<p>Let’s check how that worked:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb13-1"><a href="#cb13-1"></a>mysql<span class="op">&gt;</span> <span class="kw">desc</span> mytest;</span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="op">+</span><span class="co">---------+--------+-----------------+------+</span></span>
<span id="cb13-3"><a href="#cb13-3"></a>| Field   | <span class="kw">Type</span>   | Properties      | <span class="kw">Key</span>  |</span>
<span id="cb13-4"><a href="#cb13-4"></a><span class="op">+</span><span class="co">---------+--------+-----------------+------+</span></span>
<span id="cb13-5"><a href="#cb13-5"></a>| <span class="kw">id</span>      | bigint |                 |      |</span>
<span id="cb13-6"><a href="#cb13-6"></a>| title   | field  | <span class="kw">indexed</span>, stored |      |</span>
<span id="cb13-7"><a href="#cb13-7"></a>| content | field  | <span class="kw">indexed</span>, stored |      |</span>
<span id="cb13-8"><a href="#cb13-8"></a>| gid     | uint   |                 |      |</span>
<span id="cb13-9"><a href="#cb13-9"></a><span class="op">+</span><span class="co">---------+--------+-----------------+------+</span></span>
<span id="cb13-10"><a href="#cb13-10"></a><span class="dv">4</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span>
<span id="cb13-11"><a href="#cb13-11"></a></span>
<span id="cb13-12"><a href="#cb13-12"></a>mysql<span class="op">&gt;</span> <span class="kw">insert</span> <span class="kw">into</span> mytest (<span class="kw">id</span>, title) <span class="kw">values</span> (<span class="dv">123</span>, <span class="st">&#39;hello world&#39;</span>);</span>
<span id="cb13-13"><a href="#cb13-13"></a><span class="kw">Query</span> OK, <span class="dv">1</span> <span class="kw">row</span> affected (<span class="fl">0.00</span> sec)</span>
<span id="cb13-14"><a href="#cb13-14"></a></span>
<span id="cb13-15"><a href="#cb13-15"></a>mysql<span class="op">&gt;</span> <span class="kw">select</span> <span class="op">*</span> <span class="kw">from</span> mytest <span class="kw">where</span> match(<span class="st">&#39;hello&#39;</span>);</span>
<span id="cb13-16"><a href="#cb13-16"></a><span class="op">+</span><span class="co">------+------+-------------+---------+</span></span>
<span id="cb13-17"><a href="#cb13-17"></a>| <span class="kw">id</span>   | gid  | title       | content |</span>
<span id="cb13-18"><a href="#cb13-18"></a><span class="op">+</span><span class="co">------+------+-------------+---------+</span></span>
<span id="cb13-19"><a href="#cb13-19"></a>|  <span class="dv">123</span> |    <span class="dv">0</span> | hello world |         |</span>
<span id="cb13-20"><a href="#cb13-20"></a><span class="op">+</span><span class="co">------+------+-------------+---------+</span></span>
<span id="cb13-21"><a href="#cb13-21"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>Yay, original document contents! Not a huge step generally, not for a database anyway; but a nice improvement for Sphinx which was initially designed “for searching only” (oh, the mistakes of youth). And DocStore can do more than that, namely:</p>
<ul>
<li>store indexed fields, <code>store_fields</code> directive</li>
<li>store unindexed fields, <code>stored_only_fields</code> directive</li>
<li>store precomputed data to speedup snippets, <code>hl_fields</code> directive</li>
<li>be fine-tuned a little, using <code>docstore_type</code>, <code>docstore_comp</code>, and <code>docstore_block</code> directives</li>
</ul>
<p>So DocStore can effectively replace the existing <code>rt_attr_string</code> directive. What are the differences, and when to use each?</p>
<p><code>rt_attr_string</code> creates an <em>attribute</em>, uncompressed, and stored in RAM. Attributes are supposed to be small, and suitable for filtering (WHERE), sorting (ORDER BY), and other operations like that, by the millions. So if you really need to run queries like … WHERE title=‘abc’, or in case you want to update those strings on the fly, you will still need attributes.</p>
<p>But complete original document contents are rather rarely accessed in <em>that</em> way! Instead, you usually need just a handful of those, in the order of 10s to 100s, to have them displayed in the final search results, and/or create snippets. DocStore is designed exactly for that. It compresses all the data it receives (by default), and tries to keep most of the resulting “archive” on disk, only fetching a few documents at a time, in the very end.</p>
<p>Snippets become pretty interesting with DocStore. You can generate snippets from either specific stored fields, or the entire document, or a subdocument, respectively:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb14-1"><a href="#cb14-1"></a><span class="kw">SELECT</span> <span class="kw">id</span>, SNIPPET(title, <span class="kw">QUERY</span>()) <span class="kw">FROM</span> mytest <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello&#39;</span>)</span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="kw">SELECT</span> <span class="kw">id</span>, SNIPPET(DOCUMENT(), <span class="kw">QUERY</span>()) <span class="kw">FROM</span> mytest <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello&#39;</span>)</span>
<span id="cb14-3"><a href="#cb14-3"></a><span class="kw">SELECT</span> <span class="kw">id</span>, SNIPPET(DOCUMENT({title}), <span class="kw">QUERY</span>()) <span class="kw">FROM</span> mytest <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello&#39;</span>)</span></code></pre></div>
<p>Using <code>hl_fields</code> can accelerate highlighting where possible, sometimes making snippets <em>times</em> faster. If your documents are big enough (as in, a little bigger than tweets), try it! Without <code>hl_fields</code>, SNIPPET() function will have to reparse the document contents every time. With it, the parsed representation is compressed and stored into the index upfront, trading off a not-insignificant amount of CPU work for more disk space, and a few extra disk reads.</p>
<p>And speaking of disk space vs CPU tradeoff, these tweaking knobs let you fine-tune DocStore for specific indexes:</p>
<ul>
<li><code>docstore_type = vblock_solid</code> (default) groups small documents into a single compressed block, upto a given limit: better compression, slower access</li>
<li><code>docstore_type = vblock</code> stores every document separately: worse compression, faster access</li>
<li><code>docstore_block = 16k</code> (default) lets you tweak the block size limit</li>
<li><code>docstore_comp = lz4hc</code> (default) uses LZ4HC algorithm for compression: better compression, but slower</li>
<li><code>docstore_comp = lz4</code> uses LZ4 algorithm: worse compression, but faster</li>
<li><code>docstore_comp = none</code> disables compression</li>
</ul>
<h2 id="using-attribute-indexes">Using attribute indexes</h2>
<p>Quick kickoff: we now have <a href="#create-index-syntax"><code>CREATE INDEX</code> statement</a> which lets you create secondary indexes, and sometimes (or most of times even?!) it <em>does</em> make your queries faster!</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb15-1"><a href="#cb15-1"></a><span class="kw">CREATE</span> <span class="kw">INDEX</span> i1 <span class="kw">ON</span> mytest(<span class="fu">group_id</span>)</span>
<span id="cb15-2"><a href="#cb15-2"></a><span class="kw">DESC</span> mytest</span>
<span id="cb15-3"><a href="#cb15-3"></a><span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> mytest <span class="kw">WHERE</span> <span class="fu">group_id</span><span class="op">=</span><span class="dv">1</span></span>
<span id="cb15-4"><a href="#cb15-4"></a><span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> mytest <span class="kw">WHERE</span> <span class="fu">group_id</span> <span class="kw">BETWEEN</span> <span class="dv">10</span> <span class="kw">and</span> <span class="dv">20</span></span>
<span id="cb15-5"><a href="#cb15-5"></a><span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> mytest <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello world&#39;</span>) <span class="kw">AND</span> <span class="fu">group_id</span><span class="op">=</span><span class="dv">23</span></span>
<span id="cb15-6"><a href="#cb15-6"></a><span class="kw">DROP</span> <span class="kw">INDEX</span> i1 <span class="kw">ON</span> mytest</span></code></pre></div>
<p>Point reads, range reads, and intersections between <code>MATCH()</code> and index reads are all intended to work. Moreover, <code>GEODIST()</code> can also automatically use indexes (see more below). One of the goals is to completely eliminate the need to insert “fake keywords” into your index. (Also, it’s possible to <em>update</em> attribute indexes on the fly, as opposed to indexed text.)</p>
<p>Indexes on JSON keys should also work, but you might need to cast them to a specific type when creating the index:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb16-1"><a href="#cb16-1"></a><span class="kw">CREATE</span> <span class="kw">INDEX</span> j1 <span class="kw">ON</span> mytest(j.<span class="fu">group_id</span>)</span>
<span id="cb16-2"><a href="#cb16-2"></a><span class="kw">CREATE</span> <span class="kw">INDEX</span> j2 <span class="kw">ON</span> mytest(UINT(j.<span class="dt">year</span>))</span>
<span id="cb16-3"><a href="#cb16-3"></a><span class="kw">CREATE</span> <span class="kw">INDEX</span> j3 <span class="kw">ON</span> mytest(<span class="dt">FLOAT</span>(j.latitude))</span></code></pre></div>
<p>The first statement (the one with <code>j1</code> and without an explicit type cast) will default to <code>UINT</code> and emit a warning. In the future, this warning might get promoted to a hard error. Why?</p>
<p>The attribute index <em>must</em> know upfront what value type it indexes. At the same time the engine can not assume any type for a JSON field, because hey, JSON! Might not even <em>be</em> a single type across the entire field, might even change row to row, which is perfectly legal. So the burden of casting your JSON fields to a specific indexable type lies with you, the user.</p>
<p>Indexes on MVA (ie. sets of <code>UINT</code> or <code>BIGINT</code>) should also work:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb17-1"><a href="#cb17-1"></a><span class="kw">CREATE</span> <span class="kw">INDEX</span> tags <span class="kw">ON</span> mytest(tags)</span></code></pre></div>
<p>Note that indexes over MVA can only currently improve performance on either <code>WHERE ANY(mva) = ?</code> or <code>WHERE ANY(mva) IN (?, ?, ...)</code> types of queries. For “rare enough” reference values we can read the final matching rows from the index; that is usually quicker than scanning all rows; and for “too frequent” values query optimizer will fall back to scanning. Everything as expected.</p>
<p>However, beware that in <code>ALL(mva)</code> case index will not be used yet! Because even though technically we could read <em>candidate</em> rows (the very same ones as in <code>ANY(mva)</code> cases), and scanning <em>just</em> the candidates could very well be still quicker that a full scan, there are internal architecural issues that make such an implementation much more complicated. Given that we also usually see just the <code>ANY(mva)</code> queries in production, we postponed the <code>ALL(mva)</code> optimizations. Those might come in a future release.</p>
<p>Here’s an example where we create an index and speed up <code>ANY(mva)</code> query from 100 msec to under 1 msec, while <code>ALL(mva)</code> query still takes 57 msec.</p>
<pre><code>mysql&gt; select id, tags from t1 where any(tags)=1838227504 limit 1;
+------+--------------------+
| id   | tags               |
+------+--------------------+
|   15 | 1106984,1838227504 |
+------+--------------------+
1 row in set (0.10 sec)

mysql&gt; create index tags on t1(tags);
Query OK, 0 rows affected (4.66 sec)

mysql&gt; select id, tags from t1 where any(tags)=1838227504 limit 1;
+------+--------------------+
| id   | tags               |
+------+--------------------+
|   15 | 1106984,1838227504 |
+------+--------------------+
1 row in set (0.00 sec)

mysql&gt; select id, tags from t1 where all(tags)=1838227504 limit 1;
Empty set (0.06 sec)</code></pre>
<p>For the record, <code>t1</code> test collection had 5 million rows and 10 million <code>tags</code> values, meaning that <code>CREATE INDEX</code> which completed in 4.66 seconds was going at ~1.07M rows/sec (and ~2.14M values/sec) indexing rate in this example. In other words: creating an index is usually fast.</p>
<p>As of v.3.0, attribute indexes can only be created on RT indexes. However, you can (almost) <em>instantly</em> convert your plain indexes to RT by using <code>ATTACH ... WITH TRUNCATE</code>, and run <code>CREATE INDEX</code> after that, as follows:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb19-1"><a href="#cb19-1"></a>ATTACH <span class="kw">INDEX</span> myplain <span class="kw">TO</span> myrt <span class="kw">WITH</span> <span class="kw">TRUNCATE</span></span>
<span id="cb19-2"><a href="#cb19-2"></a><span class="kw">CREATE</span> <span class="kw">INDEX</span> date_added <span class="kw">ON</span> myrt(date_added)</span></code></pre></div>
<p>Geosearches with <code>GEODIST()</code> can also benefit quite a lot from attribute indexes. They can automatically compute a bounding box (or boxes) around a static reference point, and then process only a fraction of data using index reads. Refer to <a href="#searching-geosearches">Geosearches section</a> for more details.</p>
<h3 id="query-optimizer-and-index-hints">Query optimizer, and index hints</h3>
<p>Query optimizer is the mechanism that decides, on a per-query basis, whether to use or to ignore specific indexes to compute the current query.</p>
<p>The optimizer can usually choose any combination of any applicable indexes. The specific index combination gets chosen based on cost estimates. Curiously, that choice is not exactly completely obvious even when we have just 2 indexes.</p>
<p>For instance, assume that we are doing a geosearch, something like this:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb20-1"><a href="#cb20-1"></a><span class="kw">SELECT</span> <span class="op">..</span>. <span class="kw">FROM</span> test1</span>
<span id="cb20-2"><a href="#cb20-2"></a><span class="kw">WHERE</span> (lat <span class="kw">BETWEEN</span> <span class="fl">53.23</span> <span class="kw">AND</span> <span class="fl">53.42</span>) <span class="kw">AND</span> (lon <span class="kw">BETWEEN</span> <span class="op">-</span><span class="fl">6.45</span> <span class="kw">AND</span> <span class="op">-</span><span class="fl">6.05</span>)</span></code></pre></div>
<p>Assume that we have indexes on both <code>lat</code> and <code>lon</code> columns, and can use them. More, we can get an exact final result set out of that index pair, without any extra checks needed. But should we? Instead of using both indexes it is actually sometimes more efficient to use just one! Because with 2 indexes, we have to:</p>
<ol type="1">
<li>Perform <code>lat</code> range index read, get X <code>lat</code> candidate rowids</li>
<li>Perform <code>lon</code> range index read, get Y <code>lon</code> candidate rowids</li>
<li>Intersect X and Y rowids, get N matching rowids</li>
<li>Lookup N resulting rows</li>
<li>Process N resulting rows</li>
</ol>
<p>While when using 1 index on <code>lat</code> we only have to:</p>
<ol type="1">
<li>Perform <code>lat</code> range index read, get X <code>lat</code> candidate rowids</li>
<li>Lookup X candidate rows</li>
<li>Perform X checks for <code>lon</code> range, get N matching rows</li>
<li>Process N resulting rows</li>
</ol>
<p>Now, <code>lat</code> and <code>lon</code> frequently are somewhat correlated. Meaning that X, Y, and N values can all be pretty close. For example, let’s assume we have 11K matches in that specific latitude range, 12K matches in longitude range, and 10K final matches, ie. <code>X = 11000, Y = 12000, N = 10000</code>. Then using just 1 index means that we can avoid reading 12K <code>lat</code> rowids and then intersecting 23K rowids, introducing, however, 2K extra row lookups and 12K <code>lon</code> checks instead. Guess what, row lookups and extra checks are actually cheaper operations, and we are doing less of them. So with a few quick estimates, using only 1 index out of 2 applicable ones suddenly looks like a better bet. That can be indeed confirm on real queries, too.</p>
<p>And that’s exactly how the optimizer works. Basically, it checks multiple possible index combinations, tries to estimate the associated query costs, and then picks the best one it finds.</p>
<p>However, the number of possible combinations grows explosively with the attribute index count. Consider a rather crazy (but possible) case with as many as 20 applicable indexes. That means more than 1 million possible “on/off” combinations. Even quick estimates for <em>all</em> of them would take too much time. There are internal limits in the optimizer to prevent that. Which in turn means that eventually some “ideal” index set might not get selected. (But, of course, that is a rare situation. Normally there are just a few applicable indexes, say from 1 to 10, so the optimizer can afford “brute forcing” upto 1024 possible index combinations, and does so.)</p>
<p>Now, perhaps even worse, both the count and cost estimates are just that, ie. only estimates. They might be slightly off, or way off. The actual query costs might be somewhat different than estimated when we execute the query.</p>
<p>For those reasons, optimizer might occasionally pick a suboptimal query plan. In that event, or perhaps just for testing purposes, you can tweak its behavior with <code>SELECT</code> hints, and make it forcibly use or ignore specific attribute indexes. For a reference on the exact syntax and behavior, refer to <a href="#index-hints-clause">“Index hints clause”</a>.</p>
<h3 id="create-and-drop-index-performance">CREATE and DROP index performance</h3>
<p>DISCLAIMER: your mileage may vary <em>enormously</em> here, because there are many contributing factors. Still, we decided to provide at least <em>some</em> performance datapoints.</p>
<p>Core count is not a factor because index creation and removal are both single-threaded in v.3.4 that we used for these benchmarks.</p>
<p><strong>Scenario 1</strong>, index with ~38M rows, ~20 columns, taking ~13 GB total. Desktop with 3.7 GHz CPU, 32 GB RAM, SATA3 SSD.</p>
<p><code>CREATE INDEX</code> on an <code>UINT</code> column with a few (under 1000) distinct values took around 4-5 sec; on a pretty unique <code>BIGINT</code> column with ~10M different values it took 26-27 sec.</p>
<p><code>DROP INDEX</code> took 0.1-0.3 sec.</p>
<h2 id="using-k-batches">Using k-batches</h2>
<p>K-batches (“kill batches”) let you bulk delete older versions of the documents (rows) when bulk loading new data into Sphinx, for example, adding a new delta index on top of an older main archive index.</p>
<p>K-batches in Sphinx v.3.x replace k-lists (“kill lists”) from v.2.x and before. The major differences are that:</p>
<ol type="1">
<li>They are <em>not</em> anonymous anymore.</li>
<li>They are now only applied once on loading. (As oppposed to every search, yuck).</li>
</ol>
<p>“Not anonymous” means that when loading a new index with an associated k-batch into <code>searchd</code>, <strong>you now have to explicitly specify target indexes</strong> that it should delete the rows from. In other words, “deltas” now <em>must</em> explicitly specify all the “main” indexes that they want to erase old documents from, at index-time.</p>
<p>The effect of applying a k-batch is equivalent to running (just once) a bunch of <code>DELETE FROM X WHERE id=Y</code> queries, for every index X listed in <code>kbatch</code> directive, and every document id Y stored in the k-batch. With the index format updates this is now both possible, <strong>even in “plain” indexes</strong>, and quite efficient too.</p>
<p>K-batch only gets applied once. After a succesful application to all the target indexes, the batch gets cleared.</p>
<p>So, for example, when you load an index called <code>delta</code> with the following settings:</p>
<pre><code>index delta
{
    ...
    sql_query_kbatch = SELECT 12 UNION SELECT 13 UNION SELECT 14
    kbatch = main1, main2
}</code></pre>
<p>The following (normally) happens:</p>
<ul>
<li><code>delta</code> kbatch file is loaded
<ul>
<li>in this example it will have 3 document ids: 12, 13, and 14</li>
</ul></li>
<li>documents with those ids are deleted from <code>main1</code></li>
<li>documents with those ids are deleted from <code>main2</code></li>
<li><code>main1</code>, <code>main2</code> save those deletions to disk</li>
<li>if all went well, <code>delta</code> kbatch file is cleared</li>
</ul>
<p>All these operations are pretty fast, because deletions are now internally implemented using a bitmap. So deleting a given document by id results in a hash lookup and a bit flip. In plain speak, very quick.</p>
<p>“Loading” can happen either by restarting or rotation or whatever, k-batches should still try to apply themselves.</p>
<p>Last but not least, you can also use <code>kbatch_source</code> to avoid explicitly storing all newly added document ids into a k-batch, instead, you can use <code>kbatch_source = kl, id</code> or just <code>kbatch_source = id</code>; this will automatically add all the document ids from the index to its k-batch. The default value is <code>kbatch_source = kl</code>, that is, to use explicitly provided docids only.</p>
<h2 id="doing-bulk-data-loads">Doing bulk data loads</h2>
<p>TODO: describe rotations (legacy), RELOAD, ATTACH, etc.</p>
<h2 id="using-json">Using JSON</h2>
<p>For the most part using JSON in Sphinx should be very simple. You just put pretty much arbitrary JSON in a proper column (aka attribute). Then you just access the necessary keys using a <code>col1.key1.subkey2.subkey3</code> syntax. Or, you access the array values using <code>col1.key1[123]</code> syntax. And that’s it.</p>
<p>For a literally 30-second kickoff, you can configure a test RT index like this:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb22-1"><a href="#cb22-1"></a><span class="ex">index</span> jsontest</span>
<span id="cb22-2"><a href="#cb22-2"></a><span class="kw">{</span></span>
<span id="cb22-3"><a href="#cb22-3"></a>    <span class="bu">type</span> = rt</span>
<span id="cb22-4"><a href="#cb22-4"></a>    <span class="ex">path</span> = data/jsontest</span>
<span id="cb22-5"><a href="#cb22-5"></a>    <span class="ex">rt_field</span> = title</span>
<span id="cb22-6"><a href="#cb22-6"></a>    <span class="ex">rt_attr_json</span> = j</span>
<span id="cb22-7"><a href="#cb22-7"></a><span class="kw">}</span></span></code></pre></div>
<p>Then restart or <code>searchd</code> or reload the config, and fire away a few test queries:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb23-1"><a href="#cb23-1"></a>mysql<span class="op">&gt;</span> <span class="kw">INSERT</span> <span class="kw">INTO</span> jsontest (<span class="kw">id</span>, j) <span class="kw">VALUES</span> (<span class="dv">1</span>, <span class="st">&#39;{&quot;foo&quot;:&quot;bar&quot;, &quot;year&quot;:2019,</span></span>
<span id="cb23-2"><a href="#cb23-2"></a><span class="st">  &quot;arr&quot;:[1,2,3,&quot;yarr&quot;], &quot;address&quot;:{&quot;city&quot;:&quot;Moscow&quot;, &quot;country&quot;:&quot;Russia&quot;}}&#39;</span>);</span>
<span id="cb23-3"><a href="#cb23-3"></a><span class="kw">Query</span> OK, <span class="dv">1</span> <span class="kw">row</span> affected (<span class="fl">0.00</span> sec)</span>
<span id="cb23-4"><a href="#cb23-4"></a></span>
<span id="cb23-5"><a href="#cb23-5"></a>mysql<span class="op">&gt;</span> <span class="kw">SELECT</span> j.foo <span class="kw">FROM</span> jsontest;</span>
<span id="cb23-6"><a href="#cb23-6"></a><span class="op">+</span><span class="co">-------+</span></span>
<span id="cb23-7"><a href="#cb23-7"></a>| j.foo |</span>
<span id="cb23-8"><a href="#cb23-8"></a><span class="op">+</span><span class="co">-------+</span></span>
<span id="cb23-9"><a href="#cb23-9"></a>| bar   |</span>
<span id="cb23-10"><a href="#cb23-10"></a><span class="op">+</span><span class="co">-------+</span></span>
<span id="cb23-11"><a href="#cb23-11"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span>
<span id="cb23-12"><a href="#cb23-12"></a></span>
<span id="cb23-13"><a href="#cb23-13"></a>mysql<span class="op">&gt;</span> <span class="kw">SELECT</span> j.<span class="dt">year</span><span class="op">+</span><span class="dv">10</span>, j.arr[<span class="dv">3</span>], j.address.city <span class="kw">FROM</span> jsontest;</span>
<span id="cb23-14"><a href="#cb23-14"></a><span class="op">+</span><span class="co">-----------+----------+----------------+</span></span>
<span id="cb23-15"><a href="#cb23-15"></a>| j.<span class="dt">year</span><span class="op">+</span><span class="dv">10</span> | j.arr[<span class="dv">3</span>] | j.address.city |</span>
<span id="cb23-16"><a href="#cb23-16"></a><span class="op">+</span><span class="co">-----------+----------+----------------+</span></span>
<span id="cb23-17"><a href="#cb23-17"></a>|    <span class="fl">2029.0</span> | yarr     | Moscow         |</span>
<span id="cb23-18"><a href="#cb23-18"></a><span class="op">+</span><span class="co">-----------+----------+----------------+</span></span>
<span id="cb23-19"><a href="#cb23-19"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>However, sometimes that is not quite enough (mostly for performance reasons), and thus we have both several Sphinx-specific <strong>JSON syntax extensions</strong>, and several <strong>important internal implementation details</strong> to discuss, including a few Sphinx-specific limits. Briefly, those are as follows:</p>
<ul>
<li><p>optimized scalar storage (for <code>int8</code>, <code>int32</code>, <code>int64</code>, <code>bool</code>, <code>float</code>, and <code>NULL</code> types)</p></li>
<li><p>optimized array storage (for <code>int8</code>, <code>int32</code>, <code>int64</code>, <code>float</code>, <code>double</code>, and <code>string</code> types)</p></li>
<li><p>optimized key name storage with key compression (optional, with <code>json_packed_keys = 1</code> directive)</p></li>
<li><p><code>0.0f</code> syntax extension for 32-bit float values</p></li>
<li><p><code>int8[]</code> and <code>float[]</code> syntax extensions for 8-bit integer and 32-bit float arrays, respectively</p></li>
</ul>
<p><strong>Optimized storage</strong> means that <em>usually</em> Sphinx auto-detects the actual value types, both for standalone values and for arrays, and then uses the smallest storage type that works.</p>
<p>So when a 32-bit (4-byte) integer is enough for a numeric value, Sphinx would automatically store just that. If that overflows, no need to worry, Sphinx would just automatically switch to 8-byte integer values, or even <code>double</code> values (still 8-byte).</p>
<p>Ditto for arrays. When your arrays contain a mix of actual types, Sphinx handles that just fine, and stores a generic array, where every element has a different type attached to it. However, when your array only actually contains one very specific type (for example, regular 32-bit integers only), Sphinx auto-detects that fact, and stores <em>that</em> array in an optimized manner, using just 4 bytes per value, and skipping the repeated types. All the builtin functions support all such optimized array types, and have a special fast codepath to handle them, in a transparent fashion.</p>
<p>As of v.3.2, array value types that might get optimized that way are <code>int8</code>, <code>int32</code>, <code>int64</code>, <code>float</code>, <code>double</code>, and <code>string</code>. This covers pretty much all the usual numeric types, and therefore all you have to do to ensure that the optimizations kick in is, well, to only use one actual type in your data.</p>
<p>So everything is on autopilot, mostly. However, there are several exceptions to that rule that still require a tiny bit of effort from you!</p>
<p><strong>First, there is a catch with <code>float</code> vs <code>double</code> types.</strong> The default storage type for floating point values in Sphinx is the high-precision, 64-bit <code>double</code> type, just as (kinda) specified by JSON.</p>
<p>So the regular <code>{"scale":1.23}</code> syntax would have Sphinx store an 8-byte <code>double</code> value. However, that just might be overkill precision for some (if not most!) tasks, and to save on storage, you might want to store your values using the 32-bit (4-byte) <code>float</code> type instead.</p>
<p>Unfortunately, at the moment there is no standard way to specify that, and so Sphinx offers a custom extension: attach <code>f</code> suffix to your value, ie. use <code>{"scale":1.23f}</code> syntax instead. That works in Sphinx, and that lets it know that a <code>float</code> type is enough.</p>
<p><strong>Second, <code>int8</code> arrays must be explicit.</strong> Even though Sphinx can auto-detect the fact that all your array values are integers in the -128 to 127 range, and can be stored efficiently using just 1 byte per value, it does <em>not</em> just make that assumption, and uses <code>int32</code> type instead.</p>
<p>And this happens because there is no way for Sphinx to tell by looking at <em>just</em> those values whether you realy wanted an optimized <code>int8</code> vector, or the intent was to just have a placeholder (filled with either <code>0</code>, or <code>-1</code>, or what have you) <code>int32</code> vector for future updates. Given that JSON updates are currently in-place, at this decision point Sphinx chooses to go with the more conservative but flexible route, and store an <code>int32</code> vector even for something that could be store more efficiently like <code>[0, 0, 0, 0]</code>.</p>
<p>To force that vector into super-slim 1-byte values, you <em>have</em> to use a syntax extension, and use <code>int8[0, 0, 0, 0]</code> as your value.</p>
<p><strong>Third, watch out for integer vs float mixes.</strong> The auto-detection happens on a per-value basis. Meaning that an array value like <code>[1, 2, 3.0]</code> will be marked as mixing two different types, <code>int32</code> and <code>double</code>. So neither the <code>int32</code> nor (worse) <code>double</code> array storage optimization can kick in for this particular array.</p>
<p>You can enforce any JSON-standard type on Sphinx here using regular JSON syntax. To store it as integers, you should simply get rid of that pesky dot that triggers doubles, and use <code>[1, 2, 3]</code> syntax. For doubles, on the contrary, the dot should be everywhere, ie. you should use <code>[1.0, 2.0, 3.0]</code> syntax.</p>
<p>Finally, for the non-standard <code>float</code> type extension, you can also use the <code>f</code> suffix, ie. <code>[1.0f, 2.0f, 3.0f]</code> syntax. But that might be inconvenient, so you can also use the <code>float[1, 2, 3.0]</code> syntax instead. Either of these two forms enables Sphinx to auto-convert your vector to nice and fast optimized floats.</p>
<p>That was all about the values though. What about the keys?</p>
<p><strong>Normally, keys are stored as is.</strong> Meaning that if you have a <code>superLongKey</code> in (almost) every single document, that key will be stored as a plain old text string, and repeated as many times as there are documents. And all those repetitions would consume some RAM bytes. Flexible, but not really efficient.</p>
<p>So the rule of thumb is, super-long key names are, well, okay, but not really great. Just as with regular JSON. Of course, for smaller indexes the savings might just be negligible. But for bigger ones, you might want to consider shorter key names.</p>
<p>Or, <strong>packed JSON keys</strong> feature alleviates that automatically. It keeps track of the most frequently mentioned keys, and stores top keys using just 1 byte per key value. You can enable it by setting <code>json_packed_keys = 1</code> flag in your index config (and rebuilding the index where necessary). That way, you can use as long key names as you want, and Sphinx will kinda “zip” the JSON internally.</p>
<p>Beware and benchmark, though, that currently there can occasionally be some associated performance impact here (even though not huge), both at indexing and at search time. (Otherwise, the packing would just be always on!)</p>
<h3 id="json-comparison-quirks">JSON comparison quirks</h3>
<p>Comparisons with JSON can be a little tricky when it comes to value types. Especially the numeric ones, because of all the <code>UINT</code> vs <code>FLOAT</code> vs <code>DOUBLE</code> jazz. (And, mind you, by default the floating-point values will be stored as <code>DOUBLE</code>.) Briefly, beware that:</p>
<ol type="1">
<li><p>String comparisons are strict, and require the string type.</p>
<p>Meaning that <code>WHERE j.str1='abc'</code> check must only pass when <em>all</em> the following conditions are true: 1) <code>str1</code> key exists; 2) <code>str1</code> value type is exactly <code>string</code>; 3) the value matches.</p>
<p>Therefore, for a sudden <em>integer</em> value compared against a string constant, for example, <code>{"str1":123}</code> value against a <code>WHERE j.str1='123'</code> condition, the check will fail. As it should, there are no implicit conversions here.</p></li>
<li><p>Numeric comparisons against integers match any numeric type, not just integers.</p>
<p>Meaning that both <code>{"key1":123}</code> and <code>{"key1":123.0}</code> values must pass the <code>WHERE j.key1=123</code> check. Again, as expected.</p></li>
<li><p>Numeric comparisons against floats <em>forcibly</em> convert double values to (single-precision) floats, and roundoff issues may arise.</p>
<p>Meaning that when you store something like <code>{"key1":123.0000001}</code> into your index, then the <code>WHERE j.key1=123.0</code> check will pass, because roundoff to <code>float</code> looses that fractional part. However, at the same time <code>WHERE j.key1=123</code> check will <em>not</em> pass, because <em>that</em> check will use the original double value and compare it against the integer constant.</p>
<p>This might be a bit confusing, but otherwise (without roundoff) the situation would be arguably worse: in an even more counter-intuitive fashion, <code>{"key1":2.22}</code> does <em>not</em> pass the <code>WHERE j.key1&gt;=2.22</code> check, because the reference constant here is <code>float(2.22)</code>, and then because of rounding, <code>double(2.22) &lt; float(2.22)</code>!</p></li>
</ol>
<p>TODO: describe limits, json_xxx settings, our syntax extensions, etc.</p>
<h2 id="using-array-attributes">Using array attributes</h2>
<p>Array attributes let you save a fixed amount of integer or float values into your index. The supported types are:</p>
<ul>
<li><code>attr_int_array</code> that stores signed 32-bit integers;</li>
<li><code>attr_int8_array</code> that stores signed 8-bit integers (-128 to 127 range);</li>
<li><code>attr_float_array</code> that stores 32-bit floats.</li>
</ul>
<p>To declare an array attribute, use the following syntax:</p>
<p><code>{rt|sql|xmlpipe|csvpipe|tsvpipe}_attr_{int|int8|float}_array = NAME[SIZE]</code></p>
<p>Where <code>NAME</code> is the attribute name, and <code>SIZE</code> is the array size, in elements. For example:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb24-1"><a href="#cb24-1"></a><span class="ex">index</span> rt</span>
<span id="cb24-2"><a href="#cb24-2"></a><span class="kw">{</span></span>
<span id="cb24-3"><a href="#cb24-3"></a>    <span class="bu">type</span> = rt</span>
<span id="cb24-4"><a href="#cb24-4"></a></span>
<span id="cb24-5"><a href="#cb24-5"></a>    <span class="ex">rt_field</span> = title</span>
<span id="cb24-6"><a href="#cb24-6"></a>    <span class="ex">rt_field</span> = content</span>
<span id="cb24-7"><a href="#cb24-7"></a></span>
<span id="cb24-8"><a href="#cb24-8"></a>    <span class="ex">rt_attr_uint</span> = gid <span class="co"># regular attribute</span></span>
<span id="cb24-9"><a href="#cb24-9"></a>    <span class="ex">rt_attr_float_array</span> = vec1[5] <span class="co"># 5D array of floats</span></span>
<span id="cb24-10"><a href="#cb24-10"></a>    <span class="ex">rt_attr_int8_array</span> = vec2[3] <span class="co"># 3D array of small 8-bit integers</span></span>
<span id="cb24-11"><a href="#cb24-11"></a>    <span class="co"># ...</span></span>
<span id="cb24-12"><a href="#cb24-12"></a><span class="kw">}</span></span>
<span id="cb24-13"><a href="#cb24-13"></a></span>
<span id="cb24-14"><a href="#cb24-14"></a><span class="bu">source</span> test1</span>
<span id="cb24-15"><a href="#cb24-15"></a><span class="kw">{</span></span>
<span id="cb24-16"><a href="#cb24-16"></a>    <span class="bu">type</span> = mysql</span>
<span id="cb24-17"><a href="#cb24-17"></a></span>
<span id="cb24-18"><a href="#cb24-18"></a>    <span class="ex">sql_attr_int8_array</span> = vec1[17] <span class="co"># 17D array of small 8-bit integers</span></span>
<span id="cb24-19"><a href="#cb24-19"></a>    <span class="co"># ...</span></span>
<span id="cb24-20"><a href="#cb24-20"></a><span class="kw">}</span></span></code></pre></div>
<p>The array dimensions must be between 2 and 8192, inclusive.</p>
<p>The array gets aligned to the nearest 4 bytes. This means that an <code>int8_array</code> with 17 elements will actually use 20 bytes for storage.</p>
<p>The expected input array value for both <code>INSERT</code> queries and source indexing is either a comma or space-separated string with the values, or an empty string:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb25-1"><a href="#cb25-1"></a><span class="kw">INSERT</span> <span class="kw">INTO</span> rt (<span class="kw">id</span>, vec1) <span class="kw">VALUES</span> (<span class="dv">123</span>, <span class="st">&#39;3.14, -1, 2.718, 2019, 100500&#39;</span>);</span>
<span id="cb25-2"><a href="#cb25-2"></a><span class="kw">INSERT</span> <span class="kw">INTO</span> rt (<span class="kw">id</span>, vec1) <span class="kw">VALUES</span> (<span class="dv">124</span>, <span class="st">&#39;&#39;</span>);</span></code></pre></div>
<p>Empty strings will zero-fill the array. Non-empty strings are subject to strict validation. First, there must be exactly as many values as the array can hold. So you can not store 3 or 7 values into a 5-element array. Second, the value ranges might also be be validated. So you will not be able to store a value of <code>1000</code> into an <code>int8_array</code> because it’s out of -128..127 range.</p>
<p>Attempting to <code>INSERT</code> an invalid array value will fail. For example:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb26-1"><a href="#cb26-1"></a>mysql<span class="op">&gt;</span> <span class="kw">INSERT</span> <span class="kw">INTO</span> rt (<span class="kw">id</span>, vec1) <span class="kw">VALUES</span> (<span class="dv">200</span>, <span class="st">&#39;1 2 3&#39;</span>);</span>
<span id="cb26-2"><a href="#cb26-2"></a>ERROR <span class="dv">1064</span> (<span class="dv">42000</span>): bad <span class="dt">array</span> <span class="fu">value</span></span>
<span id="cb26-3"><a href="#cb26-3"></a></span>
<span id="cb26-4"><a href="#cb26-4"></a>mysql<span class="op">&gt;</span> <span class="kw">INSERT</span> <span class="kw">INTO</span> rt (<span class="kw">id</span>, vec1) <span class="kw">VALUES</span> (<span class="dv">200</span>, <span class="st">&#39;1 2 3 4 5 6&#39;</span>);</span>
<span id="cb26-5"><a href="#cb26-5"></a>ERROR <span class="dv">1064</span> (<span class="dv">42000</span>): bad <span class="dt">array</span> <span class="fu">value</span></span>
<span id="cb26-6"><a href="#cb26-6"></a></span>
<span id="cb26-7"><a href="#cb26-7"></a>mysql<span class="op">&gt;</span> <span class="kw">INSERT</span> <span class="kw">INTO</span> rt (<span class="kw">id</span>, vec2) <span class="kw">VALUES</span> (<span class="dv">200</span>, <span class="st">&#39;0, 1, 2345&#39;</span>);</span>
<span id="cb26-8"><a href="#cb26-8"></a>ERROR <span class="dv">1064</span> (<span class="dv">42000</span>): bad <span class="dt">array</span> <span class="fu">value</span></span></code></pre></div>
<p>However, when batch indexing with <code>indexer</code>, an invalid array value will be reported as a warning, and zero-fill the array, but it will <strong>not</strong> fail the entire indexing batch.</p>
<p>At the moment, the only function that supports arrays is <code>DOT()</code>, so you can compute a dot product between an array and a constant vector:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb27-1"><a href="#cb27-1"></a>mysql<span class="op">&gt;</span> <span class="kw">SELECT</span> <span class="kw">id</span>, DOT(vec1,FVEC(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>)) d <span class="kw">FROM</span> rt;</span>
<span id="cb27-2"><a href="#cb27-2"></a><span class="op">+</span><span class="co">------+--------------+</span></span>
<span id="cb27-3"><a href="#cb27-3"></a>| <span class="kw">id</span>   | d            |</span>
<span id="cb27-4"><a href="#cb27-4"></a><span class="op">+</span><span class="co">------+--------------+</span></span>
<span id="cb27-5"><a href="#cb27-5"></a>|  <span class="dv">123</span> | <span class="fl">510585.28125</span> |</span>
<span id="cb27-6"><a href="#cb27-6"></a>|  <span class="dv">124</span> |            <span class="dv">0</span> |</span>
<span id="cb27-7"><a href="#cb27-7"></a><span class="op">+</span><span class="co">------+--------------+</span></span>
<span id="cb27-8"><a href="#cb27-8"></a><span class="dv">2</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<h2 id="using-mappings">Using mappings</h2>
<p>Mappings are a text processing pipeline part that, basically, lets you map keywords to keywords. They come in several different flavors. Namely, mappings can differ:</p>
<ul>
<li>by term count: either “simple” 1:1, or generic “multiword” M:N;</li>
<li>by text processing stage: either pre-morphology, or post-morphology;</li>
<li>by scope: either global, or document-only.</li>
</ul>
<p>We still differentiate between <strong>1:1 mappings</strong> and <strong>M:N mappings</strong>, because there is one edge case where we have to, see below.</p>
<p><strong>Pre-morphology</strong> and <strong>post-morphology</strong> mappings, or pre-morph and post-morph for short, are applied before and after morphology respectively.</p>
<p><strong>Document-only</strong> mappings only affect documents while indexing, and never affect the queries. As opposed to <strong>global</strong> ones, which affect both documents <em>and</em> queries.</p>
<p>Most combinations of all these flavors work together just fine, but with one exception. <strong>At post-morphology stage, only 1:1 mappings are supported</strong>; mostly for operational reasons. While simply enabling post-morph M:N mappings at the engine level is trivial, carefully handling the edge cases in the engine and managing the mappings afterwards seems hard. Because <em>partial</em> clashes between multiword pre-morph and post-morph mappings are too fragile to configure, too complex to investigate, and most importantly, not even really required for production. All other combinations are supported:</p>
<table>
<thead>
<tr class="header">
<th>Terms</th>
<th>Stage</th>
<th>Scope</th>
<th>Support</th>
<th>New</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1:1</td>
<td>pre-morph</td>
<td>global</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr class="even">
<td>M:N</td>
<td>pre-morph</td>
<td>global</td>
<td>yes</td>
<td>-</td>
</tr>
<tr class="odd">
<td>1:1</td>
<td>pre-morph</td>
<td>doc-only</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr class="even">
<td>M:N</td>
<td>pre-morph</td>
<td>doc-only</td>
<td>yes</td>
<td>-</td>
</tr>
<tr class="odd">
<td>1:1</td>
<td>post-morph</td>
<td>global</td>
<td>yes</td>
<td>-</td>
</tr>
<tr class="even">
<td>M:N</td>
<td>post-morph</td>
<td>global</td>
<td>-</td>
<td>-</td>
</tr>
<tr class="odd">
<td>1:1</td>
<td>post-morph</td>
<td>doc-only</td>
<td>yes</td>
<td>-</td>
</tr>
<tr class="even">
<td>M:N</td>
<td>post-morph</td>
<td>doc-only</td>
<td>-</td>
<td>-</td>
</tr>
</tbody>
</table>
<p>“New” column means that this particular type is supported now, but was <em>not</em> supported by the legacy <code>wordforms</code> directive. Yep, that’s correct! Curiously, simple 1:1 pre-morph mappings were indeed <em>not</em> easily available before.</p>
<p>Mappings reside in a separate text file (or a set of files), and can be used in the index with a <code>mappings</code> directive.</p>
<p>You can specify either just one file, or several files, or even OS patterns like <code>*.txt</code> (the latter should be expanded according to your OS syntax).</p>
<pre><code>index test1
{
    mappings = common.txt test1specific.txt map*.txt
}</code></pre>
<p>Semi-formal file syntax is as follows. (If it’s too hard, worry not, there will be an example just a little below.)</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb29-1"><a href="#cb29-1"></a><span class="ex">mappings</span> := line, [line, [...]]</span>
<span id="cb29-2"><a href="#cb29-2"></a><span class="ex">line</span> := {comment <span class="kw">|</span> <span class="ex">mapping</span>}</span>
<span id="cb29-3"><a href="#cb29-3"></a><span class="ex">comment</span> := <span class="st">&quot;#&quot;</span>, arbitrary_text</span>
<span id="cb29-4"><a href="#cb29-4"></a></span>
<span id="cb29-5"><a href="#cb29-5"></a><span class="ex">mapping</span> := input, separator, output, [comment]</span>
<span id="cb29-6"><a href="#cb29-6"></a><span class="ex">input</span> := [flags], keyword, [keyword, [...]]</span>
<span id="cb29-7"><a href="#cb29-7"></a><span class="ex">separator</span> := {<span class="st">&quot;=&gt;&quot;</span> <span class="kw">|</span> <span class="st">&quot;&gt;&quot;</span>}</span>
<span id="cb29-8"><a href="#cb29-8"></a><span class="ex">output</span> := keyword, [keyword, [...]]</span>
<span id="cb29-9"><a href="#cb29-9"></a><span class="ex">flags</span> := [<span class="st">&quot;!&quot;</span>], [<span class="st">&quot;~&quot;</span>]</span></code></pre></div>
<p>So generally mappings are just two lists of keywords (input list to match, and output list to replace the input with, respectively) with a special <code>=&gt;</code> separator token between them. Legacy <code>&gt;</code> separator token is also still supported.</p>
<p>Mappings not marked with any flags are pre-morphology.</p>
<p>Post-morphology mappings are marked with <code>~</code> flag in the very beginning.</p>
<p>Document-only mappings are marked with <code>!</code> flag in the very beginning.</p>
<p>The two flags can be combined.</p>
<p>Comments begin with <code>#</code>, and everything from <code>#</code> to the end of the current line is considered a comment, and mostly ignored.</p>
<p>Magic <code>OVERRIDE</code> substring anywhere in the comment suppresses mapping override warnings.</p>
<p>Now to the example! Mappings are useful for a variety of tasks, for instance: correcting typos; implementing synonyms; injecting additional keywords into documents (for better recall); contracting certain well-known phrases (for performance); etc. Here’s an example that shows all that.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb30-1"><a href="#cb30-1"></a><span class="co"># put this in a file, eg. mymappings.txt</span></span>
<span id="cb30-2"><a href="#cb30-2"></a><span class="co"># then point Sphinx to it</span></span>
<span id="cb30-3"><a href="#cb30-3"></a><span class="co">#</span></span>
<span id="cb30-4"><a href="#cb30-4"></a><span class="co"># mappings = mymappings.txt</span></span>
<span id="cb30-5"><a href="#cb30-5"></a></span>
<span id="cb30-6"><a href="#cb30-6"></a><span class="co"># fixing individual typos, pre-morph</span></span>
<span id="cb30-7"><a href="#cb30-7"></a><span class="ex">mapings</span> =<span class="op">&gt;</span> mappings</span>
<span id="cb30-8"><a href="#cb30-8"></a></span>
<span id="cb30-9"><a href="#cb30-9"></a><span class="co"># fixing a class of typos, post-morph</span></span>
<span id="cb30-10"><a href="#cb30-10"></a><span class="ex">~sucess</span> =<span class="op">&gt;</span> <span class="ex">success</span></span>
<span id="cb30-11"><a href="#cb30-11"></a></span>
<span id="cb30-12"><a href="#cb30-12"></a><span class="co"># synonyms, also post-morph</span></span>
<span id="cb30-13"><a href="#cb30-13"></a><span class="ex">~commence</span> =<span class="op">&gt;</span> <span class="ex">begin</span></span>
<span id="cb30-14"><a href="#cb30-14"></a><span class="ex">~gobbledygook</span> =<span class="op">&gt;</span> <span class="ex">gibberish</span></span>
<span id="cb30-15"><a href="#cb30-15"></a><span class="ex">~lorry</span> =<span class="op">&gt;</span> <span class="ex">truck</span> <span class="co"># random comment example</span></span>
<span id="cb30-16"><a href="#cb30-16"></a></span>
<span id="cb30-17"><a href="#cb30-17"></a><span class="co"># global expansions</span></span>
<span id="cb30-18"><a href="#cb30-18"></a><span class="ex">e8400</span> =<span class="op">&gt;</span> intel e8400</span>
<span id="cb30-19"><a href="#cb30-19"></a></span>
<span id="cb30-20"><a href="#cb30-20"></a><span class="co"># global contractions</span></span>
<span id="cb30-21"><a href="#cb30-21"></a><span class="ex">core</span> 2 duo =<span class="op">&gt;</span> c2d</span>
<span id="cb30-22"><a href="#cb30-22"></a></span>
<span id="cb30-23"><a href="#cb30-23"></a><span class="co"># document-only expansions</span></span>
<span id="cb30-24"><a href="#cb30-24"></a><span class="co"># (note that semicolons are for humans, engine will ignore them)</span></span>
<span id="cb30-25"><a href="#cb30-25"></a>!<span class="ex">united</span> kingdom =<span class="op">&gt;</span> uk<span class="kw">;</span> <span class="ex">united</span> kingdom<span class="kw">;</span> <span class="ex">england</span><span class="kw">;</span> <span class="ex">scotland</span><span class="kw">;</span> <span class="ex">wales</span></span>
<span id="cb30-26"><a href="#cb30-26"></a>!<span class="ex">grrm</span> =<span class="op">&gt;</span> grrm george martin</span>
<span id="cb30-27"><a href="#cb30-27"></a></span>
<span id="cb30-28"><a href="#cb30-28"></a><span class="co"># override example</span></span>
<span id="cb30-29"><a href="#cb30-29"></a><span class="co"># this is useful when using multiple mapping files</span></span>
<span id="cb30-30"><a href="#cb30-30"></a><span class="co"># (eg. with different per-category mapping rules)</span></span>
<span id="cb30-31"><a href="#cb30-31"></a><span class="ex">e8400</span> =<span class="op">&gt;</span> intel cpu e8400 <span class="co"># OVERRIDE</span></span></code></pre></div>
<h3 id="pre-morph-mappings">Pre-morph mappings</h3>
<p><strong>Pre-morph mappings</strong> are more “precise” in a certain sense, because they only match specific forms, before any morphological normalization. For instance, <code>apple trees =&gt; garden</code> mapping will <em>not</em> kick in for a document mentioning just a singular <code>apple tree</code>.</p>
<p>Pre-morph mapping outputs are processed further as per index settings, and so they are <strong>subject to morphology</strong> when the index has that enabled! For example, <code>semiramis =&gt; hanging gardens</code> mapping with <code>stem_en</code> stemmer should result in <code>hang garden</code> text being stored into index.</p>
<p>To be completely precise, in this example the <em>mapping</em> emits <code>hanging</code> and <code>gardens</code> tokens, and then the subsequent <em>stemmer</em> normalizes them to <code>hang</code> and <code>garden</code> respectively, and then (in the absence of any other mappings etc), those two tokens are stored in the final index.</p>
<h3 id="post-morph-mappings">Post-morph mappings</h3>
<p>There is one very important caveat about the post-morph mappings.</p>
<p><strong>Post-morph mapping outputs are not morphology normalized</strong> automatically, only their <strong>inputs</strong> are. In other words, only the left (input) part is subject to morphology, the output is stored into the index as is. More or less naturally too, they are <strong>post</strong> morphology mappings, after all. Sill, that can very well cause subtle-ish configuration bugs.</p>
<p>For example, <code>~semiramis =&gt; hanging gardens</code> mapping with <code>stem_en</code> will store <code>hanging gardens</code> into the index, not <code>hang garden</code>, because no morphology for outputs.</p>
<p>This is obviously <em>not</em> our intent, right?! We actually want <code>garden hang</code> query to match documents mentioning either <code>semiramis</code> or <code>hanging gardens</code>, but with <em>this</em> configuration, it will only match the former. So for now, we have to <strong>manually</strong> morph our outputs (no syntax to automatically morph them just yet). That would be done with a <code>CALL KEYWORDS</code> statement:</p>
<pre><code>mysql&gt; CALL KEYWORDS(&#39;hanging gardens&#39;, &#39;stem_test&#39;);
+------+-----------+------------+
| qpos | tokenized | normalized |
+------+-----------+------------+
| 1    | hanging   | hang       |
| 2    | gardens   | garden     |
+------+-----------+------------+
2 rows in set (0.00 sec)</code></pre>
<p>So our mapping should be changed to <code>~semiramis =&gt; hang garden</code> in order to work as expected. Caveat!</p>
<p>As a side note, both the original and updated mappings also affect any documents mentioning <code>semirami</code> or <code>semiramied</code> (because morphology for inputs), but that is rarely an issue.</p>
<p>Bottom line, keep in mind that <strong>“post-morph mappings = morphed inputs, but UNMOPRHED outputs”</strong>, configure your mappings accordingly, and do <em>not</em> forget to morph the outputs if needed!</p>
<p>In simple cases (eg. when you only use lemmatization) you might eventually get away with “human” (natural language) normalization. One might reasonably guess that the lemma for <code>gardens</code> is going to be just <code>garden</code>, right?! Right.</p>
<p>However, even our simple example is not that simple, because of innocuously looking <code>hanging</code>, because look how <code>lemmatize_en</code> <em>actually</em> normalizes those different forms of <code>hang</code>:</p>
<pre><code>mysql&gt; CALL KEYWORDS(&#39;hang hanged hanging&#39;, &#39;lemmatize_test&#39;);
+------+-----------+------------+
| qpos | tokenized | normalized |
+------+-----------+------------+
| 1    | hang      | hang       |
| 2    | hanged    | hang       |
| 3    | hanging   | hanging    |
+------+-----------+------------+
3 rows in set (0.00 sec)</code></pre>
<p>It gets worse with more complex morphology stacks (where multiple <code>morphdict</code> files, stemmers, or lemmatizers can engage). In fact, it gets worse with just stemmers. For example, another classic caveat, <code>stem_en</code> normalizes <code>business</code> to <code>busi</code> and one would need to use <em>that</em> in the output. Less easy to guess… Hence the current rule of thumb, run your outputs through <code>CALL KEYWORDS</code> when configuring, and use the normalized tokens.</p>
<p>Full disclosure, we consider additional syntax to mark the outputs to auto-run through morphology (that would be so much easier to use than having to manually filter through <code>CALL KEYWORDS</code>, right?!) but that’s not implemented just yet.</p>
<h3 id="document-only-mappings">Document-only mappings</h3>
<p><strong>Document-only mappings</strong> are only applied to documents at indexing time, and ignored at query time. This is pretty useful for indexing time expansions, and that is why the <code>grrm</code> mapping example above maps it to itself too, and not just <code>george martin</code>.</p>
<p>In the “expansion” usecase, they are more efficient when <em>searching</em>, compared to similar regular mappings.</p>
<p>Indeed, when searching for a source mapping, regular mappings would expand to all keywords (in our example, to all 3 keywords, <code>grrm george martin</code>), fetch and intersect them, and do all that work for… nothing! Because we can obtain exactly the same result much more efficiently by simply fetching just the source keywords (just <code>grrm</code> in our example). And that’s exactly how document-only mappings work when querying, they just skip the <em>query</em> expansion altogether.</p>
<p>Now, when searching for (a part of) a destination mapping, nothing would change. In that case both document-only and regular global mappings would just execute the query completely identically. So <code>george</code> must match in any event.</p>
<p>Bottom line, use document-only mappings when you’re doing expansions, in order to avoid that unnecessary performance hit.</p>
<h2 id="using-morphdict">Using morphdict</h2>
<p><strong>Morphdict</strong> essentially lets you provide your own (additional) morphology dictionary, ie. specify a list of form-to-lemma normalizations. You can think of them as of “overrides” or “patches” that take priority over any other morphology processors. Naturally, they also are 1:1 only, ie. they <strong>must</strong> map a single morphological form to a single lemma or stem.</p>
<p>There may be multiple <code>morphdict</code> directives specifying multiple morphdict files (for instance, with patches for different languages).</p>
<pre><code>index test1
{
    morphdict = mymorph_english.txt
    morphdict = mymorph_spanish.txt
    ...
}</code></pre>
<p>For example, we can use <code>morphdict</code> to fixup a few well-known mistakes that the <code>stem_en</code> English stemmer is known to make.</p>
<pre><code>octopii =&gt; octopus
business =&gt; business
businesses =&gt; business</code></pre>
<p>Morphdict also lets you <strong>specify POS (Part Of Speech) tags</strong> for the lemmas, using a small subset of Penn syntax. For example:</p>
<pre><code>mumps =&gt; mumps, NN # always plural
impignorating =&gt; impignorate, VB</code></pre>
<p>Simple 1:1 normalizations, optional POS tags, and comments are everything there is to morphdict. Yep, it’s as simple as that. Just for the sake of completeness, semi-formal syntax is as follows.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb36-1"><a href="#cb36-1"></a><span class="ex">morphdict</span> := line, [line, [...]]</span>
<span id="cb36-2"><a href="#cb36-2"></a><span class="ex">line</span> := {comment <span class="kw">|</span> <span class="ex">entry</span>}</span>
<span id="cb36-3"><a href="#cb36-3"></a><span class="ex">comment</span> := <span class="st">&quot;#&quot;</span>, arbitrary_text</span>
<span id="cb36-4"><a href="#cb36-4"></a></span>
<span id="cb36-5"><a href="#cb36-5"></a><span class="ex">entry</span> := keyword, separator, keyword, [<span class="st">&quot;,&quot;</span> postag], [comment]</span>
<span id="cb36-6"><a href="#cb36-6"></a><span class="ex">separator</span> := {<span class="st">&quot;=&gt;&quot;</span> <span class="kw">|</span> <span class="st">&quot;&gt;&quot;</span>}</span>
<span id="cb36-7"><a href="#cb36-7"></a><span class="ex">postag</span> := {<span class="st">&quot;JJ&quot;</span> <span class="kw">|</span> <span class="st">&quot;NN&quot;</span> <span class="kw">|</span> <span class="st">&quot;RB&quot;</span> <span class="kw">|</span> <span class="st">&quot;VB&quot;</span>}</span></code></pre></div>
<p>Even though right now POS tags are only used to identify nouns in queries and then compute a few related ranking signals, we decided to support a little more tags than that.</p>
<ul>
<li><code>JJ</code>, adjective</li>
<li><code>NN</code>, noun</li>
<li><code>RB</code>, adverb</li>
<li><code>VB</code>, verb</li>
</ul>
<p>Optional POS tags are rather intended to fixup builtin lemmatizer mistakes. However they should work alright with stemmers too.</p>
<p>When fixing up stemmers you generally have to proceed with extreme care, though. Say, the following <code>stem_en</code> fixup example will <em>not</em> work as expected!</p>
<pre><code>geese =&gt; goose</code></pre>
<p>Problem is, <code>stem_en</code> stemmer (unlike <code>lemmatize_en</code> lemmatizer) does <em>not</em> normalize <code>goose</code> to itself. So when <code>goose</code> occurs in the document text, it will emit <code>goos</code> stem instead. So in order to fixup <code>stem_en</code> stemmer, you have to map to that <em>stem</em>, with a <code>geese =&gt; goos</code> entry. Extreme care.</p>
<h2 id="migrating-legacy-wordforms">Migrating legacy wordforms</h2>
<p>Mappings and morphdict were introduced in v.3.4 in order to replace the legacy <code>wordforms</code> directive. Both the directive and older indexes are still supported by v.3.4 specifically, of course, to allow for a smooth upgrade. However, they are slated for quick removal.</p>
<p>How to migrate legacy wordforms properly? That depends.</p>
<p>To change the behavior minimally, you should extract 1:1 legacy wordforms into <code>morphdict</code>, because legacy 1:1 wordforms replace the morphology. All the other entries can be used as <code>mappings</code> rather safely. By the way, our loading code for legacy <code>wordforms</code> works exactly this way.</p>
<p>However, unless you are using legacy wordforms to emulate (or implement even) morphology, chances are quite high that your 1:1 legacy wordforms were intended more for <code>mappings</code> rather than <code>morphdict</code>. In which event you should simply rename <code>wordforms</code> directive to <code>mappings</code> and that would be it.</p>
<h2 id="using-udfs">Using UDFs</h2>
<h3 id="udfs-overview">UDFs overview</h3>
<p>Sphinx supports User Defined Functions (or UDFs for short) that let you extend its expression engine:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb38-1"><a href="#cb38-1"></a><span class="kw">SELECT</span> <span class="kw">id</span>, attr1, myudf(attr2, attr3<span class="op">+</span>attr4) <span class="op">..</span>.</span></code></pre></div>
<p>You can load and unload UDFs into <code>searchd</code> dynamically, ie. without having to restart the daemon itself, and then use them in most expressions when searching and ranking. Quick summary of the UDF features is as follows.</p>
<ul>
<li>UDFs can accept most of the argument types that Sphinx supports, namely:
<ul>
<li><strong>numerics</strong>, ie. integers (32-bit and 64-bit) and floats (32-bit);</li>
<li><strong>MVAs</strong>, ie. sets of integers (32-bit and 64-bit);</li>
<li><strong>strings</strong>, including binary non-ASCIIZ blobs;</li>
<li><strong><code>FACTORS()</code></strong>, ie. special blobs with ranking signals;</li>
<li><strong>JSON objects</strong>, including subobjects or individual fields;</li>
<li><strong>float vectors</strong>.</li>
</ul></li>
<li>UDFs can return integer, float, or string values.</li>
<li>UDFs can check the argument number, types, and names during the query setup phase, and raise errors.</li>
</ul>
<p>UDFs have a wide variety of uses, for instance:</p>
<ul>
<li>adding custom mathematical or string functions;</li>
<li>accessing the database or files from within Sphinx;</li>
<li>implementing complex ranking functions.</li>
</ul>
<p>UDFs reside in the external dynamic libraries (<code>.so</code> files on UNIX and <code>.dll</code> on Windows systems). Library files need to reside in a trusted folder specified by <code>plugin_dir</code> directive, for obvious security reasons: securing a single folder is easy; letting anyone install arbitrary code into <code>searchd</code> is a risk. You can load and unload them dynamically into <code>searchd</code> with <code>CREATE FUNCTION</code> and <code>DROP FUNCTION</code> SphinxQL statements, respectively. Also, you can seamlessly reload UDFs (and other plugins) with <code>RELOAD PLUGINS</code> statement. Sphinx keeps track of the currently loaded functions, that is, every time you create or drop an UDF, <code>searchd</code> writes its state to the <code>sphinxql_state</code> file as a plain good old SQL script.</p>
<p>Once you successfully load an UDF, you can use it in your <code>SELECT</code> or other statements just as any of the builtin functions:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb39-1"><a href="#cb39-1"></a><span class="kw">SELECT</span> <span class="kw">id</span>, MYCUSTOMFUNC(groupid, authorname), <span class="op">..</span>. <span class="kw">FROM</span> myindex</span></code></pre></div>
<p>Multiple UDFs (and other plugins) may reside in a single library. That library will only be loaded once. It gets automatically unloaded once all the UDFs and plugins from it are dropped.</p>
<p>Aggregation functions are not supported just yet. In other words, your UDFs will be called for just a single document at a time and are expected to return some value for that document. Writing a function that can compute an aggregate value like <code>AVG()</code> over the entire group of documents that share the same <code>GROUP BY</code> key is not yet possible. However, you can use UDFs within the builtin aggregate functions: that is, even though <code>MYCUSTOMAVG()</code> is not supported yet, <code>AVG(MYCUSTOMFUNC())</code> should work alright!</p>
<p>UDFs are local. In order to use them on a cluster, you have to put the same library on all its nodes and run proper <code>CREATE FUNCTION</code> statements on all the nodes too. This might change in the future versions.</p>
<h3 id="udf-programming-introduction">UDF programming introduction</h3>
<p>The UDF interface is plain C. So you would usually write your UDF in C or C++. (Even though in theory it might be possible to use other languages.)</p>
<p>Your very first starting point should be <code>src/udfexample.c</code>, our example UDF library. That libary implements several different functions, to demonstrate how to use several different techniques (stateless and stateful UDFs, different argument types, batched calls, etc).</p>
<p>The files that provide the UDF interface are:</p>
<ul>
<li><code>src/sphinxudf.h</code> that declares the essential types and helper functions;</li>
<li><code>src/sphinxudf.c</code> that implements those functions.</li>
</ul>
<p>For UDFs that <strong>do not</strong> implement ranking, and therefore do not need to handle <code>FACTORS()</code> arguments, simply including the <code>sphinxudf.h</code> header is sufficient.</p>
<p>To be able to parse the <code>FACTORS()</code> blobs from your UDF, however, you will also need to compile and link with <code>sphinxudf.c</code> source file.</p>
<p>Both <code>sphinxudf.h</code> and <code>sphinxudf.c</code> are standalone. So you can copy around those files only. They do not depend on any other bits of Sphinx source code.</p>
<p>Within your UDF, you should literally implement and export just two functions.</p>
<p><strong>First</strong>, you must define <code>int LIBRARYNAME_ver() { return SPH_UDF_VERSION; }</code> in order to implement UDF interface version control. LIBRARYNAME should be replaced with the name of your library. Here’s a more complete example:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb40-1"><a href="#cb40-1"></a><span class="pp">#include </span><span class="im">&lt;sphinxudf.h&gt;</span></span>
<span id="cb40-2"><a href="#cb40-2"></a></span>
<span id="cb40-3"><a href="#cb40-3"></a><span class="co">// our library will be called udfexample.so, thus, so it must define</span></span>
<span id="cb40-4"><a href="#cb40-4"></a><span class="co">// a version function named udfexample_ver()</span></span>
<span id="cb40-5"><a href="#cb40-5"></a><span class="dt">int</span> udfexample_ver()</span>
<span id="cb40-6"><a href="#cb40-6"></a>{</span>
<span id="cb40-7"><a href="#cb40-7"></a>    <span class="cf">return</span> SPH_UDF_VERSION;</span>
<span id="cb40-8"><a href="#cb40-8"></a>}</span></code></pre></div>
<p>This version checker protects you from accidentally loading libraries with mismatching UDF interface versions. (Which would in turn usually cause either incorrect behavior or crashes.)</p>
<p><strong>Second</strong>, you must implement the actual function, too. For example:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb41-1"><a href="#cb41-1"></a>sphinx_int64_t testfunc(SPH_UDF_INIT * init, SPH_UDF_ARGS * args,</span>
<span id="cb41-2"><a href="#cb41-2"></a>    <span class="dt">char</span> * error_message)</span>
<span id="cb41-3"><a href="#cb41-3"></a>{</span>
<span id="cb41-4"><a href="#cb41-4"></a>   <span class="cf">return</span> <span class="dv">123</span>;</span>
<span id="cb41-5"><a href="#cb41-5"></a>}</span></code></pre></div>
<p>UDF function names in SphinxQL are case insensitive. However, the respective C/C++ <strong>function names must be all lower-case</strong>, or the UDF will fail to load.</p>
<p>More importantly, it is vital that:</p>
<ol type="1">
<li>the calling convention is C (aka <code>__cdecl</code>);</li>
<li>arguments list matches the plugin system expectations exactly;</li>
<li>the return type matches the one you specify in <code>CREATE FUNCTION</code>;</li>
<li>the implemented C/C++ functions are thread-safe.</li>
</ol>
<p>Unfortunately, there is no (easy) way for <code>searchd</code> to automatically check for those mistakes when loading the function, and they could crash the server and/or result in unexpected results.</p>
<p>Let’s discuss the simple <code>testfunc()</code> example in a bit more detail.</p>
<p>The first argument, a pointer to <code>SPH_UDF_INIT</code> structure, is essentially just a pointer to our function state. Using that state is optional. In this example, the function is stateless, it simply returns 123 every time it gets called. So we do not have to define an initialization function, and we can simply ignore that argument.</p>
<p>The second argument, a pointer to <code>SPH_UDF_ARGS</code>, is the most important one. All the actual call arguments are passed to your UDF via this structure. It contains the call argument count, names, types, etc. So whether your function gets called like with simple constants, like this:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb42-1"><a href="#cb42-1"></a><span class="kw">SELECT</span> <span class="kw">id</span>, testfunc(<span class="dv">1</span>) <span class="op">..</span>.</span></code></pre></div>
<p>or with a bunch of subexpressions as its arguments, like this:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb43-1"><a href="#cb43-1"></a><span class="kw">SELECT</span> <span class="kw">id</span>, testfunc(<span class="st">&#39;abc&#39;</span>, <span class="dv">1000</span><span class="op">*</span><span class="kw">id</span><span class="op">+</span>gid, WEIGHT()) <span class="op">..</span>.</span></code></pre></div>
<p>or anyhow else, it will receive the very same <code>SPH_UDF_ARGS</code> structure, in <strong>all</strong> of these cases. However, the <em>data</em> passed in the args structure can be a little different.</p>
<p>In the <code>testfunc(1)</code> call example <code>args-&gt;arg_count</code> will be set to 1, because, naturally we have just one argument. In the second example, <code>arg_count</code> will be equal to 3. Also <code>args-&gt;arg_types</code> array will contain different type data for these two calls. And so on.</p>
<p>Finally, the third argument, <code>char * error_message</code> serves both as error flag, and a method to report a human-readable message (if any). UDFs should only raise that flag/message to indicate <em>unrecoverable</em> internal errors; ones that would prevent any subsequent attempts to evaluate that instance of the UDF call from continuing.</p>
<p>You must <em>not</em> use this flag for argument type checks, or for any other error reporting that is likely to happen during “normal” use. This flag is designed to report sudden critical runtime errors only, such as running out of memory.</p>
<p>If we need to, say, allocate temporary storage for our function to use, or check upfront whether the arguments are of the supported types, then we need to add two more functions, with UDF initialization and deinitialization, respectively.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb44-1"><a href="#cb44-1"></a><span class="dt">int</span> testfunc_init ( SPH_UDF_INIT * init, SPH_UDF_ARGS * args,</span>
<span id="cb44-2"><a href="#cb44-2"></a>    <span class="dt">char</span> * error_message )</span>
<span id="cb44-3"><a href="#cb44-3"></a>{</span>
<span id="cb44-4"><a href="#cb44-4"></a>    <span class="co">// allocate and initialize a little bit of temporary storage</span></span>
<span id="cb44-5"><a href="#cb44-5"></a>    init-&gt;func_data = malloc(<span class="kw">sizeof</span>(<span class="dt">int</span>));</span>
<span id="cb44-6"><a href="#cb44-6"></a>    *(<span class="dt">int</span>*)init-&gt;func_data = <span class="dv">123</span>;</span>
<span id="cb44-7"><a href="#cb44-7"></a></span>
<span id="cb44-8"><a href="#cb44-8"></a>    <span class="co">// return a success code</span></span>
<span id="cb44-9"><a href="#cb44-9"></a>    <span class="cf">return</span> <span class="dv">0</span>;</span>
<span id="cb44-10"><a href="#cb44-10"></a>}</span>
<span id="cb44-11"><a href="#cb44-11"></a></span>
<span id="cb44-12"><a href="#cb44-12"></a><span class="dt">void</span> testfunc_deinit(SPH_UDF_INIT * init)</span>
<span id="cb44-13"><a href="#cb44-13"></a>{</span>
<span id="cb44-14"><a href="#cb44-14"></a>    <span class="co">// free up our temporary storage</span></span>
<span id="cb44-15"><a href="#cb44-15"></a>    free(init-&gt;func_data);</span>
<span id="cb44-16"><a href="#cb44-16"></a>}</span></code></pre></div>
<p>Note how <code>testfunc_init()</code> also receives the call arguments structure. At that point in time we do not yet have any actual per-row <em>values</em> though, so the <code>args-&gt;arg_values</code> will be <code>NULL</code>. But the argument names and types are already known, and will be passed. You can check them in the initialization function and return an error if they are of an unsupported type.</p>
<h3 id="udf-argument-and-return-types">UDF argument and return types</h3>
<p>UDFs can receive arguments of pretty much any valid internal Sphinx type. When in doubt, refer to <code>sphinx_udf_argtype</code> enum in <code>sphinxudf.h</code> for a full list. For convenience, here’s a short reference table:</p>
<table>
<thead>
<tr class="header">
<th>UDF arg type</th>
<th>C/C++ type, and a short description</th>
<th>Len</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>UINT32</td>
<td><code>uint32_t</code>, unsigned 32-bit integer</td>
<td>-</td>
</tr>
<tr class="even">
<td>INT64</td>
<td><code>int64_t</code>, signed 64-bit integer</td>
<td>-</td>
</tr>
<tr class="odd">
<td>FLOAT</td>
<td><code>float</code>, single-precision (32-bit) IEEE754 float</td>
<td>-</td>
</tr>
<tr class="even">
<td>STRING</td>
<td><code>char *</code>, non-ASCIIZ string, with a separate length</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>UINT32SET</td>
<td><code>uint32_t *</code>, sorted set of u32 integers</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>INT64SET</td>
<td><code>int64_t *</code>, sorted set of i64 integers</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>FACTORS</td>
<td><code>void *</code>, special blob with ranking signals</td>
<td>-</td>
</tr>
<tr class="even">
<td>JSON</td>
<td><code>char *</code>, JSON (sub)object or field in a string format</td>
<td>-</td>
</tr>
<tr class="odd">
<td>FLOAT_VEC</td>
<td><code>float *</code>, an unsorted array of floats</td>
<td>Yes</td>
</tr>
</tbody>
</table>
<p>The <code>Len</code> column in this table means that the argument length is passed separately via <code>args-&gt;str_lengths[i]</code> in addition to the argument value <code>args-&gt;arg_values[i]</code> itself.</p>
<p>For <code>STRING</code> arguments, the length contains the string length, in bytes. For all other types, it contains the number of elements.</p>
<p>As for the return types, UDFs can currently return numeric or string values. The respective types are as follows:</p>
<table>
<thead>
<tr class="header">
<th>Sphinx type</th>
<th>Regular return type</th>
<th>Batched output arg type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>UINT</code></td>
<td><code>sphinx_int64_t</code></td>
<td><code>int *</code></td>
</tr>
<tr class="even">
<td><code>BIGINT</code></td>
<td><code>sphinx_int64_t</code></td>
<td><code>sphinx_int64_t *</code></td>
</tr>
<tr class="odd">
<td><code>FLOAT</code></td>
<td><code>double</code></td>
<td><code>float *</code></td>
</tr>
<tr class="even">
<td><code>STRING</code></td>
<td><code>char *</code></td>
<td>-</td>
</tr>
</tbody>
</table>
<p>Batched calls are discussed below.</p>
<p>We still define our own <code>sphinx_int64_t</code> type in <code>sphinxudf.h</code> for clarity and convenience, but these days, any standard 64-bit integer type like <code>int64_t</code> or <code>long long</code> should also suffice, and can be safely used in your UDF code.</p>
<p>Any non-scalar return values in general (for now just the <code>STRING</code> return type) <strong>MUST</strong> be allocated using <code>args-&gt;fn_malloc</code> function.</p>
<p>Also, <code>STRING</code> values must (rather naturally) be zero-terminated C/C++ strings, or the engine will crash.</p>
<p>It is safe to return a <code>NULL</code> value. At the moment (as of v.3.4), that should be equivalent to returning an empty string.</p>
<p>Of course, <em>internally</em> in your UDF you can use whatever allocator you want, so the <code>testfunc_init()</code> example above is correct even though it uses <code>malloc()</code> directly. You manage that pointer yourself, it gets freed up using a matching <code>free()</code> call, and all is well. However, the <em>returned</em> strings values will be managed by Sphinx, and we have our own allocator. So for the return values specifically, you need to use it too.</p>
<p>Note than when you set a non-empty error message, the engine will immediately free the pointer that you return. So even in the error case, you still <em>must</em> either return whatever you allocated with <code>args-&gt;fn_malloc</code> (otherwise that would be a leak). However, in this case it’s okay to return a garbage buffer (eg. not yet fully initialized and therefore not zero-terminated), as the engine will not attempt to interpret it as a string.</p>
<h3 id="udf-call-batching">UDF call batching</h3>
<p>Since v.3.3 Sphinx supports two types of the “main” UDF call with a numeric return type:</p>
<ul>
<li>regular, called with exactly 1 row at a time;</li>
<li>batched, called with batches of 1 to 128 rows at a time.</li>
</ul>
<p>These two types have different C/C++ signatures, for example:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb45-1"><a href="#cb45-1"></a><span class="co">/// regular call that RETURNS UINT</span></span>
<span id="cb45-2"><a href="#cb45-2"></a><span class="co">/// note the `sphinx_int64_t` ret type</span></span>
<span id="cb45-3"><a href="#cb45-3"></a>sphinx_int64_t foo(SPH_UDF_INIT * init, SPH_UDF_ARGS * args,</span>
<span id="cb45-4"><a href="#cb45-4"></a>    <span class="dt">char</span> * error);</span>
<span id="cb45-5"><a href="#cb45-5"></a></span>
<span id="cb45-6"><a href="#cb45-6"></a><span class="co">/// batched call that RETURNS UINT</span></span>
<span id="cb45-7"><a href="#cb45-7"></a><span class="co">/// note the `int *` out arg type</span></span>
<span id="cb45-8"><a href="#cb45-8"></a><span class="dt">void</span> foo_batch(SPH_UDF_INIT * init, SPH_UDF_ARGS * args,</span>
<span id="cb45-9"><a href="#cb45-9"></a>    <span class="dt">int</span> * results, <span class="dt">int</span> batch_size, <span class="dt">char</span> * error);</span></code></pre></div>
<p>UDF must define at least 1 of these two functions. As of v.3.3, UDF can define both functions, but batched calls take priority. So when both <code>foo_batch()</code> and <code>foo()</code> are defined, the engine will only use <code>foo_batch()</code>, and completely ignore <code>foo()</code>.</p>
<p>Batched calls are needed for performance. For instance, processing multiple documents at once with certain CatBoost ML models could be more than 5x faster.</p>
<p>As mentioned a little earlier, return types for batched calls differ from regular ones, again for performance reasons. So yes, the types in the example above are correct. Regular, single-row <code>foo()</code> call must use <code>sphinx_int64_t</code> for its return type either when the function was created with <code>RETURNS UINT</code> or <code>RETURNS BIGINT</code>, for simplicity. However the batched multi-row <code>foo_batch()</code> call <strong>must</strong> use an output buffer typed as <code>int *</code> when created with <code>RETURNS UINT</code>; or a buffer typed as <code>sphinx_int64_t *</code> when created with <code>RETURNS BIGINT</code>; just as mentioned in that types table earlier.</p>
<p>Current target batch size is 128, but that size may change in either direction in the future. Assume little about <code>batch_size</code>, and very definitely do <em>not</em> hardcode the current limit anywhere. (Say, it is reasonably safe to assume that batches will always be in 1 to 65536 range, though.)</p>
<p>Engine should accumulate matches upto the target size, so that most UDF calls receive complete batches. However, trailing batches will be sized arbitrarily. For example, for 397 matches there should be 4 calls to <code>foo_batch()</code>, with 128, 128, 128, and 13 matches per batch respectively.</p>
<p>Arguments (and their sizes where applicable) are stored into <code>arg_values</code> (and <code>str_lengths</code>) sequentially for every match in the batch. For example, you can access them as follows:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb46-1"><a href="#cb46-1"></a><span class="cf">for</span> (<span class="dt">int</span> row = <span class="dv">0</span>; row &lt; batch_size; row++)</span>
<span id="cb46-2"><a href="#cb46-2"></a>    <span class="cf">for</span> (<span class="dt">int</span> arg = <span class="dv">0</span>; arg &lt; args-&gt;arg_count; arg++)</span>
<span id="cb46-3"><a href="#cb46-3"></a>    {</span>
<span id="cb46-4"><a href="#cb46-4"></a>        <span class="dt">int</span> index = row * args-&gt;args_count + arg;</span>
<span id="cb46-5"><a href="#cb46-5"></a>        use_arg(args-&gt;arg_values[index], args-&gt;str_lengths[index]);</span>
<span id="cb46-6"><a href="#cb46-6"></a>    }</span></code></pre></div>
<p>Batched UDF <strong>must</strong> fill the <strong>entire</strong> results array with some sane default value, even if it decides to fail with an unrecoverable error in the middle of the batch. It must never return garbage results.</p>
<p>On error, engine will stop calling the batched UDF for the rest of the current <code>SELECT</code> query (just as it does with regular UDFs), and automatically zero out the rest of the values. However, it is the UDFs responsbility to completely fill the failed batch anyway.</p>
<p>Batched calls are currently only supported for numeric UDFs, ie. functions that return <code>UINT</code>, <code>BIGINT</code>, or <code>FLOAT</code>; batching is not yet supported for <code>STRING</code> functions. That may change in the future.</p>
<h3 id="using-factors-in-udfs">Using <code>FACTORS()</code> in UDFs</h3>
<p>Most of the types map straightforwardly to the respective C types. The most notable exception is the <code>SPH_UDF_TYPE_FACTORS</code> argument type. You get that type by passing <code>FACTORS()</code> expression as an argument to your UDF. The value that the UDF will receive is a binary blob in a special internal format.</p>
<p>To extract individual ranking signals from that blob, you need to use either of the two <code>sphinx_factors_XXX()</code> or <code>sphinx_get_YYY_factor()</code> function families.</p>
<p>The first family consists of just 3 functions:</p>
<ul>
<li><code>sphinx_factors_init()</code> that initializes the unpacked <code>SPH_UDF_FACTORS</code> structure;</li>
<li><code>sphinx_factors_unpack()</code> that unpacks a binary blob value into it;</li>
<li><code>sphinx_factors_deinit()</code> that cleans up an deallocates <code>SPH_UDF_FACTORS</code>.</li>
</ul>
<p>So you need to call <code>init()</code> and <code>unpack()</code> first, then you can use the fields within the <code>SPH_UDF_FACTORS</code> structure, and then you have to call <code>deinit()</code> for cleanup. The resuling code would be rather simple, like this:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb47-1"><a href="#cb47-1"></a><span class="co">// init!</span></span>
<span id="cb47-2"><a href="#cb47-2"></a>SPH_UDF_FACTORS F;</span>
<span id="cb47-3"><a href="#cb47-3"></a>sphinx_factors_init(&amp;F);</span>
<span id="cb47-4"><a href="#cb47-4"></a></span>
<span id="cb47-5"><a href="#cb47-5"></a><span class="cf">if</span> (sphinx_factors_unpack((<span class="dt">const</span> <span class="dt">unsigned</span> <span class="dt">int</span> *)args-&gt;arg_values[<span class="dv">0</span>], &amp;F))</span>
<span id="cb47-6"><a href="#cb47-6"></a>{</span>
<span id="cb47-7"><a href="#cb47-7"></a>    sphinx_factors_deinit(&amp;F); <span class="co">// no leaks please</span></span>
<span id="cb47-8"><a href="#cb47-8"></a>    <span class="cf">return</span> -<span class="dv">1</span>;</span>
<span id="cb47-9"><a href="#cb47-9"></a>}</span>
<span id="cb47-10"><a href="#cb47-10"></a></span>
<span id="cb47-11"><a href="#cb47-11"></a><span class="co">// process!</span></span>
<span id="cb47-12"><a href="#cb47-12"></a><span class="dt">int</span> result = F.field[<span class="dv">3</span>].hit_count;</span>
<span id="cb47-13"><a href="#cb47-13"></a><span class="co">// ... maybe more math here ...</span></span>
<span id="cb47-14"><a href="#cb47-14"></a></span>
<span id="cb47-15"><a href="#cb47-15"></a><span class="co">// cleanup!</span></span>
<span id="cb47-16"><a href="#cb47-16"></a>sphinx_factors_deinit(&amp;F);</span>
<span id="cb47-17"><a href="#cb47-17"></a><span class="cf">return</span> result;</span></code></pre></div>
<p>However, this access simplicity has an obvious drawback. It will cause several memory allocations per each processed document (made by <code>init()</code> and <code>unpack()</code> and later freed by <code>deinit()</code> respectively), which might be slow.</p>
<p>So there is another interface to access <code>FACTORS()</code> that consists of a bunch of <code>sphinx_get_YYY_factor()</code> functions. It is more verbose, but it accesses the blob data directly, and it <em>guarantees</em> zero allocations and zero copying. So for top-notch ranking UDF performance, you want that one. Here goes the matching example code that also accesses just 1 signal from just 1 field:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb48-1"><a href="#cb48-1"></a><span class="co">// init!</span></span>
<span id="cb48-2"><a href="#cb48-2"></a><span class="dt">const</span> <span class="dt">unsigned</span> <span class="dt">int</span> * F = (<span class="dt">const</span> <span class="dt">unsigned</span> <span class="dt">int</span> *)args-&gt;arg_values[<span class="dv">0</span>];</span>
<span id="cb48-3"><a href="#cb48-3"></a><span class="dt">const</span> <span class="dt">unsigned</span> <span class="dt">int</span> * field3 = sphinx_get_field_factors(F, <span class="dv">3</span>);</span>
<span id="cb48-4"><a href="#cb48-4"></a></span>
<span id="cb48-5"><a href="#cb48-5"></a><span class="co">// process!</span></span>
<span id="cb48-6"><a href="#cb48-6"></a><span class="dt">int</span> result = sphinx_get_field_factor_int(field3, SPH_FIELDF_HIT_COUNT);</span>
<span id="cb48-7"><a href="#cb48-7"></a><span class="co">// ... maybe more math here ...</span></span>
<span id="cb48-8"><a href="#cb48-8"></a></span>
<span id="cb48-9"><a href="#cb48-9"></a><span class="co">// done! no cleanup needed</span></span>
<span id="cb48-10"><a href="#cb48-10"></a><span class="cf">return</span> result;</span></code></pre></div>
<h3 id="udf-calls-sequences">UDF calls sequences</h3>
<p>Depending on how your UDFs are used in the query, the main function call (<code>testfunc()</code> in our running example) might get called in a rather different volume and order. Specifically,</p>
<ul>
<li><p>UDFs referenced in <code>WHERE</code>, <code>ORDER BY</code>, or <code>GROUP BY</code> clauses must and will be evaluated for every matched document. They will be called in the <strong>natural matching order</strong>.</p></li>
<li><p>without subselects, UDFs that can be evaluated at the very last stage over the final result set will be evaluated that way, but before applying the <code>LIMIT</code> clause. They will be called in the <strong>result set order</strong>.</p></li>
<li><p>with subselects, such UDFs will also be evaluated <em>after</em> applying the inner <code>LIMIT</code> clause.</p></li>
</ul>
<p>The calling sequence of the other functions is fixed, though. Namely,</p>
<ul>
<li><p><code>testfunc_init()</code> is called once when initializing the query. It can return a non-zero code to indicate a failure; in that case query gets terminated early, and the error message from the <code>error_message</code> buffer is returned.</p></li>
<li><p><code>testfunc()</code> or <code>testfunc_batch()</code> is called for every eligible row batch (see above), whenever Sphinx needs to compute the UDF value(s). This call can indicate an unrecoverable error by writing either a value of 1, or some human-readable message to the <code>error_message</code> argument. (So in other words, you can use <code>error_message</code> either as a boolean flag, or a string buffer.)</p></li>
<li><p>After getting a non-zero <code>error_message</code> from the main UDF call, the engine guarantees to stop calling that UDF call for subsequent rows for the rest of the query. A default return value of 0 for numerics and an empty string for strings will be used instead. Sphinx might or might not choose to terminate such queries early, neither behavior is currently guaranteed.</p></li>
<li><p><code>testfunc_deinit()</code> is called once when the query processing (in a given index shard) ends. It must get called even if the main call reported an unrecoverable error earlier.</p></li>
</ul>
<h2 id="indexing-csv-and-tsv-files">Indexing: CSV and TSV files</h2>
<p><code>indexer</code> supports indexing data in both CSV and TSV formats, via the <code>csvpipe</code> and <code>tsvpipe</code> source types, respectively. Here’s a brief cheat sheet on the respective source directives.</p>
<ul>
<li><code>csvpipe_command = ...</code> specifies a command to run (for instance, <code>csvpipe_command = cat mydata.csv</code> in the simplest case).</li>
<li><code>csvpipe_header = 1</code> tells the <code>indexer</code> to pick the column list from the first row (otherwise, by default, the column list has to be specified in the config file).</li>
<li><code>csvpipe_attr_XXX</code> (where <code>XXX</code> is an attribute type, i.e. one of <code>bigint</code>, <code>bool</code>, <code>float</code>, <code>json</code>, <code>multi</code>, <code>multi_64</code>, <code>string</code>, or <code>uint</code>) specifies an attribute type for a given column.</li>
<li><code>csvpipe_field</code> and <code>csvpipe_field_string</code> specify a regular full-text field and a full-text field that should also be stored as a <code>string</code> attribute, respectively.</li>
<li><code>csvpipe_delimiter</code> changes the column delimiter to a given character (this is <code>csvpipe</code> only; <code>tsvpipe</code> naturally uses tabs).</li>
</ul>
<p>When working with TSV, you would use the very same directives, but start them with <code>tsvpipe</code> prefix (i.e. <code>tsvpipe_command</code>, <code>tsvpipe_header</code>, etc).</p>
<p>The first column is currently always treated as <code>id</code>, and must be a unique document identifier.</p>
<p>The first row can either be treated as a named list of columns (when <code>csvpipe_header = 1</code>), or as a first row of actual data. By default it’s treated as data. The column names are trimmed, so a bit of extra whitespace should not hurt.</p>
<p><code>csvpipe_header</code> affects how CSV input columns are matched to Sphinx attributes and fields.</p>
<p>With <code>csvpipe_header = 0</code> the input file only contains data, so the order of columns is taken from the config file. Thus, the order of <code>csvpipe_attr_XXX</code> and <code>csvpipe_field</code> directives is very important in this case. You will have to explicitly declare <em>all</em> the fields and attributes (except the leading <code>id</code>), and in <em>exactly</em> the same order they appear in the CSV file. <code>indexer</code> will warn if there were unmatched or extraneous columns.</p>
<p>With <code>csvpipe_header = 1</code> the input file starts with the column names list, so the declarations from the config file are only used to adjust the types. So in this case, the order of <code>csvpipe_attr_XXX</code> and <code>csvpipe_field</code> directives does not matter any more. Also, by default all the input CSV columns will be considered as fields, so you only need to explicitly configure attributes, not fields. For example, the following should work nicely, and index <code>title</code> and <code>content</code> as fields automatically:</p>
<pre><code>1.csv:

id, gid, title, content
123, 11, hello world, document number one
124, 12, hello again, document number two

sphinx.conf:

source csv1
{
    type = csvpipe
    csvpipe_command = cat 1.csv
    csvpipe_header = 1
    csvpipe_attr_uint = gid
}</code></pre>
<h2 id="indexing-special-chars-blended-tokens-and-mixed-codes">Indexing: special chars, blended tokens, and mixed codes</h2>
<p>Sphinx provides tools to help you better index (and then later search):</p>
<ul>
<li>terms that have special characters in them, like <code>@Rihanna</code>, or <code>Procter&amp;Gamble</code> or <code>U.S.A</code>, etc;</li>
<li>terms that mix letters and digits, like <code>UE53N5740AU</code>.</li>
</ul>
<p>The general approach, so-called “blending”, is the same in both cases:</p>
<ul>
<li>we always store a certain “base” (most granular) tokenization;</li>
<li>we also additonally store (“blend”) extra tokens, as configured;</li>
<li>we then let you search for either original or extra tokens.</li>
</ul>
<p>So in the examples just above Sphinx can:</p>
<ul>
<li>index base tokens, such as <code>rihanna</code> or <code>ue53n5740au</code>;</li>
<li>index special tokens, such as <code>@rihanna</code>;</li>
<li>index parts of mixed-codes tokens, such as <code>ue 53</code> and <code>ue53</code>.</li>
</ul>
<h3 id="blended-tokens-with-special-characters">Blended tokens (with special characters)</h3>
<p>To index <strong>blended tokens</strong>, i.e. tokens with special characters in them, you should:</p>
<ul>
<li>add your special “blended” characters to the <code>blend_chars</code> directive;</li>
<li>configure several processing modes for the extra tokens (optionally) using the <code>blend_mode</code> directive;</li>
<li>rebuild your index.</li>
</ul>
<p>Blended characters are going to be indexed both as separators, and <em>at the same time</em> as valid characters. They are considered separators when generating the base tokenization (or “base split” for short). But in addition they also are processed as valid characters when generating extra tokens.</p>
<p>For instance, when you set <code>blend_chars = @, &amp;, .</code> and index the text <code>@Rihanna Procter&amp;Gamble U.S.A</code>, the base split stores the following six tokens into the final index: <code>rihanna</code>, <code>procter</code>, <code>gamble</code>, <code>u</code>, <code>s</code>, and <code>a</code>. Exactly like it would without the <code>blend_chars</code>, based on just the <code>charset_table</code>.</p>
<p>And because of <code>blend_chars</code> settings, the following three <em>extra</em> tokens get stored: <code>@rihanna</code>, <code>procter&amp;gamble</code>, and <code>u.s.a</code>. Regular characters are still case-folded according to <code>charset_table</code>, but those special blended characters are now preserved. As opposed to being treated as whitespace, like they were in the base split. So far so good.</p>
<p>But why not just add <code>@, &amp;, .</code> to <code>charset_table</code> then? Because that way we would completely lose the base split. <em>Only</em> the three “magic” tokens like <code>@rihanna</code> would be stored. And then searching for their “parts” (for example, for just <code>rihanna</code> or just <code>gamble</code>) would not work. Meh.</p>
<p>Last but not least, the in-field token positions are adjusted accordingly, and shared between the base and extra tokens:</p>
<ul>
<li>pos 1, <code>rihanna</code> and <code>@rihanna</code></li>
<li>pos 2, <code>procter</code> and <code>procter&amp;gamble</code></li>
<li>pos 3, <code>gamble</code></li>
<li>pos 4, <code>u</code> and <code>u.s.a</code></li>
<li>pos 5, <code>s</code></li>
<li>pos 6, <code>a</code></li>
</ul>
<p>Bottom line, <code>blend_chars</code> lets you enrich the index and store extra tokens with special characters in those. That might be a handy addition to your regular tokenization based on <code>charset_table</code>.</p>
<h3 id="mixed-codes-with-letters-and-digits">Mixed codes (with letters and digits)</h3>
<p>To index <strong>mixed codes</strong>, i.e. terms that mix letters and digits, you need to enable <code>blend_mixed_codes = 1</code> setting (and reindex).</p>
<p>That way Sphinx adds extra spaces on <em>letter-digit boundaries</em> when making the base split, but still stores the full original token as an extra. For example, <code>UE53N5740AU</code> gets broken down to as much as 5 parts:</p>
<ul>
<li>pos 1, <code>ue</code> and <code>ue53n5740au</code></li>
<li>pos 2, <code>53</code></li>
<li>pos 3, <code>n</code></li>
<li>pos 4, <code>5740</code></li>
<li>pos 5, <code>au</code></li>
</ul>
<p>Besides the “full” split and the “original” code, it is also possible to store prefixes and suffixes. See <code>blend_mode</code> discussion just below.</p>
<p>Also note that on certain input data mixed codes indexing can generate a lot of undesired noise tokens. So when you have a number of fields with special terms that do <em>not</em> need to be processed as mixed codes (consider either terms like <code>_category1234</code>, or just long URLs), you can use the <code>mixed_codes_fields</code> directive and limit mixed codes indexing to human-readable text fields only. For instance:</p>
<pre><code>blend_mixed_codes = 1
mixed_codes_fields = title, content</code></pre>
<p>That could save you a noticeable amount of both index size and indexing time.</p>
<h3 id="blending-modes">Blending modes</h3>
<p>There’s somewhat more than one way to generate extra tokens. So there is a directive to control that. It’s called <code>blend_mode</code> and it lets you list all the different processing variants that you require:</p>
<ul>
<li><code>trim_none</code>, store a full token with all the blended characters;</li>
<li><code>trim_head</code>, store a token with heading blended characters trimmed;</li>
<li><code>trim_tail</code>, store a token with trailing blended characters trimmed;</li>
<li><code>trim_both</code>, store a token with both heading and trailing blended characters trimmed;</li>
<li><code>skip_pure</code>, do <em>not</em> store tokens that only contain blended characters;</li>
<li><code>prefix_tokens</code>, store all possible prefix tokens;</li>
<li><code>suffix_tokens</code>, store all possible suffix tokens.</li>
</ul>
<p>To visualize all those trims a bit, consider the following setup:</p>
<pre><code>blend_chars = @, !
blend_mode = trim_none, trim_head, trim_tail, trim_both

doc_title = @someone!</code></pre>
<p>Quite a bunch of extra tokens will be indexed in this case:</p>
<ul>
<li><code>someone</code> for the base split;</li>
<li><code>@someone!</code> for <code>trim_none</code>;</li>
<li><code>someone!</code> for <code>trim_head</code>;</li>
<li><code>@someone</code> for <code>trim_tail</code>;</li>
<li><code>someone</code> (yes, again) for <code>trim_both</code>.</li>
</ul>
<p><code>trim_both</code> option might seem redundant here for a moment. But do consider a bit more complicated term like <code>&amp;U.S.A!</code> where all the special characters are blended. It’s base split is three tokens (<code>u</code>, <code>s</code>, and <code>a</code>); it’s original full form (stored for <code>trim_none</code>) is lower-case <code>&amp;u.s.a!</code>; and so for this term <code>trim_both</code> is the only way to still generate the cleaned-up <code>u.s.a</code> variant.</p>
<p><code>prefix_tokens</code> and <code>suffix_tokens</code> actually begin to generate something non-trivial on that very same <code>&amp;U.S.A!</code> example, too. For the record, that’s because its base split is long enough, 3 or more tokens. <code>prefix_tokens</code> would be the only way to store the (useful) <code>u.s</code> prefix; and <code>suffix_tokens</code> would in turn store the (questionable) <code>s.a</code> suffix.</p>
<p>But <code>prefix_tokens</code> and <code>suffix_tokens</code> modes are, of course, especially useful for indexing mixed codes. The following gets stored with <code>blend_mode = prefix_tokens</code> in our running example:</p>
<ul>
<li>pos 1, <code>ue</code>, <code>ue53</code>, <code>ue53n</code>, <code>ue53n5740</code>, and <code>ue53n5740au</code></li>
<li>pos 2, <code>53</code></li>
<li>pos 3, <code>n</code></li>
<li>pos 4, <code>5740</code></li>
<li>pos 5, <code>au</code></li>
</ul>
<p>And with <code>blend_mode = suffix_tokens</code> respectively:</p>
<ul>
<li>pos 1, <code>ue</code> and <code>ue53n5740au</code></li>
<li>pos 2, <code>53</code> and <code>53n5740au</code></li>
<li>pos 3, <code>n</code> and <code>n5740au</code></li>
<li>pos 4, <code>5740</code> and <code>5740au</code></li>
<li>pos 5, <code>au</code></li>
</ul>
<p>Of course, there still can be missing combinations. For instance, <code>ue 53n</code> query will still not match any of that. However, for now we intentionally decided to avoid indexing <em>all</em> the possible base token subsequences, as that seemed to produce way too much noise.</p>
<h3 id="searching-vs-blended-tokens-and-mixed-codes">Searching vs blended tokens and mixed codes</h3>
<p>The rule of thumb is quite simple. All the extra tokens are <strong>indexing-only</strong>. And in queries, all tokens are treated “as is”.</p>
<p><strong>Blended characters</strong> are going to be handled as valid characters in the queries, and <em>require</em> matching.</p>
<p>For example, querying for <code>"@rihanna"</code> will <em>not</em> match <code>Robyn Rihanna Fenty is a Barbadian-born singer</code> document. However, querying for just <code>rihanna</code> will match both that document, and <code>@rihanna doesn't tweet all that much</code> document.</p>
<p><strong>Mixed codes</strong> are <em>not</em> going to be automatically “sliced” in the queries.</p>
<p>For example, querying for <code>UE53</code> will <em>not</em> automatically match neither <code>UE 53</code> nor <code>UE 37 53</code> documents. You need to manually add extra whitespace into your query term for that.</p>
<h2 id="searching-query-syntax">Searching: query syntax</h2>
<p>By default, full-text queries in Sphinx are treated as simple “bags of words”, and all keywords are required in a document to match. In other words, by default we perform a strict boolean AND over all keywords.</p>
<p>However, text queries are much more flexible than just that, and Sphinx has its own full-text query language to expose that flexibility.</p>
<p>You essentially use that language <em>within</em> the <code>MATCH()</code> clause in your <code>SELECT</code> statements. So in this section, when we refer to just the <code>hello world</code> (text) query for brevity, the actual complete SphinxQL statement that you would run is something like <code>SELECT *, WEIGHT() FROM myindex WHERE MATCH('hello world')</code>.</p>
<p>That said, let’s begin with a couple key concepts, and a cheat sheet.</p>
<h3 id="operators">Operators</h3>
<p>Operators generally work on arbitrary subexpressions. For instance, you can combine keywords using operators AND and OR (and brackets) as needed, and build any boolean expression that way.</p>
<p>However, there is a number of exceptions. Not all operators are universally compatible. For instance, phrase operator (double quotes) naturally only works on keywords. You can’t build a “phrase” from arbitrary boolean expressions.</p>
<p>Some of the operators use special characters, like the phrase operator uses double quotes: <code>"this is phrase"</code>. Thus, sometimes you might have to filter out a few special characters from end-user queries, to avoid unintentionally triggering those operators.</p>
<p>Other ones are literal, and their syntax is an all-caps keyword. For example, MAYBE operator would quite literally be used as <code>(rick MAYBE morty)</code> in a query. To avoid triggering those operators, it should be sufficient to lower-case the query: <code>rick maybe morty</code> is again just a regular bag-of-words query that just requires all 3 keywords to match.</p>
<h3 id="modifiers">Modifiers</h3>
<p>Modifiers are attached to individual keywords, and they must work at all times, and must be allowed within any operator. So no compatibility issues there!</p>
<p>A couple examples would be the exact form modifier or the field start modifier, <code>=exact ^start</code>. They limit matching of “their” keyword to either its exact morphological form, or at the very start of (any) field, respectively.</p>
<h3 id="cheat-sheet">Cheat sheet</h3>
<p>As of v.3.2, there are just 4 per-keyword modifiers.</p>
<table>
<thead>
<tr class="header">
<th>Modifier</th>
<th>Example</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>exact form</td>
<td><code>=cats</code></td>
<td>Only match this exact form, needs <code>index_exact_words</code></td>
</tr>
<tr class="even">
<td>field start</td>
<td><code>^hello</code></td>
<td>Only match at the very start of (any) field</td>
</tr>
<tr class="odd">
<td>field end</td>
<td><code>world$</code></td>
<td>Only match at the very end of (any) field</td>
</tr>
<tr class="even">
<td>IDF boost</td>
<td><code>boost^1.23</code></td>
<td>Multply keyword IDF by a given value when ranking</td>
</tr>
</tbody>
</table>
<p>The operators are a bit more interesting!</p>
<table style="width:100%;">
<colgroup>
<col style="width: 16%" />
<col style="width: 28%" />
<col style="width: 54%" />
</colgroup>
<thead>
<tr class="header">
<th>Operator</th>
<th>Example</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>brackets</td>
<td><code>(one two)</code></td>
<td>Group a subexpression</td>
</tr>
<tr class="even">
<td>AND</td>
<td><code>one two</code></td>
<td>Match both args</td>
</tr>
<tr class="odd">
<td>OR</td>
<td><code>one | two</code></td>
<td>Match any arg</td>
</tr>
<tr class="even">
<td>term-OR</td>
<td><code>one || two</code></td>
<td>Match any keyword, and reuse in-query position</td>
</tr>
<tr class="odd">
<td>NOT</td>
<td><code>one -two</code></td>
<td>Match 1st arg, but exclude matches of 2nd arg</td>
</tr>
<tr class="even">
<td>NOT</td>
<td><code>one !two</code></td>
<td>Match 1st arg, but exclude matches of 2nd arg</td>
</tr>
<tr class="odd">
<td>MAYBE</td>
<td><code>one MAYBE two</code></td>
<td>Match 1st arg, but include 2nd arg when ranking</td>
</tr>
<tr class="even">
<td>field limit</td>
<td><code>@title one @body two</code></td>
<td>Limit matching to a given field</td>
</tr>
<tr class="odd">
<td>fields limit</td>
<td><code>@(title,body) test</code></td>
<td>Limit matching to given fields</td>
</tr>
<tr class="even">
<td>fields limit</td>
<td><code>@!(phone,year) test</code></td>
<td>Limit matching to all but given fields</td>
</tr>
<tr class="odd">
<td>fields limit</td>
<td><code>@* test</code></td>
<td>Reset any previous field limits</td>
</tr>
<tr class="even">
<td>position limit</td>
<td><code>@title[50] test</code></td>
<td>Limit matching to N first positions in a field</td>
</tr>
<tr class="odd">
<td>phrase</td>
<td><code>"one two"</code></td>
<td>Match all keywords as an (exact) phrase</td>
</tr>
<tr class="even">
<td>phrase</td>
<td><code>"one * * four"</code></td>
<td>Match all keywords as an (exact) phrase</td>
</tr>
<tr class="odd">
<td>proximity</td>
<td><code>"one two"~3</code></td>
<td>Match all keywords within a proximity window</td>
</tr>
<tr class="even">
<td>quorum</td>
<td><code>"uno due tre"/2</code></td>
<td>Match any N out of all keywords</td>
</tr>
<tr class="odd">
<td>quorum</td>
<td><code>"uno due tre"/0.7</code></td>
<td>Match any given fraction of all keywords</td>
</tr>
<tr class="even">
<td>BEFORE</td>
<td><code>one &lt;&lt; two</code></td>
<td>Match args in this specific order only</td>
</tr>
<tr class="odd">
<td>NEAR</td>
<td><code>one NEAR/3 "two three"</code></td>
<td>Match args in any order within a given distance</td>
</tr>
<tr class="even">
<td>SENTENCE</td>
<td><code>one SENTENCE "two three"</code></td>
<td>Match args in one sentence; needs <code>index_sp</code></td>
</tr>
<tr class="odd">
<td>PARAGRAPH</td>
<td><code>one PARAGRAPH two</code></td>
<td>Match args in one paragraph; needs <code>index_sp</code></td>
</tr>
<tr class="even">
<td>ZONE</td>
<td><code>ZONE:(h3,h4) one two</code></td>
<td>Match in given zones only; needs <code>index_zones</code></td>
</tr>
<tr class="odd">
<td>ZONESPAN</td>
<td><code>ZONESPAN:(h3,h4) one two</code></td>
<td>Match in contiguous spans only; needs <code>index_zones</code></td>
</tr>
</tbody>
</table>
<p>Now let’s discuss all these modifiers and operators in a bit more detail.</p>
<h3 id="keyword-modifiers">Keyword modifiers</h3>
<p><strong>Exact form</strong> modifier is only applicable when morphology (ie. either stemming or lemmatizaion) is enabled. With morphology on, Sphinx searches for normalized keywords by default. This modifier lets you search for an exact original form. It requires <code>index_exact_words</code> setting to be enabled.</p>
<p>The syntax is <code>=</code> at the keyword start.</p>
<pre><code>=exact</code></pre>
<p>For the sake of an example, assume that English stemming is enabled, ie. that the index was configured with <code>morphology = stem_en</code> setting. Also assume that we have these three sample documents:</p>
<pre><code>id, content
1, run
2, runs
3, running</code></pre>
<p>Without <code>index_exact_words</code>, only the normalized form, namely <code>run</code>, is stored into the index for every document. Even with the modifier, it is impossible to differentiate between them.</p>
<p>With <code>index_exact_words = 1</code>, both the normalized and original keyword forms are stored into the index. However, by default the keywords are also normalized when searching. So a query <code>runs</code> will get normalized to <code>run</code>, and will still match all 3 documents.</p>
<p>And finally, with <code>index_exact_words = 1</code> and with the exact form modifier, a query like <code>=runs</code> will be able to match just the original form, and return just the document #2.</p>
<p>For convenience, you can also apply this particular modifier to an entire phrase operator, and it will propagate down to all keywords.</p>
<pre><code>=&quot;runs down the hills&quot;
&quot;=runs =down =the =hills&quot;</code></pre>
<p><strong>Field start modifier</strong> makes the keyword match if and only if it occurred at the very beginning of (any) full-text field. (Technically, it will only match postings with an in-field position of 1.)</p>
<p>The syntax is <code>^</code> at the keyword start, mimicked after regexps.</p>
<pre><code>^fieldstart</code></pre>
<p><strong>Field end modifier</strong> makes the keyword match if and only if it occurred at the very end of (any) full-text field. (Technically, it will only match postings with a special internal “end-of-field” flag.)</p>
<p>The syntax is <code>$</code> at the keyword start, mimicked after regexps.</p>
<pre><code>fieldend$</code></pre>
<p><strong>IDF boost modifier</strong> lets you adjust the keyword IDF value (used for ranking), it multiples the IDF value by a given constant. That affects a number of ranking factors that build upon the IDF. That in turn also affects default ranking.</p>
<p>The syntax is <code>^</code> followed by a scale constant. Scale must be non-negative and must start with a digit or a dot. Scale can be zero, both <code>^0</code> and <code>^0.0</code> should be legal.</p>
<pre><code>boostme^1.23</code></pre>
<h3 id="boolean-operators-brackets-and-or-not">Boolean operators (brackets, AND, OR, NOT)</h3>
<p>These let you implement grouping (with brackets) and classic boolean logic. The respective formal syntax is as follows:</p>
<ul>
<li>brackets: <code>(expr1)</code></li>
<li>AND: <code>expr1 expr2</code></li>
<li>OR: <code>expr1 | expr2</code></li>
<li>NOT: <code>-expr1</code> or <code>!expr1</code></li>
</ul>
<p>Where <code>expr1</code> and <code>expr2</code> are either keywords, or any other computable text query expressions. Here go a few query examples showing all of the operators.</p>
<pre><code>(shaken !stirred)
&quot;barack obama&quot; (alaska | california | texas | &quot;new york&quot;)
one -(two | (three -four))</code></pre>
<p>Nothing too exciting to see here. But still there are a few quirks worth a quick mention. Here they go, in no particular order.</p>
<p><strong>OR operator precedence is higher than AND.</strong></p>
<p>In other words, ORs take priority, they are evaluated first, ANDs are then evaluated on top of ORs. Thus, <code>looking for cat | dog | mouse</code> query is equivalent to <code>looking for (cat | dog | mouse)</code>, and <em>not</em> <code>(looking for cat) | dog | mouse</code>.</p>
<p><strong>ANDs are implicit.</strong></p>
<p>There isn’t any explicit syntax for them in Sphinx. Just put two expressions right next to each other, and that’s it.</p>
<p><strong>No all-caps versions for AND/OR/NOT, those are valid keywords.</strong></p>
<p>So something like <code>rick AND morty</code> is equivalent to <code>rick and morty</code>, and both these queries require all 3 keywords to match, including that literal <code>and</code>.</p>
<p>Notice the difference in behavior between this, and, say, <code>rick MAYBE morty</code>, where the syntax for operator MAYBE is that all-caps keyword.</p>
<p><strong>Field and zone limits affect the entire (sub)expression.</strong></p>
<p>Meaning that <code>@title</code> limit in a <code>@title hello world</code> query applies to all keywords, not just a keyword or expression immediately after the limit operator. Both keywords in this example would need to match in the <code>title</code> field, not only the first <code>hello</code>. An explicit way to write this query, with an explicit field limit for every keyword, would be <code>(@title hello) (@title world)</code>.</p>
<p><strong>Brackets push and pop field and zone limits.</strong></p>
<p>For example, <code>(@title hello) world</code> query requires <code>hello</code> to be matched in <code>title</code> only. But that limit ends on a closing bracket, and <code>world</code> can then match anywhere in the document again. Therefore <em>this</em> query is equivalent to something like <code>(@title hello) (@* world)</code>.</p>
<p>Even more curiously, but quite predictably, <code>@body (@title hello) world</code> query would in turn be equivalent to <code>(@title hello) (@body world)</code>. The first <code>@body</code> limit gets pushed on an opening bracket, and then restored on a closing one.</p>
<p>Sames rules apply to zones, see <code>ZONE</code> and <code>ZONESPAN</code> operators below.</p>
<p><strong>In-query positions in boolean operators are sequential.</strong></p>
<p>And while those do not affect <em>matching</em> (aka text based filtering), they do noticeably affect <em>ranking</em>. For example, even if you splice a phrase with ORs, a rather important “phrase match degree” ranking factor (the one called ‘lcs’) does not change at all, even though matching changes quite a lot:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb59-1"><a href="#cb59-1"></a>mysql<span class="op">&gt;</span> <span class="kw">select</span> <span class="kw">id</span>, weight(), title <span class="kw">from</span> test1</span>
<span id="cb59-2"><a href="#cb59-2"></a>  <span class="kw">where</span> match(<span class="st">&#39;@title little black dress&#39;</span>);</span>
<span id="cb59-3"><a href="#cb59-3"></a><span class="op">+</span><span class="co">--------+----------+--------------------+</span></span>
<span id="cb59-4"><a href="#cb59-4"></a>| <span class="kw">id</span>     | weight() | title              |</span>
<span id="cb59-5"><a href="#cb59-5"></a><span class="op">+</span><span class="co">--------+----------+--------------------+</span></span>
<span id="cb59-6"><a href="#cb59-6"></a>| <span class="dv">334757</span> |     <span class="dv">3582</span> | Little black dress |</span>
<span id="cb59-7"><a href="#cb59-7"></a><span class="op">+</span><span class="co">--------+----------+--------------------+</span></span>
<span id="cb59-8"><a href="#cb59-8"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.01</span> sec)</span>
<span id="cb59-9"><a href="#cb59-9"></a></span>
<span id="cb59-10"><a href="#cb59-10"></a>mysql<span class="op">&gt;</span> <span class="kw">select</span> <span class="kw">id</span>, weight(), title <span class="kw">from</span> test1</span>
<span id="cb59-11"><a href="#cb59-11"></a>  <span class="kw">where</span> match(<span class="st">&#39;@title little | black | dress&#39;</span>);</span>
<span id="cb59-12"><a href="#cb59-12"></a><span class="op">+</span><span class="co">--------+----------+------------------------+</span></span>
<span id="cb59-13"><a href="#cb59-13"></a>| <span class="kw">id</span>     | weight() | title                  |</span>
<span id="cb59-14"><a href="#cb59-14"></a><span class="op">+</span><span class="co">--------+----------+------------------------+</span></span>
<span id="cb59-15"><a href="#cb59-15"></a>| <span class="dv">334757</span> |     <span class="dv">3582</span> | Little black dress     |</span>
<span id="cb59-16"><a href="#cb59-16"></a>| <span class="dv">420209</span> |     <span class="dv">2549</span> | Little Black Backpack. |</span>
<span id="cb59-17"><a href="#cb59-17"></a><span class="op">..</span>.</span></code></pre></div>
<p>So in a sense, everything you construct using brackets and operators still looks like a single huge “phrase” (bag of words, really) to the ranking code. As if there were no brackets and no operators.</p>
<p><strong>Operator NOT is really operator ANDNOT.</strong></p>
<p>While a query like <code>-something</code> technically can be computed, more often than not such a query is just a programming error. And a potentially expensive one at that, because an implicit list of <em>all</em> the documents in the index could be quite big. Here go a few examples.</p>
<pre><code>// correct query, computable at every level
aaa -(bbb -(ccc ddd))

// non-computable queries
-aaa
aaa | -bbb</code></pre>
<p>(On a side note, that might also raise the philosophical question of ranking documents that contain zero matched keywords; thankfully, from an engineering perspective it would be extremely easy to brutally cut that Gordian knot by merely setting the weight to zero, too.)</p>
<p>For that reason, NOT operator requires something computable to its left. An isolated NOT will raise a query error. In case that you <em>absolutely</em> must, you can append some special magic keyword (something like <code>__allmydocs</code>, to your taste) to all your documents when indexing. Two example non-computable queries just above would then become:</p>
<pre><code>(__allmydocs -aaa)
aaa | (__allmydocs -bbb)</code></pre>
<p><strong>Operator NOT only works at term start.</strong></p>
<p>In order to trigger, it must be preceded with a whitespace, or a bracket, or other clear keyword boundary. For instance, <code>cat-dog</code> is by default actually equivalent to merely <code>cat dog</code>, while <code>cat -dog</code> with a space does apply the operator NOT to <code>dog</code>.</p>
<h3 id="phrase-operator">Phrase operator</h3>
<p>Phrase operator uses the de-facto standard double quotes syntax and basically lets you search for an exact phrase, ie. several keywords in this exact order, without any gaps between them. For example.</p>
<pre><code>&quot;mary had a little lamb&quot;</code></pre>
<p>Yep, boring. But of course there is a bit more even to this simple operator.</p>
<p><strong>Exact form modifier works on the entire operator.</strong> Of course, any modifiers must work within a phrase, that’s what modifiers are all about. But with exact form modifiers there’s extra syntax sugar that lets you apply it to the entire phrase at once: <code>="runs down the hills"</code> form is a bit easier to write than <code>"=runs =down =the =hills"</code>.</p>
<p><strong>Standalone star “matches” any keyword.</strong> Or rather, they skip that position when matching the phrase. Text queries do not really work with document texts. They work with just the specified keywords, and analyze their in-document and in-query positions. Now, a special star token within a phrase operator will not actually match anything, it will simply adjust the query position when parsing the query. So there will be no impact on search performance at all, but the phrase keyword positions will be shifted. For example.</p>
<pre><code>&quot;mary had * * lamb&quot;</code></pre>
<p><strong>Stopwords “match” any keyword.</strong> The very same logic applies to stopwords. Stopwords are not even stored in the index, so we have nothing to match. But even on stopwords, we still need adjust both the in-document positions when indexing, and in-query positions when matching.</p>
<p>This sometimes causes a little counter-intuitive and unexpected (but inevitable!) matching behavior. Consider the following set of documents:</p>
<pre><code>id, content
1, Microsoft Office 2016
2, we are using a lot of software from Microsoft in the office
3, Microsoft opens another office in the UK</code></pre>
<p>Assume that <code>in</code> and <code>the</code> are our only stopwords. What documents would be matched by the following two phrase queries?</p>
<ol type="1">
<li><code>"microsoft office"</code></li>
<li><code>"microsoft in the office"</code></li>
</ol>
<p>Query #1 only matches document #1, no big surprise there. However, as we just discussed, query #2 is in fact equivalent to <code>"microsoft * * office"</code>, because of stopwords. And so it matches both documents #2 and #3.</p>
<h3 id="maybe-operator">MAYBE operator</h3>
<p>Operator MAYBE is occasionally needed for ranking. It takes two arbitrary expressions, and only requires the first one to match, but uses the (optional) matches of the second expression for ranking.</p>
<pre><code>expr1 MAYBE expr2</code></pre>
<p>For instance, <code>rick MAYBE morty</code> query matches exactly the same documents as just <code>rick</code>, but with that extra MAYBE, documents that mention both <code>rick</code> and <code>morty</code> will get ranked higher.</p>
<p>Arbitrary expressions are supported, so this is also valid:</p>
<pre><code>rick MAYBE morty MAYBE (season (one || two || three) -four&#39;)</code></pre>
<h3 id="term-or-operator">Term-OR operator</h3>
<p>Term-OR operator (double pipe) essentially lets you specify “properly ranked” per-keyword synonyms at query time.</p>
<p>Matching-wise, it just does regular boolean OR over several keywords, but ranking-wise (and unlike the regular OR operator), it does <em>not</em> increment their in-query positions. That keeps any positional ranking factors intact.</p>
<p>Naturally, it only accepts individual keywords, you can not term-OR a keyword and a phrase or any other expression. Also, term-OR is currently not supported within phrase or proximity operators, though that is an interesting possibility.</p>
<p>It should be easiest to illustrate it with a simple example. Assume we are still searching for that little black dress, as we did in our example on the regular OR operator.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb67-1"><a href="#cb67-1"></a>mysql<span class="op">&gt;</span> <span class="kw">select</span> <span class="kw">id</span>, weight(), title <span class="kw">from</span> rt</span>
<span id="cb67-2"><a href="#cb67-2"></a>  <span class="kw">where</span> match(<span class="st">&#39;little black dress&#39;</span>);</span>
<span id="cb67-3"><a href="#cb67-3"></a><span class="op">+</span><span class="co">------+----------+-----------------------------------------------+</span></span>
<span id="cb67-4"><a href="#cb67-4"></a>| <span class="kw">id</span>   | weight() | title                                         |</span>
<span id="cb67-5"><a href="#cb67-5"></a><span class="op">+</span><span class="co">------+----------+-----------------------------------------------+</span></span>
<span id="cb67-6"><a href="#cb67-6"></a>|    <span class="dv">1</span> |     <span class="dv">3566</span> | little black dress                            |</span>
<span id="cb67-7"><a href="#cb67-7"></a>|    <span class="dv">3</span> |     <span class="dv">1566</span> | huge black<span class="op">/</span>charcoal dress <span class="kw">with</span> a little white |</span>
<span id="cb67-8"><a href="#cb67-8"></a><span class="op">+</span><span class="co">------+----------+-----------------------------------------------+</span></span>
<span id="cb67-9"><a href="#cb67-9"></a><span class="dv">2</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>So far so good. But looks like <code>charcoal</code> is a synonym that we could use here. Let’s try to use it using the regular OR operator.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb68-1"><a href="#cb68-1"></a>mysql<span class="op">&gt;</span> <span class="kw">select</span> <span class="kw">id</span>, weight(), title <span class="kw">from</span> rt</span>
<span id="cb68-2"><a href="#cb68-2"></a>  <span class="kw">where</span> match(<span class="st">&#39;little black|charcoal dress&#39;</span>);</span>
<span id="cb68-3"><a href="#cb68-3"></a><span class="op">+</span><span class="co">------+----------+-----------------------------------------------+</span></span>
<span id="cb68-4"><a href="#cb68-4"></a>| <span class="kw">id</span>   | weight() | title                                         |</span>
<span id="cb68-5"><a href="#cb68-5"></a><span class="op">+</span><span class="co">------+----------+-----------------------------------------------+</span></span>
<span id="cb68-6"><a href="#cb68-6"></a>|    <span class="dv">3</span> |     <span class="dv">3632</span> | huge black<span class="op">/</span>charcoal dress <span class="kw">with</span> a little white |</span>
<span id="cb68-7"><a href="#cb68-7"></a>|    <span class="dv">1</span> |     <span class="dv">2566</span> | little black dress                            |</span>
<span id="cb68-8"><a href="#cb68-8"></a>|    <span class="dv">2</span> |     <span class="dv">2566</span> | little charcoal dress                         |</span>
<span id="cb68-9"><a href="#cb68-9"></a><span class="op">+</span><span class="co">------+----------+-----------------------------------------------+</span></span>
<span id="cb68-10"><a href="#cb68-10"></a><span class="dv">3</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>Oops, what just happened? We now also match document #2, which is good, but why is the document #3 ranked so high all of a sudden?</p>
<p>That’s because with regular ORs ranking would, basically, look for the entire query as if without any operators, ie. the ideal phrase match would be not just <code>"little black dress"</code>, but the entire <code>"little black charcoal dress"</code> query with all special operators removed.</p>
<p>There is no such a “perfect” 4 keyword full phrase match in our small test database. (If there was, it would get top rank.) From the phrase ranking point of view, the next kinda-best thing to it is the <code>"black/charcoal dress"</code> part, where a 3 keyword subphrase matches the query. And that’s why it gets ranked higher that <code>"little black dress"</code>, where the longest common subphrase between the document and the query is <code>"little black"</code>, only 2 keywords long, not 3.</p>
<p>But that’s not what we wanted in this case at all; we just wanted to introduce a synonym for <code>black</code>, rather than break ranking! And that’s exactly what term-OR operator is for.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb69-1"><a href="#cb69-1"></a>mysql<span class="op">&gt;</span> <span class="kw">select</span> <span class="kw">id</span>, weight(), title <span class="kw">from</span> rt</span>
<span id="cb69-2"><a href="#cb69-2"></a>  <span class="kw">where</span> match(<span class="st">&#39;little black||charcoal dress&#39;</span>);</span>
<span id="cb69-3"><a href="#cb69-3"></a><span class="op">+</span><span class="co">------+----------+-----------------------------------------------+</span></span>
<span id="cb69-4"><a href="#cb69-4"></a>| <span class="kw">id</span>   | weight() | title                                         |</span>
<span id="cb69-5"><a href="#cb69-5"></a><span class="op">+</span><span class="co">------+----------+-----------------------------------------------+</span></span>
<span id="cb69-6"><a href="#cb69-6"></a>|    <span class="dv">1</span> |     <span class="dv">3566</span> | little black dress                            |</span>
<span id="cb69-7"><a href="#cb69-7"></a>|    <span class="dv">2</span> |     <span class="dv">3566</span> | little charcoal dress                         |</span>
<span id="cb69-8"><a href="#cb69-8"></a>|    <span class="dv">3</span> |     <span class="dv">2632</span> | huge black<span class="op">/</span>charcoal dress <span class="kw">with</span> a little white |</span>
<span id="cb69-9"><a href="#cb69-9"></a><span class="op">+</span><span class="co">------+----------+-----------------------------------------------+</span></span>
<span id="cb69-10"><a href="#cb69-10"></a><span class="dv">3</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>Good, ranking is back to expected. Both the original exact match <code>"little black dress"</code> and synonymical <code>"little charcoal dress"</code> are now at the top again, because of a perfect phrase match (which is favored by the default ranker).</p>
<p>Note that while all the examples above revolved around a single positional factor <code>lcs</code> (which is used in the default ranker), there are more positional factors than just that. See the section on <a href="#ranking-factors">Ranking factors</a> for more details.</p>
<h3 id="field-and-position-limit-operator">Field and position limit operator</h3>
<p>Field limit operator limits matching of the subsequent expressions to a given field, or a set of fields. Field names must exist in the index, otherwise the query will fail with an error.</p>
<p>There are several syntax forms available.</p>
<ol type="1">
<li><p><code>@field</code> limits matching to a single given field. This is the simplest form. <code>@(field)</code> is also valid.</p></li>
<li><p><code>@(f1,f2,f3)</code> limits matching to multiple given fields. Note that the match might happen just partially in one of the fields. For example, <code>@(title,body) hello world</code> does <em>not</em> require that both keywords match in the very same field! Document like <code>{"id":123, "title":"hello", "body":"world"}</code> (pardon my JSON) does match this query.</p></li>
<li><p><code>@!(f1,f2,f3)</code> limits matching to all the fields <em>except</em> given ones. This can be useful to avoid matching end-user queries against some internal system fields, for one. <code>@!f1</code> is also valid syntax in case you want to skip just the one field.</p></li>
<li><p><code>@*</code> syntax resets any previous limits, and re-enables matching all fields.</p></li>
</ol>
<p>In addition, all forms except <code>@*</code> can be followed by an optional <code>[N]</code> clause, which limits the matching to <code>N</code> first tokens (keywords) within a field. All of the examples below are valid:</p>
<ul>
<li><code>@title[50] test</code></li>
<li><code>@(title,body)[50] test</code></li>
<li><code>@!title[50] test</code></li>
</ul>
<p>To reiterate, field limits are “contained” by brackets, or more formally, any current limits are stored on an opening bracket, and restored on a closing one.</p>
<p>When in doubt, use <code>SHOW PLAN</code> to figure out what limits are actually used:</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb70-1"><a href="#cb70-1"></a>mysql<span class="op">&gt;</span> <span class="kw">set</span> profiling<span class="op">=</span><span class="dv">1</span>;</span>
<span id="cb70-2"><a href="#cb70-2"></a>  <span class="kw">select</span> <span class="op">*</span> <span class="kw">from</span> rt <span class="kw">where</span> match(<span class="st">&#39;(@title[50] hello) world&#39;</span>) <span class="kw">limit</span> <span class="dv">0</span>;</span>
<span id="cb70-3"><a href="#cb70-3"></a>  show <span class="kw">plan</span> \G</span>
<span id="cb70-4"><a href="#cb70-4"></a><span class="op">..</span>.</span>
<span id="cb70-5"><a href="#cb70-5"></a></span>
<span id="cb70-6"><a href="#cb70-6"></a><span class="op">***************************</span> <span class="fl">1.</span> <span class="kw">row</span> <span class="op">***************************</span></span>
<span id="cb70-7"><a href="#cb70-7"></a>Variable: transformed_tree</span>
<span id="cb70-8"><a href="#cb70-8"></a>   <span class="fu">Value</span>: <span class="kw">AND</span>(</span>
<span id="cb70-9"><a href="#cb70-9"></a>  <span class="kw">AND</span>(fields<span class="op">=</span>(title), max_field_pos<span class="op">=</span><span class="dv">50</span>, KEYWORD(hello, querypos<span class="op">=</span><span class="dv">1</span>)),</span>
<span id="cb70-10"><a href="#cb70-10"></a>  <span class="kw">AND</span>(KEYWORD(world, querypos<span class="op">=</span><span class="dv">2</span>)))</span>
<span id="cb70-11"><a href="#cb70-11"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>We can see that <code>@title</code> limit was only applied to <code>hello</code>, and reset back to matching all fields (and positions) on a closing bracket, as expected.</p>
<h3 id="proximity-and-near-operators">Proximity and NEAR operators</h3>
<p><strong>Proximity operator</strong> matches all the specified keywords, in any order, and allows for a number of gaps between those keywords. The formal syntax is as follows:</p>
<pre><code>&quot;keyword1 keyword2 ... keywordM&quot;~N</code></pre>
<p>Where <code>N</code> has a little weird meaning. It is the allowed number of gaps (other keywords) that can occur between those <code>M</code> specified keywords, but additionally incremented by 1.</p>
<p>For example, consider a document that reads <code>"Mary had a little lamb whose fleece was white as snow"</code>, and consider two queries: <code>"lamb fleece mary"~4</code>, and <code>"lamb fleece mary"~5</code>. We have exactly 4 extra words between <code>mary</code>, <code>lamb</code>, and <code>fleece</code>, namely those 4 are <code>had</code>, <code>a</code>, <code>little</code>, and <code>whose</code>. This means that the first query with <code>N = 4</code> will <em>not</em> match, because with <code>N = 4</code> the proximity operator actually allows for 3 gaps only, not 4. And thus the second example query will match, as with <code>N = 5</code> it allows for 4 gaps (plus 1 permutation).</p>
<p><strong>NEAR operator</strong> is a generalized version of proximity operator. Its syntax is:</p>
<pre><code>expr1 NEAR/N expr2</code></pre>
<p>Where <code>N</code> has the same meaning as in the proximity operator, the number of allowed gaps plus one. But with NEAR we can use arbitrary expressions, not just individual keywords.</p>
<pre><code>(binary | &quot;red black&quot;) NEAR/2 tree</code></pre>
<p>Left and right expressions can still match in any order. For example, a query <code>progress NEAR/2 bar</code> would match both these documents:</p>
<ol type="1">
<li><code>progress bar</code></li>
<li><code>a bar called Progress</code></li>
</ol>
<p>NEAR is left associative, meaning that <code>arg1 NEAR/X arg2 NEAR/Y arg3</code> will be evaluated as <code>(arg1 NEAR/X arg2) NEAR/Y arg3</code>. It has the same (lowest) precedence as BEFORE.</p>
<p>Note that while with just 2 keywords proximity and NEAR operators are identical (eg. <code>"one two"~N</code> and <code>one NEAR/N two</code> should behave exactly the same), with more keywords that is <em>not</em> the case.</p>
<p>Because when you stack multiple keywords with NEAR, then upto <code>N - 1</code> gaps are allowed per <em>each</em> keyword in the stack. Consider this example with two stacked NEAR operators: <code>one NEAR/3 two NEAR/3 three</code>. It allows for upto 2 gaps between <code>one</code> and <code>two</code>, and then for 2 more gaps between <code>two</code> and three. That’s less restrictive than the proximity operator with the same N (<code>"one two three"~3</code>), as the proximity operator will only allow 2 gaps total. So a document with <code>one aaa two bbb ccc three</code> text will match the NEAR query, but <em>not</em> the proximity query.</p>
<p>And vice versa, what if we bump the limit in proximity to match the total limit allowed by all NEARs? We get <code>"one two three"~5</code> (4 gaps allowed, plus that magic 1), so that anything that matches the NEARs variant would also match the proximity variant. But now a document <code>one two aaa bbb ccc ddd three</code> ceases to match the NEARs, because the gap between <code>two</code> and <code>three</code> is too big. And now the proximity operator becomes less restrictive.</p>
<p>Bottom line is, the proximity operator and a stack of NEARs are <em>not</em> really interchangeable, they match a bit different things.</p>
<h3 id="quorum-operator">Quorum operator</h3>
<p>Quorum matching operator essentially lets you perform fuzzy matching. It’s less strict than matching all the argument keywords. It will match all documents with at least N keywords present out of M total specified. Just like with proximity (or with AND), those N can occur in any order.</p>
<pre><code>&quot;keyword1 keyword2 ... keywordM&quot;/N
&quot;keyword1 keyword2 ... keywordM&quot;/fraction</code></pre>
<p>For a specific example, <code>"the world is a wonderful place"/3</code> will match all documents that have any 3 of the specified words, or more.</p>
<p>Naturally, N must be less or equal to M. Also, M must be anywhere from 1 to 256 keywords, inclusive. (Even though quorum with just 1 keyword makes little sense, that is allowed.)</p>
<p>Fraction must be from 0.0 to 1.0, more details below.</p>
<p>Quorum with <code>N = 1</code> is effectively equivalent to a stack of ORs, and can be used as syntax sugar to replace that. For instance, these two queries are equivalent:</p>
<pre><code>red | orange | yellow | green | blue | indigo | violet
&quot;red orange yellow green blue indigo violet&quot;/1</code></pre>
<p>Instead of an absolute number <code>N</code>, you can also specify a fraction, a floating point number between 0.0 and 1.0. In this case Sphinx will automatically compute <code>N</code> based on the number of keywords in the operator. This is useful when you don’t or can’t know the keyword count in advance. The example above can be rewritten as <code>"the world is a wonderful place"/0.5</code>, meaning that we want to match at least 50% of the keywords. As there are 6 words in this query, the autocomputed match threshold would also be 3.</p>
<p>Fractional threshold is rounded up. So with 3 keywords and a fraction of 0.5 we would get a final threshold of 2 keywords, as <code>3 * 0.5 = 1.5</code> rounds up as 2. There’s also a lower safety limit of 1 keyword, as matching zero keywords makes zero sense.</p>
<p>When the quorum threshold is too restrictive (ie. when N is greater than M), the operator gets automatically replaced with an AND operator. The same fallback happens when there are more than 256 keywords.</p>
<h3 id="strict-order-operator-before">Strict order operator (BEFORE)</h3>
<p>This operator enforces a strict “left to right” order (ie. the query order) on its arguments. The arguments can be arbitrary expressions. The syntax is <code>&lt;&lt;</code>, and there is no all-caps version.</p>
<pre><code>expr1 &lt;&lt; expr2</code></pre>
<p>For instance, <code>black &lt;&lt; cat</code> query will match a <code>black and white cat</code> document but <em>not</em> a <code>that cat was black</code> document.</p>
<p>Strict order operator has the lowest priority, same as NEAR operator.</p>
<p>It can be applied both to just keywords and more complex expressions, so the following is a valid query:</p>
<pre><code>(bag of words) &lt;&lt; &quot;exact phrase&quot; &lt;&lt; red|green|blue</code></pre>
<h3 id="sentence-and-paragraph-operators">SENTENCE and PARAGRAPH operators</h3>
<p>These operators match the document when both their arguments are within the same sentence or the same paragraph of text, respectively. The arguments can be either keywords, or phrases, or the instances of the same operator. (That is, you can stack several SENTENCE operators or PARAGRAPH operators. Mixing them is however not supported.) Here are a few examples:</p>
<pre><code>one SENTENCE two
one SENTENCE &quot;two three&quot;
one SENTENCE &quot;two three&quot; SENTENCE four</code></pre>
<p>The order of the arguments within the sentence or paragraph does not matter.</p>
<p>These operators require indexes built with <a href="sphinx2.html#conf-index-sp"><code>index_sp</code></a> setting (sentence and paragraph indexing feature) enabled, and revert to a mere AND otherwise. You can refer to documentation on <code>index_sp</code> for additional details on what’s considered a sentence or a paragraph.</p>
<h3 id="zone-and-zonespan-operators">ZONE and ZONESPAN operators</h3>
<p>Zone limit operator is a bit similar to field limit operator, but restricts matching to a given in-field zone (or a list of zones). The following syntax variants are supported:</p>
<pre><code>ZONE:h1 test
ZONE:(h2,h3) test
ZONESPAN:h1 test
ZONESPAN:(h2,h3) test</code></pre>
<p>Zones are named regions within a field. Essentially they map to HTML (or XML) markup. Everything between <code>&lt;h1&gt;</code> and <code>&lt;/h1&gt;</code> is in a zone called <code>h1</code> and could be matched by that <code>ZONE:h1 test</code> query.</p>
<p>Note that ZONE and ZONESPAN limits will get reset not only on a closing bracket, or on the next zone limit operator, but on a next <em>field</em> limit operator too! So make sure to specify zones explicitly for every field. Also, this makes operator <code>@*</code> a <em>full</em> reset, ie. it should reset both field and zone limits.</p>
<p>Zone limits require indexes built with zones support (see documentation on <a href="sphinx2.html#conf-index-zones"><code>index_zones</code></a> for a bit more details).</p>
<p>The difference between ZONE and ZONESPAN limit is that the former allows its arguments to match in multiple disconnected spans of the same zone, and the latter requires that all matching occurs within a single contiguous span.</p>
<p>For instance, <code>(ZONE:th hello world)</code> query <em>will</em> match this example document.</p>
<pre><code>&lt;th&gt;Table 1. Local awareness of Hello Kitty brand.&lt;/th&gt;
.. some table data goes here ..
&lt;th&gt;Table 2. World-wide brand awareness.&lt;/th&gt;</code></pre>
<p>In this example we have 2 spans of <code>th</code> zone, <code>hello</code> will match in the first one, and <code>world</code> in the second one. So in a sense ZONE works on a concatenation of all the zone spans.</p>
<p>And if you need to further limit matching to any of the individual contiguous spans, you should use the ZONESPAN operator. <code>(ZONESPAN:th hello world)</code> query does <em>not</em> match the document above. <code>(ZONESPAN:th hello kitty)</code> however does!</p>
<h2 id="searching-geosearches">Searching: geosearches</h2>
<p>Efficient geosearches are possible with Sphinx, and the related features are:</p>
<ul>
<li><code>GEODIST()</code> function that computes a distance between two geopoints</li>
<li><code>CONTAINS()</code> function that checks if a geopoint is inside a geopolygon</li>
<li><a href="#using-attribute-indexes">attribute indexes</a> that are used for fast, early distance checks</li>
</ul>
<p><strong>Attribute indexes for geosearches.</strong></p>
<p>When you create indexes on your latitude and longitude columns (and you should), query optimizer can utilize those in a few important <code>GEODIST()</code> usecases:</p>
<ol type="1">
<li>Single constant anchor case:</li>
</ol>
<div class="sourceCode" id="cb81"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb81-1"><a href="#cb81-1"></a><span class="kw">SELECT</span> GEODIST(lat,lon,$lat,$lon) dist <span class="op">..</span>.</span>
<span id="cb81-2"><a href="#cb81-2"></a>    <span class="kw">WHERE</span> dist <span class="op">&lt;=</span> $radius</span></code></pre></div>
<ol start="2" type="1">
<li>Multiple constant anchors case:</li>
</ol>
<div class="sourceCode" id="cb82"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb82-1"><a href="#cb82-1"></a><span class="kw">SELECT</span></span>
<span id="cb82-2"><a href="#cb82-2"></a>    GEODIST(lat,lon,$lat1,$lon1) dist1,</span>
<span id="cb82-3"><a href="#cb82-3"></a>    GEODIST(lat,lon,$lat2,$lon2) dist2,</span>
<span id="cb82-4"><a href="#cb82-4"></a>    GEODIST(lat,lon,$lat3,$lon3) dist3,</span>
<span id="cb82-5"><a href="#cb82-5"></a>    <span class="op">..</span>.,</span>
<span id="cb82-6"><a href="#cb82-6"></a>    (dist1 <span class="op">&lt;</span> $radius1 <span class="kw">OR</span> dist2 <span class="op">&lt;</span> $radius2 <span class="kw">OR</span> dist3 <span class="op">&lt;</span> $radius3 <span class="op">..</span>.) ok</span>
<span id="cb82-7"><a href="#cb82-7"></a><span class="kw">WHERE</span> ok<span class="op">=</span><span class="dv">1</span></span></code></pre></div>
<p>These cases are known to the query optimizer, and once it detects them, it can choose to perform an approximate attribute index read (or reads) first, instead of scanning the entire index. When the quick approximate read is selective enough, which frequently happens with small enough search distances, savings can be huge.</p>
<p>Case #1 handles your typical “give me everything close enough to a certain point” search. When the anchor point and radius are all constant, Sphinx will automatically precompute a bounding box that fully covers a “circle” with a required radius around that anchor point, ie. find some two internal min/max values for latitude and longitude, respectively. It will then quickly check attribute indexes statistics, and if the bounding box condition is selective enough, it will switch to attribute index reads instead of a full scan.</p>
<p>Here’s a working query example:</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb83-1"><a href="#cb83-1"></a><span class="kw">SELECT</span> <span class="op">*</span>, GEODIST(lat,lon,<span class="fl">55.7540</span>,<span class="fl">37.6206</span>,{<span class="kw">in</span><span class="op">=</span>deg,<span class="kw">out</span><span class="op">=</span>km}) <span class="kw">AS</span> dist</span>
<span id="cb83-2"><a href="#cb83-2"></a>  <span class="kw">FROM</span> myindex <span class="kw">WHERE</span> dist<span class="op">&lt;=</span><span class="dv">100</span></span></code></pre></div>
<p>Case #2 handles multi-anchor search, ie. “give me documents that are either close enough to point number 1, or to point number 2, etc”. The base approach is exactly the same, but <em>multiple</em> boundboxes are generated, multiple index reads are performed, and their results are all merged together.</p>
<p>Here’s another example:</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb84-1"><a href="#cb84-1"></a><span class="kw">SELECT</span> <span class="kw">id</span>,</span>
<span id="cb84-2"><a href="#cb84-2"></a>   GEODIST(lat, lon, <span class="fl">55.777</span>, <span class="fl">37.585</span>, {<span class="kw">in</span><span class="op">=</span>deg,<span class="kw">out</span><span class="op">=</span>km}) d1,</span>
<span id="cb84-3"><a href="#cb84-3"></a>   GEODIST(lat, lon, <span class="fl">55.569</span>, <span class="fl">37.576</span>, {<span class="kw">in</span><span class="op">=</span>deg,<span class="kw">out</span><span class="op">=</span>km}) d2,</span>
<span id="cb84-4"><a href="#cb84-4"></a>   geodist(lat, lon, <span class="fl">56.860</span>, <span class="fl">35.912</span>, {<span class="kw">in</span><span class="op">=</span>deg,<span class="kw">out</span><span class="op">=</span>km}) d3,</span>
<span id="cb84-5"><a href="#cb84-5"></a>   (d1<span class="op">&lt;</span><span class="dv">1</span> <span class="kw">OR</span> d2<span class="op">&lt;</span><span class="dv">1</span> <span class="kw">OR</span> d3<span class="op">&lt;</span><span class="dv">1</span>) ok</span>
<span id="cb84-6"><a href="#cb84-6"></a><span class="kw">FROM</span> myindex <span class="kw">WHERE</span> ok<span class="op">=</span><span class="dv">1</span></span></code></pre></div>
<p>Note that if we reformulate the queries a little, and the optimizer does not recognize the eligible cases any more, the optimization will <em>not</em> trigger. For example:</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb85-1"><a href="#cb85-1"></a><span class="kw">SELECT</span> <span class="op">*</span>, <span class="dv">2</span><span class="op">*</span>GEODIST(lat,lon,<span class="fl">55.7540</span>,<span class="fl">37.6206</span>,{<span class="kw">in</span><span class="op">=</span>deg,<span class="kw">out</span><span class="op">=</span>km})<span class="op">&lt;=</span><span class="dv">100</span> <span class="kw">AS</span> flag</span>
<span id="cb85-2"><a href="#cb85-2"></a>  <span class="kw">FROM</span> myindex <span class="kw">WHERE</span> flag<span class="op">=</span><span class="dv">1</span></span></code></pre></div>
<p>Obviously, “the boundbox optimization” is actually still feasible in this case, but the optimizer will not recognize that and switch to full scan.</p>
<p>To ensure whether these optimizations are working for you, use <code>EXPLAIN</code> on your query. Also, make sure the radius small enough when doing those checks.</p>
<p>Another interesting bit is that sometimes optimizer can quite <em>properly</em> choose to only use one index instead of two, or avoid using the indexes at all.</p>
<p>Say, what if our radius covers the entire country? All our documents will be within the boundbox anyway, and simple full scan will indeed be faster. That’s why you should use some “small enough” test radius with <code>EXPLAIN</code>.</p>
<p>Or say, what if we have another, super-selective <code>AND id=1234</code> condition in our query? Doing index reads will be just as extraneous, the optimizer will choose to perform a lookup by <code>id</code> instead.</p>
<h2 id="searching-vector-searches">Searching: vector searches</h2>
<p>You can implement vector searches with Sphinx and there are several different features intended for that, namely:</p>
<ul>
<li>fixed array attributes, eg. <code>rt_attr_int8_array = vec1[128]</code></li>
<li>JSON array attributes, eg. <code>{"vec2": int8[1,2,3,4]}</code></li>
<li><a href="#dot-function"><code>DOT()</code> function</a> to compute dot products</li>
<li><a href="#fvec-function"><code>FVEC()</code> function</a> to specify vector constants</li>
</ul>
<p>Let’s see how all these parts connect together.</p>
<p><strong>First, storage.</strong> You can store your per-document vectors using any of the following options:</p>
<ul>
<li>fixed-size fixed-type arrays, ie. <code>XXX_attr_YYY_array</code> directive</li>
<li>JSON arrays with implicit types, ie. regular <code>[1,2,3,4]</code> values in JSON</li>
<li>JSON arrays with explicit types, ie. <code>int8[1,2,3,4]</code> or <code>float[1,2,3,4]</code> syntax extensions</li>
</ul>
<p>Fixed arrays are the fastest to access, but not flexible at all. Also, they require some RAM per every document. For instance, a fixed array with 32 floats (<code>rt_attr_float_array = test1[32]</code>) will consume 128 bytes per <em>every</em> row, whether or not it contains any actual data (and arrays without any explicit data will be filled with zeroes).</p>
<p>JSON arrays are slower to access, and consume a bit more memory per row, but that memory is only consumed per <em>used</em> row. Meaning that when your vectors are defined sparsely (for, say, just 1M documents out of the entire 10M collection), then it might make sense to use JSON anyway to save some RAM.</p>
<p>JSON arrays are also “mixed” by default, that is, can contain values with arbitrary different types. With vector searches however you would normally want to use optimized arrays, with a single type attached to <em>all</em> values. Sphinx can auto-detect integer arrays in JSON, with values that fit into either int32 or int64 range, and store and later process them efficiently. However, to enforce either int8 or float type on a JSON array, you have to <em>explicitly</em> use our JSON syntax extensions.</p>
<p>To store an array of <code>float</code> values in JSON, you have to:</p>
<ul>
<li>either specify <code>float</code> type in each value with <code>1.234f</code> syntax (because by default <code>1.234</code> gets a <code>double</code> type in JSON), eg: <code>[1.0f, 2.0f, 3.0f]</code></li>
<li>or specify array type with <code>float[...]</code> syntax, eg: <code>float[1,2,3]</code></li>
</ul>
<p>To store an array of <code>int8</code> values (ie. from -128 to 127 inclusive) in JSON, the only option is to:</p>
<ul>
<li>specify array type with <code>int8[...]</code> syntax, eg: <code>int8[1,2,3]</code></li>
</ul>
<p>In both these cases, we require an explicit type to differentiate between the two possible options (<code>float</code> vs <code>double</code>, or <code>int8</code> vs <code>int</code> case), and by default, we choose to use higher precision rather than save space.</p>
<p><strong>Second, calculations.</strong> The workhorse here is the <code>DOT()</code> function that computes a dot product between the two vector arguments, ie. a sum of the products of the corresponding vector components.</p>
<p>The most frequent usecase is, of course, computing a <code>DOT()</code> between some per-document array (stored either as an attribute or in JSON) and a constant. The latter should be specifed with <code>FVEC()</code>:</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb86-1"><a href="#cb86-1"></a><span class="kw">SELECT</span> <span class="kw">id</span>, DOT(vec1, FVEC(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>)) <span class="kw">FROM</span> mydocuments</span>
<span id="cb86-2"><a href="#cb86-2"></a><span class="kw">SELECT</span> <span class="kw">id</span>, DOT(json.vec2, FVEC(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>)) <span class="kw">FROM</span> mydocuments</span></code></pre></div>
<p>Note that <code>DOT()</code> internally optimizes its execution depending on the actual argument types (ie. float vectors, or integer vectors, etc). That is why the two following queries perform very differently:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb87-1"><a href="#cb87-1"></a>mysql<span class="op">&gt;</span> <span class="kw">SELECT</span> <span class="kw">id</span>, DOT(vec1, FVEC(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="op">..</span>.)) d</span>
<span id="cb87-2"><a href="#cb87-2"></a>  <span class="kw">FROM</span> mydocuments <span class="kw">ORDER</span> <span class="kw">BY</span> d <span class="kw">DESC</span> <span class="kw">LIMIT</span> <span class="dv">3</span>;</span>
<span id="cb87-3"><a href="#cb87-3"></a><span class="op">..</span>.</span>
<span id="cb87-4"><a href="#cb87-4"></a><span class="dv">3</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.047</span> sec)</span>
<span id="cb87-5"><a href="#cb87-5"></a></span>
<span id="cb87-6"><a href="#cb87-6"></a>mysql<span class="op">&gt;</span> <span class="kw">SELECT</span> <span class="kw">id</span>, DOT(vec1, FVEC(<span class="fl">1.0</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="op">..</span>.)) d</span>
<span id="cb87-7"><a href="#cb87-7"></a>  <span class="kw">FROM</span> mydocuments <span class="kw">ORDER</span> <span class="kw">BY</span> d <span class="kw">DESC</span> <span class="kw">LIMIT</span> <span class="dv">3</span>;</span>
<span id="cb87-8"><a href="#cb87-8"></a><span class="op">..</span>.</span>
<span id="cb87-9"><a href="#cb87-9"></a><span class="dv">3</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.073</span> sec)</span></code></pre></div>
<p>In this example, <code>vec1</code> is an integer array, and we <code>DOT()</code> it against either an integer constant vector, or a float constant vector. Obviously, int-by-int vs int-by-float multiplications are a bit different, and hence the performance difference.</p>
<h2 id="ranking-factors">Ranking: factors</h2>
<p>Sphinx lets you specify custom ranking formulas for <code>weight()</code> calculations, and tailor text-based relevance ranking for your needs. For instance:</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb88-1"><a href="#cb88-1"></a><span class="kw">SELECT</span> <span class="op">*</span>, WEIGHT() <span class="kw">FROM</span> myindex <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello world&#39;</span>)</span>
<span id="cb88-2"><a href="#cb88-2"></a><span class="kw">OPTION</span> ranker<span class="op">=</span>expr(<span class="st">&#39;sum(lcs)*1000+bm15&#39;</span>)</span></code></pre></div>
<p>This mechanism is called the <strong>expression ranker</strong> and its ranking formulas (expressions) can access a few more special variables, called ranking factors, than a regular expression. (Of course, all the per-document attributes and all the math and other functions are still accessible to these formulas, too.)</p>
<p><strong>Ranking factors (aka ranking signals)</strong> are, basically, a bunch of different values computed for every document (or even field), based on the current search query. They essentially describe various aspects of the specific document match, and so they are used as input variables in a ranking formula, or a ML model.</p>
<p>There are three types (or levels) of factors, that determine when exactly some given factor can and will be computed:</p>
<ul>
<li><strong>query factors</strong>: values that only depend on the search query, but not the document, like <code>query_word_count</code>;</li>
<li><strong>document factors</strong>: values that depend on both the query <em>and</em> the matched document, like <code>doc_word_count</code> or <code>bm15</code>;</li>
<li><strong>field factors</strong>: values that depend on both the query <em>and</em> the matched full-text field, like <code>word_count</code> or <code>lcs</code>.</li>
</ul>
<p><strong>Query factors</strong> are naturally computed just once at the query start, and from there they stay constant. Those are usually simple things, like a number of unique keywords in the query. You can use them anywhere in the ranking formula.</p>
<p><strong>Document factors</strong> additionally depend on the document text, and so they get computed for every matched document. You can use them anywhere in the ranking formula, too. Of these, a few variants of the classic <code>bm25()</code> function are arguably the most important for relevance ranking.</p>
<p>Finally, <strong>field factors</strong> are even more granular, they get computed for every single field. And thus they then have to be aggregated into a singular value by some <strong>factor aggregation function</strong> (as of v.3.2, the supported functions are either <code>SUM()</code> or <code>TOP()</code>).</p>
<p>And before we discuss every specific factor in a bit more details, here goes the obligatory <strong>factors cheat sheet</strong>.</p>
<ul>
<li><strong>Hits</strong> in Sphinx == postings in IR == formally “a number of (a certain type of) matching keyword occurrences in the current field”</li>
</ul>
<table>
<colgroup>
<col style="width: 16%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 72%" />
</colgroup>
<thead>
<tr class="header">
<th>Name</th>
<th>Level</th>
<th>Type</th>
<th>Summary</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>has_digit_words</td>
<td>query</td>
<td>int</td>
<td>number of <code>has_digit</code> words that contain <code>[0-9]</code> chars (but may also contain other chars)</td>
</tr>
<tr class="even">
<td>is_latin_words</td>
<td>query</td>
<td>int</td>
<td>number of <code>is_latin</code> words, ie. words with <code>[a-zA-Z]</code> chars only</td>
</tr>
<tr class="odd">
<td>is_noun_words</td>
<td>query</td>
<td>int</td>
<td>number of <code>is_noun</code> words, ie. tagged as nouns (by the lemmatizer)</td>
</tr>
<tr class="even">
<td>is_number_words</td>
<td>query</td>
<td>int</td>
<td>number of <code>is_number</code> words, ie. integers with <code>[0-9]</code> chars only</td>
</tr>
<tr class="odd">
<td>max_lcs</td>
<td>query</td>
<td>int</td>
<td>maximum possible LCS value for the current query</td>
</tr>
<tr class="even">
<td>query_word_count</td>
<td>query</td>
<td>int</td>
<td>number of unique inclusive keywords in a query</td>
</tr>
<tr class="odd">
<td>bm15</td>
<td>doc</td>
<td>int</td>
<td>quick estimate of <code>BM25(1.2, 0)</code> without query syntax support</td>
</tr>
<tr class="even">
<td>bm25a(k1, b)</td>
<td>doc</td>
<td>int</td>
<td>precise <code>BM25()</code> value with configurable <code>K1</code>, <code>B</code> constants and syntax support</td>
</tr>
<tr class="odd">
<td>bm25f(k1, b, …)</td>
<td>doc</td>
<td>int</td>
<td>precise <code>BM25F()</code> value with extra configurable field weights</td>
</tr>
<tr class="even">
<td>doc_word_count</td>
<td>doc</td>
<td>int</td>
<td>number of unique keywords matched in the document</td>
</tr>
<tr class="odd">
<td>field_mask</td>
<td>doc</td>
<td>int</td>
<td>bit mask of the matched fields</td>
</tr>
<tr class="even">
<td>atc</td>
<td>field</td>
<td>float</td>
<td>Aggregate Term Closeness, <code>log(1+sum(idf1*idf2*pow(dist, -1.75))</code> over “best” term pairs</td>
</tr>
<tr class="odd">
<td>exact_field_hit</td>
<td>field</td>
<td>bool</td>
<td>whether field is fully covered by the query, in the query term order</td>
</tr>
<tr class="even">
<td>exact_hit</td>
<td>field</td>
<td>bool</td>
<td>whether query == field</td>
</tr>
<tr class="odd">
<td>exact_order</td>
<td>field</td>
<td>bool</td>
<td>whether all query keywords were a) matched and b) in query order</td>
</tr>
<tr class="even">
<td>full_field_hit</td>
<td>field</td>
<td>bool</td>
<td>whether field is fully covered by the query, in arbitrary term order</td>
</tr>
<tr class="odd">
<td>has_digit_hits</td>
<td>field</td>
<td>int</td>
<td>number of <code>has_digit</code> keyword hits</td>
</tr>
<tr class="even">
<td>hit_count</td>
<td>field</td>
<td>int</td>
<td>total number of any-keyword hits</td>
</tr>
<tr class="odd">
<td>is_latin_hits</td>
<td>field</td>
<td>int</td>
<td>number of <code>is_latin</code> keyword hits</td>
</tr>
<tr class="even">
<td>is_noun_hits</td>
<td>field</td>
<td>int</td>
<td>number of <code>is_noun</code> keyword hits</td>
</tr>
<tr class="odd">
<td>is_number_hits</td>
<td>field</td>
<td>int</td>
<td>number of <code>is_number</code> keyword hits</td>
</tr>
<tr class="even">
<td>lccs</td>
<td>field</td>
<td>int</td>
<td>Longest Common Contiguous Subsequence between query and document, in words</td>
</tr>
<tr class="odd">
<td>lcs</td>
<td>field</td>
<td>int</td>
<td>Longest Common Subsequence between query and document, in words</td>
</tr>
<tr class="even">
<td>max_idf</td>
<td>field</td>
<td>float</td>
<td><code>max(idf)</code> over keywords matched in this field</td>
</tr>
<tr class="odd">
<td>max_window_hits(n)</td>
<td>field</td>
<td>int</td>
<td><code>max(window_hit_count)</code> computed over all N-word windows in the current field</td>
</tr>
<tr class="even">
<td>min_best_span_pos</td>
<td>field</td>
<td>int</td>
<td>first maximum LCS span position, in words, 1-based</td>
</tr>
<tr class="odd">
<td>min_gaps</td>
<td>field</td>
<td>int</td>
<td>min number of gaps between the matched keywords over the matching spans</td>
</tr>
<tr class="even">
<td>min_hit_pos</td>
<td>field</td>
<td>int</td>
<td>first matched occurrence position, in words, 1-based</td>
</tr>
<tr class="odd">
<td>min_idf</td>
<td>field</td>
<td>float</td>
<td><code>min(idf)</code> over keywords matched in this field</td>
</tr>
<tr class="even">
<td>phrase_decay10</td>
<td>field</td>
<td>float</td>
<td>field to query phrase “similarity” with 2x weight decay per 10 positions</td>
</tr>
<tr class="odd">
<td>phrase_decay30</td>
<td>field</td>
<td>float</td>
<td>field to query phrase “similarity” with 2x weight decay per 30 positions</td>
</tr>
<tr class="even">
<td>sum_idf</td>
<td>field</td>
<td>float</td>
<td><code>sum(idf)</code> over unique keywords matched in this field</td>
</tr>
<tr class="odd">
<td>sum_idf_boost</td>
<td>field</td>
<td>float</td>
<td><code>sum(idf_boost)</code> over unique keywords matched in this field</td>
</tr>
<tr class="even">
<td>tf_idf</td>
<td>field</td>
<td>float</td>
<td><code>sum(tf*idf)</code> over unique matched keywords, ie. <code>sum(idf)</code> over all occurrences</td>
</tr>
<tr class="odd">
<td>trf_aqt</td>
<td>field</td>
<td>float</td>
<td>Trigram Filter Alphanumeric Query Trigrams ratio</td>
</tr>
<tr class="even">
<td>trf_i2f</td>
<td>field</td>
<td>float</td>
<td>Trigram Filter Intersection To Field ratio</td>
</tr>
<tr class="odd">
<td>trf_i2q</td>
<td>field</td>
<td>float</td>
<td>Trigram Filter Intersection to Query ratio</td>
</tr>
<tr class="even">
<td>trf_i2u</td>
<td>field</td>
<td>float</td>
<td>Trigram Filter Intersection to Union ratio</td>
</tr>
<tr class="odd">
<td>trf_naqt</td>
<td>field</td>
<td>float</td>
<td>Trigram Filter Number of Alphanumeric Query Trigrams</td>
</tr>
<tr class="even">
<td>trf_qt</td>
<td>field</td>
<td>float</td>
<td>Trigram Filter Query Trigrams ratio</td>
</tr>
<tr class="odd">
<td>user_weight</td>
<td>field</td>
<td>int</td>
<td>user-specified field weight (via <code>OPTION field_weights</code>)</td>
</tr>
<tr class="even">
<td>wlccs</td>
<td>field</td>
<td>float</td>
<td>Weighted LCCS, <code>sum(idf)</code> over contiguous keyword spans</td>
</tr>
<tr class="odd">
<td>word_count</td>
<td>field</td>
<td>int</td>
<td>number of unique keyword matched in this field</td>
</tr>
</tbody>
</table>
<h3 id="factor-aggregation-functions">Factor aggregation functions</h3>
<p>Formally, a (field) factor aggregation function is a single argument function that takes an expression with field-level factors, iterates it over all the matched fields, and computes the final result over the individual per-field values.</p>
<p>Currently supported aggregation functions are:</p>
<ul>
<li><code>SUM()</code>, sums the argument expression over all matched fields. For instance, <code>sum(1)</code> should return a number of matched fields.</li>
<li><code>TOP()</code>, returns the greatest value of the argument over all matched fields. For instance, <code>top(max_idf)</code> should return a maximum per-keyword IDF over the entire document.</li>
</ul>
<p>Naturally, these are only needed over expressions with field-level factors, query-level and document-level factors can be used in the formulas “as is”.</p>
<h3 id="keyword-flags">Keyword flags</h3>
<p>When searching and ranking, Sphinx classifies every query keyword with regards to a few classes of interest. That is, it flags a keyword with a “noun” class when the keyword is a (known) noun, or flags it with a “number” class when it is an integer, etc.</p>
<p>At the moment we identify 4 keyword classes and assign the respective flags. Those 4 flags in turn generate 8 ranking factors, 4 query-level per-flag keyword counts, and 4 field-level per-class hit counts. The flags are described in a bit more detail just below.</p>
<p>It’s important to understand that all the flags are essentially assigned at <em>query</em> parsing time, without looking into any actual index <em>data</em> (as opposed to tokenization and morphology settings). Also, query processing rules apply. Meaning that the valid keyword modifiers are effectively stripped before assigning the flags.</p>
<h4 id="has_digit-flag"><code>has_digit</code> flag</h4>
<p>Keyword is flagged as <code>has_digit</code> when there is at least one digit character, ie. from <code>[0-9]</code> range, in that keyword.</p>
<p>Other characters are allowed, meaning that <code>l33t</code> is a <code>has_digit</code> keyword.</p>
<p>But they are not required, and thus, any <code>is_number</code> keyword is by definition a <code>has_digit</code> keyword.</p>
<h4 id="is_latin-flag"><code>is_latin</code> flag</h4>
<p>Keyword is flagged as <code>is_latin</code> when it completely consists of Latin letters, ie. any of the <code>[a-zA-Z]</code> characters. No other characters are allowed.</p>
<p>For instance, <code>hello</code> is flagged as <code>is_latin</code>, but <code>l33t</code> is <em>not</em>, because of the digits.</p>
<p>Also note that wildcards like <code>abc*</code> are <em>not</em> flagged as <code>is_latin</code>, even if all the actual expansions are latin-only. Technically, query keyword flagging only looks at the query itself, and not the index data, and can not know anything about the actual expansions yet. (And even if it did, then inserting a new row with a new expansion could suddenly break the <code>is_latin</code> property.)</p>
<p>At the same time, as query keyword modifiers like <code>^abc</code> or <code>=abc</code> still get properly processed, these keywords <em>are</em> flagged as <code>is_latin</code> alright.</p>
<h4 id="is_noun-flag"><code>is_noun</code> flag</h4>
<p>Keyword is flagged as <code>is_noun</code> when (a) there is at least one lemmatizer enabled for the index, and (b) that lemmatizer classifies that standalone keyword as a noun.</p>
<p>For example, with <code>morphology = lemmatize_en</code> configured in our example index, we get the following:</p>
<pre><code>mysql&gt; CALL KEYWORDS(&#39;deadly mortal sin&#39;, &#39;en&#39;, 1 AS stats);
+------+-----------+------------+------+------+-----------+------------+----------------+----------+---------+-----------+-----------+
| qpos | tokenized | normalized | docs | hits | plain_idf | global_idf | has_global_idf | is_latin | is_noun | is_number | has_digit |
+------+-----------+------------+------+------+-----------+------------+----------------+----------+---------+-----------+-----------+
| 1    | deadly    | deadly     | 0    | 0    | 0.000000  | 0.000000   | 0              | 1        | 0       | 0         | 0         |
| 2    | mortal    | mortal     | 0    | 0    | 0.000000  | 0.000000   | 0              | 1        | 1       | 0         | 0         |
| 3    | sin       | sin        | 0    | 0    | 0.000000  | 0.000000   | 0              | 1        | 1       | 0         | 0         |
+------+-----------+------------+------+------+-----------+------------+----------------+----------+---------+-----------+-----------+
3 rows in set (0.00 sec)</code></pre>
<p>However, as you can see from this very example, <code>is_noun</code> POS tagging is not completely precise.</p>
<p>For now it works on individual words rather than contexts. So even though in <em>this</em> particular query context we could technically guess that “mortal” is not a noun, in general it sometimes is. Hence the <code>is_noun</code> flags in this example are 0/1/1, though ideally they would be 0/0/1 respectively.</p>
<p>Also, at the moment the tagger prefers to overtag. That is, when “in doubt”, ie. when the lemmatizer reports that a given wordform can either be a noun or not, we do not (yet) analyze the probabilities, and just always set the flag.</p>
<p>Another tricky bit is the handling of non-dictionary forms. As of v.3.2 the lemmatizer reports all such predictions as nouns.</p>
<p>So use with care; this can be a noisy signal.</p>
<h4 id="is_number-flag"><code>is_number</code> flag</h4>
<p>Keyword is flagged as <code>is_number</code> when <em>all</em> its characters are digits from the <code>[0-9]</code> range. Other characters are not allowed.</p>
<p>So, for example, <code>123</code> will be flagged <code>is_number</code>, but neither <code>0.123</code> nor <code>0x123</code> will be flagged.</p>
<p>To nitpick on this particular example a bit more, note that <code>.</code> does not even get parsed as a character by default. So with the default <code>charset_table</code> that query text will not even produce a single keyword. Instead, by default it gets tokenized as two tokens (keywords), <code>0</code> and <code>123</code>, and <em>those</em> tokens in turn <em>are</em> flagged <code>is_number</code>.</p>
<h3 id="query-level-ranking-factors">Query-level ranking factors</h3>
<p>These are perhaps the simplest factors. They are entirely independent from the documents being ranked; they only describe the query. So they only get computed once, at the very start of query processing.</p>
<h4 id="has_digit_words">has_digit_words</h4>
<p>Query-level, a number of unique <code>has_digit</code> keywords in the query. Duplicates should only be accounted once.</p>
<h4 id="is_latin_words">is_latin_words</h4>
<p>Query-level, a number of unique <code>is_latin</code> keywords in the query. Duplicates should only be accounted once.</p>
<h4 id="is_noun_words">is_noun_words</h4>
<p>Query-level, a number of unique <code>is_noun</code> keywords in the query. Duplicates should only be accounted once.</p>
<h4 id="is_number_words">is_number_words</h4>
<p>Query-level, a number of unique <code>is_number</code> keywords in the query. Duplicates should only be accounted once.</p>
<h4 id="max_lcs">max_lcs</h4>
<p>Query-level, maximum possible value that the <code>sum(lcs*user_weight)</code> expression can take. This can be useful for weight boost scaling. For instance, (legacy) <code>MATCHANY</code> ranker formula uses this factor to <em>guarantee</em> that a full phrase match in <em>any</em> individual field ranks higher than any combination of partial matches in all fields.</p>
<h4 id="query_word_count">query_word_count</h4>
<p>Query-level, a number of unique and inclusive keywords in a query. “Inclusive” means that it’s additionally adjusted for a number of excluded keywords. For example, both <code>one one one one</code> and <code>(one !two)</code> queries should assign a value of 1 to this factor, because there is just one unique non-excluded keyword.</p>
<h3 id="document-level-ranking-factors">Document-level ranking factors</h3>
<p>These are a few factors that “look” at both the query and the (entire) matching document being ranked. The most useful among these are several variants of the classic BM-family factors (as in Okapi BM25).</p>
<h4 id="bm15">bm15</h4>
<p>Document-level, a quick estimate of a classic <code>BM15(1.2)</code> value. It is computed without keyword occurrence filtering (ie. over all the term postings rather than just the matched ones). Also, it ignores the document and fields lengths.</p>
<p>For example, if you search for an exact phrase like <code>"foo bar"</code>, and both <code>foo</code> and <code>bar</code> keywords occur 10 times each in the document, but the <em>phrase</em> only occurs once, then this <code>bm15</code> estimate will still use 10 as TF (Term Frequency) values for both these keywords, ie. account all the term occurrences (postings), instead of “accounting” just 1 actual matching posting.</p>
<p>So <code>bm15</code> uses pre-computed document TFs, rather that computing actual matched TFs on the fly. By design, that makes zero difference all when running a simple bag-of-words query against the entire document. However, once you start using pretty much <em>any</em> query syntax, the differences become obvious.</p>
<p>To discuss one, what if you limit all your searches to a single field with, and the query is <code>@title foo bar</code>? Should the weights really depend on contents of any other fields, as we clearly intended to limit our searches to titles? They should not. However, with the <code>bm15</code> approximation they will. But this really is just a performance vs quality tradeoff.</p>
<p>Last but not least, this factor was not-quite-correctly named <code>bm25</code> for quite a while, until v.3.0.2. (It can be argued that in a way it did compute the BM25 value, for a very specific <code>k1 = 1.2</code> and <code>b = 0</code> case. But come on. There is a special name for that <code>b = 0</code> family of cases, and it is <code>bm15</code>.)</p>
<h4 id="bm25a">bm25a()</h4>
<p>Document-level, parametrized, computes a value of classic <code>BM25(k1,b)</code> function with the two given (required) parameters. For example:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb90-1"><a href="#cb90-1"></a><span class="kw">SELECT</span> <span class="op">..</span>. <span class="kw">OPTION</span> ranker<span class="op">=</span>expr(<span class="st">&#39;10000*bm25a(2.0, 0.7)&#39;</span>)</span></code></pre></div>
<p>Unlike <code>bm15</code>, this factor only account the <em>matching</em> occurrences (postings) when computing TFs. It also requires <code>index_field_lengths = 1</code> setting to be on, in order to compute the current and average document lengths (which is in turn required by BM25 function with non-zero <code>b</code> parameters).</p>
<p>It is called <code>bm25a</code> only because <code>bm25</code> was initially taken (mistakenly) by that <code>BM25(1.2, 0)</code> value estimate that we now (properly) call <code>bm15</code>; no other hidden meaning in that <code>a</code> suffix.</p>
<h4 id="bm25f">bm25f()</h4>
<p>Document-level, parametrized, computes a value of an extended <code>BM25F(k1,b)</code> function with the two given (required) parameters, and an extra set of named per-field weights. For example:</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb91-1"><a href="#cb91-1"></a><span class="kw">SELECT</span> <span class="op">..</span>. <span class="kw">OPTION</span> ranker<span class="op">=</span>expr(<span class="st">&#39;10000*bm25f(2.0, 0.7, {title = 3})&#39;</span>)</span></code></pre></div>
<p>Unlike <code>bm15</code>, this factor only account the <em>matching</em> occurrences (postings) when computing TFs. It also requires <code>index_field_lengths = 1</code> setting to be on.</p>
<p>BM25F extension lets you assign bigger weights to certain fields. Internally those weights will simply pre-scale the TFs before plugging them into the original BM25 formula. For an original TR, see <a href="https://trec.nist.gov/pubs/trec13/papers/microsoft-cambridge.web.hard.pdf">Zaragoza et al (1994), “Microsoft Cambridge at TREC-13: Web and HARD tracks”</a> paper.</p>
<h4 id="doc_word_count">doc_word_count</h4>
<p>Document-level, a number of unique keywords matched in the entire document.</p>
<h4 id="field_mask">field_mask</h4>
<p>Document-level, a 32-bit mask of matched fields. Fields with numbers 33 and up are ignored in this mask.</p>
<h3 id="field-level-ranking-factors">Field-level ranking factors</h3>
<p>Generally, a field-level factor is just some numeric value computed by the ranking engine for every matched in-document text field, with regards to the current query, describing this or this aspect of the actual match.</p>
<p>As a query can match multiple fields, but the final weight needs to be a single value, these per-field values need to be folded into a single one. Meaning that, unlike query-level and document-level factors, you can’t use them directly in your ranking formulas:</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb92-1"><a href="#cb92-1"></a>mysql<span class="op">&gt;</span> <span class="kw">SELECT</span> <span class="kw">id</span>, weight() <span class="kw">FROM</span> test1 <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello world&#39;</span>)</span>
<span id="cb92-2"><a href="#cb92-2"></a><span class="kw">OPTION</span> ranker<span class="op">=</span>expr(<span class="st">&#39;lcs&#39;</span>);</span>
<span id="cb92-3"><a href="#cb92-3"></a></span>
<span id="cb92-4"><a href="#cb92-4"></a>ERROR <span class="dv">1064</span> (<span class="dv">42000</span>): <span class="kw">index</span> <span class="st">&#39;test1&#39;</span>: field factors must <span class="kw">only</span></span>
<span id="cb92-5"><a href="#cb92-5"></a>occur within field aggregates <span class="kw">in</span> a ranking expression</span></code></pre></div>
<p>The correct syntax should use one of the aggregation functions. Multiple different aggregations are allowed:</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb93-1"><a href="#cb93-1"></a>mysql<span class="op">&gt;</span> <span class="kw">SELECT</span> <span class="kw">id</span>, weight() <span class="kw">FROM</span> test1 <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello world&#39;</span>)</span>
<span id="cb93-2"><a href="#cb93-2"></a><span class="kw">OPTION</span> ranker<span class="op">=</span>expr(<span class="st">&#39;sum(lcs) + top(max_idf) * 1000&#39;</span>);</span></code></pre></div>
<p>Now let’s discuss the individual factors in a bit more detail.</p>
<h4 id="atc">atc</h4>
<p>Field-level, Aggregate Term Closeness. This is a proximity based measure that grows higher when the document contains more groups of more closely located and more important (rare) query keywords.</p>
<p><strong>WARNING:</strong> you should use ATC with <code>OPTION idf='plain,tfidf_unnormalized'</code>; otherwise you could get rather unexpected results.</p>
<p>ATC basically works as follows. For every keyword <em>occurrence</em> in the document, we compute the so called <em>term closeness</em>. For that, we examine all the other closest occurrences of all the query keywords (keyword itself included too), both to the left and to the right of the subject occurrence. We then compute a distance dampening coefficient as <code>k = pow(distance, -1.75)</code> for all those occurrences, and sum the dampened IDFs. Thus for every occurrence of every keyword, we get a “closeness” value that describes the “neighbors” of that occurrence. We then multiply those per-occurrence closenesses by their respective subject keyword IDF, sum them all, and finally, compute a logarithm of that sum.</p>
<p>Or in other words, we process the best (closest) matched keyword pairs in the document, and compute pairwise “closenesses” as the product of their IDFs scaled by the distance coefficient:</p>
<pre><code>pair_tc = idf(pair_word1) * idf(pair_word2) * pow(pair_distance, -1.75)</code></pre>
<p>We then sum such closenesses, and compute the final, log-dampened ATC value:</p>
<pre><code>atc = log(1 + sum(pair_tc))</code></pre>
<p>Note that this final dampening logarithm is exactly the reason you should use <code>OPTION idf=plain</code>, because without it, the expression inside the <code>log()</code> could be negative.</p>
<p>Having closer keyword occurrences actually contributes <em>much</em> more to ATC than having more frequent keywords. Indeed, when the keywords are right next to each other, we get <code>distance = 1</code> and <code>k = 1</code>; and when there is only one extra word between them, we get <code>distance = 2</code> and <code>k = 0.297</code>; and with two extra words in-between, we get <code>distance = 3</code> and <code>k = 0.146</code>, and so on.</p>
<p>At the same time IDF attenuates somewhat slower. For example, in a 1 million document collection, the IDF values for 3 example keywords that are found in 10, 100, and 1000 documents would be 0.833, 0.667, and 0.500, respectively.</p>
<p>So a keyword pair with two rather rare keywords that occur in just 10 documents each but with 2 other words in between would yield <code>pair_tc = 0.101</code> and thus just barely outweigh a pair with a 100-doc and a 1000-doc keyword with 1 other word between them and <code>pair_tc = 0.099</code>.</p>
<p>Moreover, a pair of two <em>unique</em>, 1-document keywords with ideal IDFs, and with just 3 words between them would fetch a <code>pair_tc = 0.088</code> and lose to a pair of two 1000-doc keywords located right next to each other, with a <code>pair_tc = 0.25</code>.</p>
<p>So, basically, while ATC does combine both keyword frequency and proximity, it is still heavily favoring the proximity.</p>
<h4 id="exact_field_hit">exact_field_hit</h4>
<p>Field-level, boolean, whether the current field was (seemingly) fully covered by the query, and in the right (query) term order, too.</p>
<p>This flag should be set when the field is basically either “equal” to the entire query, or equal to a query with a few terms thrown away. Note that term order matters, and it must match, too.</p>
<p>For example, if our query is <code>one two three</code>, then either <code>one two three</code>, or just <code>one three</code>, or <code>two three</code> should all have <code>exact_field_hit = 1</code>, because in these examples all the <em>field</em> keywords are matched by the query, and they are in the right order. However, <code>three one</code> should get <code>exact_field_hit = 0</code>, because of the wrong (non-query) term order. And then if we throw in any extra terms, <code>one four three</code> field should also get <code>exact_field_hit = 0</code>, because <code>four</code> was not matched by the query, ie. this field is not covered fully.</p>
<p>Also, beware that stopwords and other text processing tools might “break” this factor.</p>
<p>For example, when the field is <code>one stop three</code>, where <code>stop</code> is a stopword, we would still get 0 instead of 1, even though intuitively it should be ignored, and the field should be kinda equal to <code>one three</code>, and we get a 1 for that. How come?</p>
<p>This is because stopwords are <em>not</em> really ignored completely. They do still affect <em>positions</em> (and that’s intentional, so that matching operators and other ranking factors would work as expected, just in some other example cases).</p>
<p>Therefore, this field gets indexed as <code>one * three</code>, where star marks a skipped position. So when matching the <code>one two three</code> query, the engine knows that positions number 1 and 3 were matched alright. But there is no (efficient) way for it to tell what exactly was in that missed position 2 in the original field; ie. was there a stopword, or was there any <em>regular</em> word that the query simply did not mention (like in the <code>one four three</code> example). So when computing this factor, we see that there was an unmatched position, therefore we assume that the field was not covered fully (by the query terms), and set the factor to 0.</p>
<h4 id="exact_hit">exact_hit</h4>
<p>Field-level, boolean, whether a query was a full and exact match of the entire current field (that is, after normalization, morphology, etc). Used in the SPH04 ranker.</p>
<h4 id="exact_order">exact_order</h4>
<p>Field-level, boolean, whether all of the query keywords were matched in the current field in the exact query order. (In other words, whether our field “covers” the entire query, and in the right order, too.)</p>
<p>For example, <code>(microsoft office)</code> query would yield <code>exact_order = 1</code> in a field with the <code>We use Microsoft software in our office.</code> content.</p>
<p>However, the very same query in a field with <code>(Our office is Microsoft free.)</code> text would yield <code>exact_order = 0</code> because, while the coverage is there (all words are matched), the order is wrong.</p>
<h4 id="full_field_hit">full_field_hit</h4>
<p>Field-level, boolean, whether the current field was (seemingly) fully covered by the query.</p>
<p>This flag should be set when all the <em>field</em> keywords are matched by the query, in whatever order. In other words, this factor requires “full coverage” of the field by the query, and “allows” to reorder the words.</p>
<p>For example, a field <code>three one</code> should get <code>full_field_hit = 1</code> against a query <code>one two three</code>. Both keywords were “covered” (matched), and the order does not matter.</p>
<p>Note that all documents where <code>exact_field_hit = 1</code> (which is even more strict) must also get <code>full_field_hit = 1</code>, but not vice versa.</p>
<p>Also, beware that stopwords and other text processing tools might “break” this factor, for exactly the same reasons that we disscussed a little earlier in <a href="#exact_field_hit">exact_field_hit</a>.</p>
<h4 id="has_digit_hits">has_digit_hits</h4>
<p>Field-level, total matched field hits count over just the <code>has_digit</code> keywords.</p>
<h4 id="hit_count">hit_count</h4>
<p>Field-level, total field hits count over all keywords. In other words, total number of keyword occurrences that were matched in the current field.</p>
<p>Note that a single keyword may occur (and match!) multiple times. For example, if <code>hello</code> occurs 3 times in a field and <code>world</code> occurs 5 times, <code>hit_count</code> will be 8.</p>
<h4 id="is_noun_hits">is_noun_hits</h4>
<p>Field-level, total matched field hits count over just the <code>is_noun</code> keywords.</p>
<h4 id="is_latin_hits">is_latin_hits</h4>
<p>Field-level, total matched field hits count over just the <code>is_latin</code> keywords.</p>
<h4 id="is_number_hits">is_number_hits</h4>
<p>Field-level, total matched field hits count over just the <code>is_number</code> keywords.</p>
<h4 id="lccs">lccs</h4>
<p>Field-level, Longest Common Contiguous Subsequence. A length of the longest contiguous subphrase between the query and the document, computed in keywords.</p>
<p>LCCS factor is rather similar to LCS but, in a sense, more restrictive. While LCS could be greater than 1 even though no two query words are matched right next to each other, LCCS would only get greater than 1 if there are <em>exact</em>, contiguous query subphrases in the document.</p>
<p>For example, <code>one two three four five</code> query vs <code>one hundred three hundred five hundred</code> document would yield <code>lcs = 3</code>, but <code>lccs = 1</code>, because even though mutual dispositions of 3 matched keywords (<code>one</code>, <code>three</code>, and <code>five</code>) do match between the query and the document, none of the occurences are actually next to each other.</p>
<p>Note that LCCS still does not differentiate between the frequent and rare keywords; for that, see WLCCS factor.</p>
<h4 id="lcs">lcs</h4>
<p>Field-level, Longest Common Subsequence. This is the length of a maximum “verbatim” match between the document and the query, counted in words.</p>
<p>By construction, it takes a minimum value of 1 when only “stray” keywords were matched in a field, and a maximum value of a query length (in keywords) when the entire query was matched in a field “as is”, in the exact query order.</p>
<p>For example, if the query is <code>hello world</code> and the field contains these two words as a subphrase anywhere in the field, <code>lcs</code> will be 2. Another example, this works on <em>subsets</em> of the query too, ie. with <code>hello world program</code> query the field that only contains <code>hello world</code> subphrase also a gets an <code>lcs</code> value of 2.</p>
<p>Note that any <em>non-contiguous</em> subset of the query keyword works here, not just a subset of adjacent keywords. For example, with <code>hello world program</code> query and <code>hello (test program)</code> field contents, <code>lcs</code> will be 2 just as well, because both <code>hello</code> and <code>program</code> matched in the same respective positions as they were in the query. In other words, both the query and field match a non-contiguous 2-keyword subset <code>hello * program</code> here, hence the value of 2 of <code>lcs</code>.</p>
<p>However, if we keep the <code>hello world program</code> query but our field changes to <code>hello (test computer program)</code>, then the longest matching subset is now only 1-keyword long (two subsets match here actually, either <code>hello</code> or <code>program</code>), and <code>lcs</code> is therefore 1.</p>
<p>Finally, if the query is <code>hello world program</code> and the field contains an exact match <code>hello world program</code>, <code>lcs</code> will be 3. (Hopefully that is unsurprising at this point.</p>
<h4 id="max_idf">max_idf</h4>
<p>Field-level, <code>max(idf)</code> over all keywords that were matched in the field.</p>
<h4 id="max_window_hits">max_window_hits()</h4>
<p>Field-level, parametrized, computes <code>max(window_hit_count)</code> over all N-keyword windows (where N is the parameter). For example:</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb96-1"><a href="#cb96-1"></a>mysql<span class="op">&gt;</span> <span class="kw">SELECT</span> <span class="op">*</span>, weight() <span class="kw">FROM</span> test1 <span class="kw">WHERE</span> MATCH(<span class="st">&#39;one two&#39;</span>)</span>
<span id="cb96-2"><a href="#cb96-2"></a>    <span class="op">-&gt;</span> <span class="kw">OPTION</span> ranker<span class="op">=</span>expr(<span class="st">&#39;sum(max_window_hits(3))&#39;</span>);</span>
<span id="cb96-3"><a href="#cb96-3"></a><span class="op">+</span><span class="co">------+-------------------+----------+</span></span>
<span id="cb96-4"><a href="#cb96-4"></a>| <span class="kw">id</span>   | title             | weight() |</span>
<span id="cb96-5"><a href="#cb96-5"></a><span class="op">+</span><span class="co">------+-------------------+----------+</span></span>
<span id="cb96-6"><a href="#cb96-6"></a>|    <span class="dv">1</span> | one two           |        <span class="dv">2</span> |</span>
<span id="cb96-7"><a href="#cb96-7"></a>|    <span class="dv">2</span> | one aa two        |        <span class="dv">2</span> |</span>
<span id="cb96-8"><a href="#cb96-8"></a>|    <span class="dv">4</span> | one one aa bb two |        <span class="dv">1</span> |</span>
<span id="cb96-9"><a href="#cb96-9"></a>|    <span class="dv">3</span> | one aa bb two     |        <span class="dv">1</span> |</span>
<span id="cb96-10"><a href="#cb96-10"></a><span class="op">+</span><span class="co">------+-------------------+----------+</span></span>
<span id="cb96-11"><a href="#cb96-11"></a><span class="dv">3</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>So in this example we are looking at rather short 3-keyword windows, and in document number 3 our matched keywords are too far apart, so the factor is 1. However, in document number 4 the <code>one one aa</code> window has 2 occurrences (even though of just one keyword), so the factor is 2 there. Documents number 1 and 2 are straightfoward.</p>
<h4 id="min_best_span_pos">min_best_span_pos</h4>
<p>Field-level, the position of the first maximum LCS keyword span.</p>
<p>For example, assume that our query was <code>hello world program</code>, and that the <code>hello world</code> subphrase was matched twice in the current field, in positions 13 and 21. Now assume that <code>hello</code> and <code>world</code> additionally occurred elsewhere in the field (say, in positions 5, 8, and 34), but as those occurrences were not next to each other, they did not count as a subphrase match. In this example, <code>min_best_span_pos</code> will be 13, ie. the position of a first occurence of a longest (maximum) match, LCS-wise.</p>
<p>Note how for the single keyword queries <code>min_best_span_pos</code> must always equal <code>min_hit_pos</code>.</p>
<h4 id="min_gaps">min_gaps</h4>
<p>Field-level, the minimum number of positional gaps between (just) the keywords matched in field. Always 0 when less than 2 keywords match; always greater or equal than 0 otherwise.</p>
<p>For example, with the same <code>big wolf</code> query, <code>big bad wolf</code> field would yield <code>min_gaps = 1</code>; <code>big bad hairy wolf</code> field would yield <code>min_gaps = 2</code>; <code>the wolf was scary and big</code> field would yield <code>min_gaps = 3</code>; etc. However, a field like <code>i heard a wolf howl</code> would yield <code>min_gaps = 0</code>, because only one keyword would be matching in that field, and, naturally, there would be no gaps <em>matched</em> keywords.</p>
<p>Therefore, this is a rather low-level, “raw” factor that you would most likely want to <em>adjust</em> before actually using for ranking.</p>
<p>Specific adjustments depend heavily on your data and the resulting formula, but here are a few ideas you can start with:</p>
<ul>
<li>any <code>min_gaps</code> based boosts could be simply ignored when <code>word_count &lt; 2</code>;</li>
<li>non-trivial <code>min_gaps</code> values (ie. when <code>word_count &lt;= 2</code>) could be clamped with a certain “worst case” constant while trivial values (ie. when <code>min_gaps = 0</code> and <code>word_count &lt; 2</code>) could be replaced by that constant;</li>
<li>a transfer function like <code>1 / (1 + min_gaps)</code> could be applied (so that better, smaller min_gaps values would maximize it and worse, bigger <code>min_gaps</code> values would fall off slowly).</li>
</ul>
<h4 id="min_hit_pos">min_hit_pos</h4>
<p>Field-level, the position of the first matched keyword occurrence, counted in words. Positions begins from 1, so <code>min_hit_pos = 0</code> must be impossible in an actually matched field.</p>
<h4 id="min_idf">min_idf</h4>
<p>Field-level, <code>min(idf)</code> over all keywords (not occurrences!) that were matched in the field.</p>
<h4 id="phrase_decay10">phrase_decay10</h4>
<p>Field-level, position-decayed (0.5 decay per 10 positions) and proximity-based “similarity” of a matched field to the query interpreted as a phrase.</p>
<p>Ranges from 0.0 to 1.0, and maxes out at 1.0 when the entire field is a query phrase repeated one or more times. For instance, <code>[cats dogs]</code> query will yield <code>phrase_decay10 = 1.0</code> against <code>title = [cats dogs cats dogs]</code> field (with two repeats), or just <code>title = [cats dogs]</code>, etc.</p>
<p>Note that <code>[dogs cats]</code> field yields a smaller <code>phrase_decay10</code> because of no phrase match. The exact value is going to vary because it also depends on IDFs. For instance:</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb97-1"><a href="#cb97-1"></a>mysql<span class="op">&gt;</span> <span class="kw">select</span> <span class="kw">id</span>, title, weight() <span class="kw">from</span> rt</span>
<span id="cb97-2"><a href="#cb97-2"></a>    <span class="op">-&gt;</span> <span class="kw">where</span> match(<span class="st">&#39;cats dogs&#39;</span>)</span>
<span id="cb97-3"><a href="#cb97-3"></a>    <span class="op">-&gt;</span> <span class="kw">option</span> ranker<span class="op">=</span>expr(<span class="st">&#39;sum(phrase_decay10)&#39;</span>);</span>
<span id="cb97-4"><a href="#cb97-4"></a><span class="op">+</span><span class="co">--------+---------------------+------------+</span></span>
<span id="cb97-5"><a href="#cb97-5"></a>| <span class="kw">id</span>     | title               | weight()   |</span>
<span id="cb97-6"><a href="#cb97-6"></a><span class="op">+</span><span class="co">--------+---------------------+------------+</span></span>
<span id="cb97-7"><a href="#cb97-7"></a>| <span class="dv">400001</span> | cats dogs           |        <span class="fl">1.0</span> |</span>
<span id="cb97-8"><a href="#cb97-8"></a>| <span class="dv">400002</span> | cats dogs cats dogs |        <span class="fl">1.0</span> |</span>
<span id="cb97-9"><a href="#cb97-9"></a>| <span class="dv">400003</span> | dogs cats           | <span class="fl">0.87473994</span> |</span>
<span id="cb97-10"><a href="#cb97-10"></a><span class="op">+</span><span class="co">--------+---------------------+------------+</span></span>
<span id="cb97-11"><a href="#cb97-11"></a><span class="dv">3</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>The signal calculation is somewhat similar to ATC. We begin with assigning an exponentially discounted, position-decayed IDF weight to every matched hit. The number 10 in the signal name is in fact the half-life distance, so that the decay coefficient is 1.0 at position 1, 0.5 at position 11, 0.25 at 21, etc. Then for each adjacent hit we multiply the per-hits weights and obtain the pair weight; compute an expected adjacent hit postion (ie. where it should had been in the ideal phrase match case); and additionally decay the pair weight based on the difference between the expected and actual position. In the end, we also perform normalization so that the signal fits into 0 to 1 range.</p>
<p>To summarize, the signal decays when hits are more sparse and/or in a different order in the field than in the query, and also decays when the hits are farther from the beginning of the field, hence the “phrase_decay” name.</p>
<p>Note that this signal calculation is relatively heavy, also simlarly to <code>atc</code> signal. Even though we actually did not observe any significant slowdowns on our production workloads, neither on average nor at 99th percentile, your mileage may vary, because our synthetic <em>worst case</em> test queries were significantly slower on our tests, upto 2x and more in extreme cases. For that reason we also added <code>no_decay=1</code> flag to <code>FACTORS()</code> that lets you skip computing this signal at all if you do not actually use it.</p>
<h4 id="phrase_decay30">phrase_decay30</h4>
<p>Field-level, position-decayed (0.5 decay per 30 positions) and proximity-based “similarity” of a matched field to the query interpreted as a phrase.</p>
<p>Completely similar to <code>phrase_decay10</code> signal, except that the position-based half-life is 30 rather than 10. In other words, <code>phrase_decay30</code> decays somewhat slower based on the in-field position (for example, decay coefficient is going to be 0.5 rather than 0.125 at position 31). Therefore it penalizes more “distant” matches less than <code>phrase_decay10</code> would.</p>
<h4 id="sum_idf">sum_idf</h4>
<p>Field-level, <code>sum(idf)</code> over all keywords (not occurrences!) that were matched in the field.</p>
<h4 id="sum_idf_boost">sum_idf_boost</h4>
<p>Field-level, <code>sum(idf_boost)</code> over all keywords (not occurrences!) that were matched in the field.</p>
<h4 id="tf_idf">tf_idf</h4>
<p>Field-level, a sum of <code>tf*idf</code> over all the keywords matched in the field. (Or, naturally, a sum of <code>idf</code> over all the matched postings.)</p>
<p>For the record, <code>TF</code> is the Term Frequency, aka the number of (matched) keyword occurrences in the current field.</p>
<p>And <code>IDF</code> is the Inverse Document Frequency, a floating point value between 0 and 1 that describes how frequent this keyword is in the index.</p>
<p>Basically, frequent (and therefore <em>not</em> really interesting) words get lower IDFs, hitting the minimum value of 0 when the keyword is present in all of the indexed documents. And vice versa, rare, unique, and therefore interesting words get higher IDFs, maxing out at 1 for unique keywords that occur in just a single document.</p>
<h4 id="trf_aqt">trf_aqt</h4>
<p>Field-level, float, a fraction of alphanumeric-only query trigrams matched by the field trigrams filter. Takes values in 0..1 range.</p>
<p>See <a href="#ranking-trigrams">“Ranking: trigrams”</a> section for more details.</p>
<h4 id="trf_i2f">trf_i2f</h4>
<p>Field-level, float, a ratio of query-and-field intersection filter bitcount to field filter bitcount (Intersection to Field). Takes values in 0..1 range.</p>
<p>See <a href="#ranking-trigrams">“Ranking: trigrams”</a> section for more details.</p>
<h4 id="trf_i2q">trf_i2q</h4>
<p>Field-level, float, a ratio of query-and-field intersection filter bitcount to query filter bitcount (Intersection to Query). Takes values in 0..1 range.</p>
<p>See <a href="#ranking-trigrams">“Ranking: trigrams”</a> section for more details.</p>
<h4 id="trf_i2u">trf_i2u</h4>
<p>Field-level, float, a ratio of query-and-field intersection filter bitcount to query-or-field union filter bitcount (Intersection to Union). Takes values in 0..1 range.</p>
<p>See <a href="#ranking-trigrams">“Ranking: trigrams”</a> section for more details.</p>
<h4 id="trf_naqt">trf_naqt</h4>
<p>Field-level, float, a number of alphanumeric-only query trigrams matched by the field trigrams filter. Takes non-negative integer values (ie. 0, 1, 2, etc), but stored as float anyway, for consistency.</p>
<p>See <a href="#ranking-trigrams">“Ranking: trigrams”</a> section for more details.</p>
<h4 id="trf_qt">trf_qt</h4>
<p>Field-level, float, a fraction of query trigrams matched by the field trigrams filter. Either in 0..1 range, or -1 when there is no field filter.</p>
<p>See <a href="#ranking-trigrams">“Ranking: trigrams”</a> section for more details.</p>
<h4 id="user_weight">user_weight</h4>
<p>Field-level, a user specified per-field weight (for a bit more details on how to set those, refer to <a href="sphinx2.html#sphinxql-select"><code>OPTION field_weights</code></a> section). By default all these weights are set to 1.</p>
<h4 id="wlccs">wlccs</h4>
<p>Field-level, Weighted Longest Common Contiguous Subsequence. A sum of IDFs over the keywords of the longest contiguous subphrase between the current query and the field.</p>
<p>WLCCS is computed very similarly to LCCS, but every “suitable” keyword occurrence increases it by the keyword IDF rather than just by 1 (which is the case with both LCS and LCCS). That lets us rank sequences of more rare and important keywords higher than sequences of frequent keywords, even if the latter are longer. For example, a query <code>Zanzibar bed and breakfast</code> would yield <code>lccs = 1</code> against a <code>hotels of Zanzibar</code> field, but <code>lccs = 3</code> against a <code>London bed and breakfast</code> field, even though <code>Zanzibar</code> could be actually somewhat more rare than the entire <code>bed and breakfast</code> phrase. WLCCS factor alleviates (to a certain extent) by accounting the keyword frequencies.</p>
<h4 id="word_count">word_count</h4>
<p>Field-level, the number of unique keywords matched in the field. For example, if both <code>hello</code> and <code>world</code> occur in the current field, <code>word_count</code> will be 2, irregardless of how many times do both keywords occur.</p>
<h2 id="ranking-builtin-ranker-formulas">Ranking: builtin ranker formulas</h2>
<p>All of the built-in Sphinx rankers can be emulated with the expression based ranker. You just need to pass a proper formula using the <code>OPTION ranker</code> clause.</p>
<p>Such emulation is, of course, going to be slower than using the built-in, pre-compiled rankers. But it still might be of interest if you want to start fine-tuning your ranking formula from an existing built-in baselines ranker. (Also, these formulas kinda define the nitty gritty built-in ranker details in a nicely readable fashion.)</p>
<table>
<colgroup>
<col style="width: 17%" />
<col style="width: 82%" />
</colgroup>
<thead>
<tr class="header">
<th>Ranker</th>
<th>Formula</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PROXIMITY_BM25</td>
<td><code>sum(lcs*user_weight)*1000 + bm25</code></td>
</tr>
<tr class="even">
<td>BM25</td>
<td><code>bm25</code></td>
</tr>
<tr class="odd">
<td>NONE</td>
<td><code>1</code></td>
</tr>
<tr class="even">
<td>WORDCOUNT</td>
<td><code>sum(hit_count*user_weight)</code></td>
</tr>
<tr class="odd">
<td>PROXIMITY</td>
<td><code>sum(lcs*user_weight)</code></td>
</tr>
<tr class="even">
<td>MATCHANY</td>
<td><code>sum((word_count + (lcs - 1)*max_lcs)*user_weight)</code></td>
</tr>
<tr class="odd">
<td>FIELDMASK</td>
<td><code>field_mask</code></td>
</tr>
<tr class="even">
<td>SPH04</td>
<td><code>sum((4*lcs + 2*(min_hit_pos==1) + exact_hit)*user_weight)*1000 + bm25</code></td>
</tr>
</tbody>
</table>
<p>And here goes a complete example query:</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb98-1"><a href="#cb98-1"></a><span class="kw">SELECT</span> <span class="kw">id</span>, weight() <span class="kw">FROM</span> test1</span>
<span id="cb98-2"><a href="#cb98-2"></a><span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello world&#39;</span>)</span>
<span id="cb98-3"><a href="#cb98-3"></a><span class="kw">OPTION</span> ranker<span class="op">=</span>expr(<span class="st">&#39;sum(lcs*user_weight)*1000 + bm25&#39;</span>)</span></code></pre></div>
<h2 id="ranking-idf-magics">Ranking: IDF magics</h2>
<p>Sphinx supports several different IDF (Inverse Document Frequency) calculation options. Those can affect your relevance ranking (aka scoring) when you are:</p>
<ul>
<li><em>either</em> sharding your data, even with built-in rankers;</li>
<li><em>or</em> doing any custom ranking work, even on a single shard.</li>
</ul>
<p>By default, term IDFs are (a) per-shard, and (b) computed online. So they might fluctuate significantly when ranking. And several other ranking factors rely on them, so the entire rank might change a lot in a seeimingly random fashion. The reasons are twofold.</p>
<p>First, IDFs usually differ across shards (i.e. individual indexes that make up a bigger combined index). This means that a completely identical document might rank differently depending on a specific shard it ends up in. Not great.</p>
<p>Second, IDFs might change from query to query, as you update the index data. That instability in time might or might not be a desired effect.</p>
<p>To help alleviate these quirks (if they affect your use case), Sphinx offers two features:</p>
<ol type="1">
<li><code>local_df</code> option to aggregate sharded IDFs.</li>
<li><code>global_idf</code> feature to enforce prebuilt static IDFs.</li>
</ol>
<p><code>local_df</code> syntax is <code>SELECT ... OPTION local_df=1</code> and enabling that option tells the query to compute IDFs (more) precisely, i.e. over the entire index rather than individual shards. The default value is 0 (off) for performance reasons.</p>
<p><code>global_idf</code> feature is more complicated and includes several components:</p>
<ul>
<li><code>indextool --dumpdict --stats</code> switch that generates the source data, i.e. the per-shard dictionary dumps;</li>
<li><code>indextool --buildidf</code> switch that builds a static IDF file from those;</li>
<li>per-shard <code>global_idf</code> config directive that lets you assign a static IDF file to your shards;</li>
<li>per-query <code>OPTION global_idf=1</code> that forces the query to use that file.</li>
</ul>
<p>Both these features affect the input variables used for IDF calculations. More specifically:</p>
<ul>
<li>let <code>n</code> be the DF, document frequency (for a given term);</li>
<li>let <code>N</code> be the corpus size, total number of documents;</li>
<li>by default, both <code>n</code> and <code>N</code> are per-shard;</li>
<li>with <code>local_df</code>, they both are summed across shards;</li>
<li>with <code>global_idf</code>, they both are taken from a static IDF file.</li>
</ul>
<p>The static <code>global_idf</code> file actually stores a bunch of <code>n</code> values for every individual term, and the <code>N</code> value for the entire corpus, summed over all the source files that were available during <code>--buildidf</code> stage. For terms that are not present in the static <code>global_idf</code> file, their current (dynamic) DF values will be used. <code>local_df</code> should also still affect those.</p>
<p>To avoid overflows, <code>N</code> is adjusted up for the actual corpus size. Meaning that, for example, if the <code>global_idf</code> file says there were 1000 documents, but your index carries 3000 documents, then <code>N</code> is set to the bigger value, i.e. 3000. Therefore, you should either avoid using too small data slices for dictionary dumps, and/or manually adjust the frequencies, otherwise your static IDFs might be quite off.</p>
<p>To keep the <code>global_idf</code> file reasonably compact, you can use the additional <code>--skip-uniq</code> switch when doing the <code>--buildidf</code> stage. That switch will filter out all terms that only occur once. That usually reduces the <code>.idf</code> file size greatly, while still yielding exact or almost-exact results.</p>
<h3 id="how-sphinx-computes-idf">How Sphinx computes IDF</h3>
<p>In v.3.4 we finished cleaning the legacy IDF code. Before, we used to support two different methods to compute IDF, and we used to have dubious IDF scaling. All that legacy is now gone, finally and fully, and we do not plan any further significant changes.</p>
<p>Nowadays, Sphinx always uses the following formula to compute IDF from <code>n</code> (document frequency) and <code>N</code> (corpus size).</p>
<ul>
<li><code>idf = min(log(N/n), IDF_LIMIT) * term_idf_boost</code></li>
<li><code>IDF_LIMIT</code> is currently hardcoded at 20.0</li>
</ul>
<p>So we start with de-facto standard <code>raw_idf = log(N/n)</code>; then clamp it with <code>IDF_LIMIT</code> (and stop differentiating between extremely rare keywords); then apply per-term user boosts from the query.</p>
<p>Note how with the current limit of 20.0 “extremely rare” <em>specifically</em> means that just the keywords that occur less than once per as much as ~485.2 million tokens will be considered “equal” for ranking purposes. We may eventually change this limit.</p>
<p><code>term_idf_boost</code> naturally defaults to <code>1.0</code> but can be changed for individual query terms by using the respective <a href="#keyword-modifiers">keyword modifier</a>, eg. <code>... WHERE MATCH('cat^1.2 dog')</code>.</p>
<h2 id="ranking-picking-fields-with-rank_fields">Ranking: picking fields with <code>rank_fields</code></h2>
<p>When your indexes and queries contain any special “fake” keywords (usually used to speedup matching), it makes sense to exclude those from ranking. That can be achieved by putting such keywords into special fields, and then using <code>OPTION rank_fields</code> clause in the <code>SELECT</code> statement to pick the fields with actual text for ranking. For example:</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb99-1"><a href="#cb99-1"></a><span class="kw">SELECT</span> <span class="kw">id</span>, weight(), title <span class="kw">FROM</span> myindex</span>
<span id="cb99-2"><a href="#cb99-2"></a><span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello world @sys _category1234&#39;</span>)</span>
<span id="cb99-3"><a href="#cb99-3"></a><span class="kw">OPTION</span> rank_fields<span class="op">=</span><span class="st">&#39;title content&#39;</span></span></code></pre></div>
<p><code>rank_fields</code> is designed to work as follows. Only the keyword occurrences in the ranked fields get processed when computing ranking factors. Any other occurrences are ignored (by ranking, that is).</p>
<p>Note a slight caveat here: for <em>query-level</em> factors, only the <em>query</em> itself can be analyzed, not the index data.</p>
<p>This means that when you do not explicitly specify the fields in the query, the query parser <em>must</em> assume that the keyword can actually occur anywhere in the document. And, for example, <code>MATCH('hello world _category1234')</code> will compute <code>query_word_count=3</code> for that reason. This query does indeed have 3 keywords, even if <code>_category1234</code> never <em>actually</em> occurs anywhere except <code>sys</code> field.</p>
<p>Other than that, <code>rank_fields</code> is pretty straightforward. <em>Matching</em> will still work as usual. But for <em>ranking</em> purposes, any occurrences (hits) from the “system” fields can be ignored and hidden.</p>
<h2 id="ranking-trigrams">Ranking: trigrams</h2>
<p>Signals based on character trigrams are useful to improve ranking for short fields such as document titles. But the respective ranking gains are not that huge. Naively using full and exact trigram sets (and thus exact signals) is, basically, way too expensive to justify those gains.</p>
<p>However, we found that using <strong>coarse trigram sets</strong> (precomputed and stored as <strong>tiny Bloom filters</strong>) also yields measurable ranking improvements, while having only a very small impact on performance: about just 1-5% extra CPU load both when indexing and searching. So we added trigram indexing and ranking support based on that.</p>
<p>Here’s a quick overview of the essentials.</p>
<ul>
<li><p>When indexing, we can now compute and store a per-field “trigram filter”, ie. a tiny Bloom filter <em>coarsely</em> representing the field text trigrams.</p></li>
<li><p>Note that trigram (filters) indexing is optional and must be enabled explicitly, using the <code>index_trigram_fields</code> directive.</p></li>
<li><p>When searching, we use those filters (where available) to compute a few additional trigram ranking signals.</p></li>
<li><p>Trigram signals are accessible via <code>FACTORS()</code> function as usual; all their names begin with a <code>trf_</code> prefix (TRF means Trigram Filter).</p></li>
<li><p>Note that trigram signals are <em>always</em> available to both ranking expressions and UDFs, but for fields without trigram filters, they are all zeroed out (except for <code>trf_qt</code> which equals -1 in that case).</p></li>
</ul>
<p>That’s basically all the high-level notes; now let’s move on to the nitty-gritty details.</p>
<p>As mentioned, trigram filter indexing is enabled by <code>index_trigram_fields</code> directive, for example:</p>
<pre><code>index_trigram_fields = title, keywords</code></pre>
<p>Both plain and RT indexes are supported. The Bloom filter size is currently hardcoded at 128 bits (ie. 16 bytes) per each field. The filters are stored as hidden system document attributes.</p>
<p>Expression ranker (ie. <code>OPTION ranker=expr(...)</code>) then checks for such filters when searching, and computes a few extra signals for fields that have them. Here is a brief reference table.</p>
<table>
<thead>
<tr class="header">
<th>Signal</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>trf_qt</td>
<td>Fraction of Query Trigrams present in field filter</td>
</tr>
<tr class="even">
<td>trf_i2u</td>
<td>Ratio of Intersection to Union filter bitcounts</td>
</tr>
<tr class="odd">
<td>trf_i2q</td>
<td>Ratio of Intersection to Query filter bitcounts</td>
</tr>
<tr class="even">
<td>trf_i2f</td>
<td>Ratio of Intersection to Field filter bitcounts</td>
</tr>
<tr class="odd">
<td>trf_aqt</td>
<td>Fraction of Alphanum Query Trigrams present in field filter</td>
</tr>
<tr class="even">
<td>trf_naqt</td>
<td>Number of Alphanum Query Trigrams</td>
</tr>
</tbody>
</table>
<p>Trigrams are computed over almost raw field and query text. “Almost raw” means that we still apply <code>charset_table</code> for case folding, but perform no other text processing. Even the special characters should be retained.</p>
<p>Trigrams sets are then heavily pruned, again both for field and query text, and then squashed into Bloom filters. This step makes our internal representations quite coarse.</p>
<p>However, it also ensures that even the longer input texts never overflow the resulting filter. Pruning only keeps a few select trigrams, and the exact limit is derived based on the filter size. So that the false positive rate after compressing the pruned trigrams into a filter is still reasonable.</p>
<p>That’s rather important, because in all the signal computations the engine uses those coarse values, ie. pruned trigram sets first, and then filters built from those next. Meaning that signals values are occasionally way off from what one would intuitively expect. Note that for very short input texts (say, upto 10-20 characters) the filters could still yield exact results. But that can not be <em>guaranteed</em>; not even for texts that short.</p>
<p>That being said, the new trigram signals are specifically computed as follows. Let’s introduce the following short names:</p>
<ul>
<li><code>qt</code>, set of query trigrams (also pruned, same as field trigrams)</li>
<li><code>aqt</code>, subset of alphanumeric-only query trigrams</li>
<li><code>QF</code>, query trigrams filter (built from <code>qt</code>)</li>
<li><code>FF</code>, field trigrams filter</li>
<li><code>popcount()</code>, population count, ie. number of set bits (in a filter)</li>
</ul>
<p>In those terms, the signals are computed as follows:</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1"></a>trf_qt <span class="op">=</span> <span class="bu">len</span>([x <span class="cf">for</span> x <span class="kw">in</span> qt where FF.probably_has(x)]) <span class="op">/</span> <span class="bu">len</span>(qt)</span>
<span id="cb101-2"><a href="#cb101-2"></a>trf_i2u <span class="op">=</span> popcount(QF <span class="op">&amp;</span> FF) <span class="op">/</span> popcount(QF <span class="op">|</span> FF)</span>
<span id="cb101-3"><a href="#cb101-3"></a>trf_i2q <span class="op">=</span> popcount(QF <span class="op">&amp;</span> FF) <span class="op">/</span> popcount(QF)</span>
<span id="cb101-4"><a href="#cb101-4"></a>trf_i2f <span class="op">=</span> popcount(QF <span class="op">&amp;</span> FF) <span class="op">/</span> popcount(FF)</span></code></pre></div>
<p>So-called “alphanum” trigrams are extracted from additionally filtered query text, keeping just the terms completely made of latin alphanumeric characters (ie. <code>[a-z0-9]</code> characters only), and ignoring any other terms (ie. with special characters, or in national languages, etc).</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1"></a>trf_aqt <span class="op">=</span> <span class="bu">len</span>([x <span class="cf">for</span> x <span class="kw">in</span> aqt where FF.probably_has(x)]) <span class="op">/</span> <span class="bu">len</span>(aqt)</span>
<span id="cb102-2"><a href="#cb102-2"></a>trf_naqt <span class="op">=</span> <span class="bu">len</span>(aqt)</span></code></pre></div>
<p>Any divisions by zero must be checked and must return 0.0 rather than infinity.</p>
<p>Naturally, as almost all these signals (except <code>trf_naqt</code>) are ratios, they are floats in the 0..1 range.</p>
<p>However, the leading <code>trf_qt</code> ratio is at the moment also reused to signal that the trigram filter is not available for the current field. In that case it gets set to -1. So you want to clamp it by zero in your ranking formulas and UDFs.</p>
<p>All these signals are always accessible in both ranking expressions and UDFs, even if the index was built without trigrams. However, for brevity they are suppressed from the <code>FACTORS()</code> output:</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb103-1"><a href="#cb103-1"></a>mysql<span class="op">&gt;</span> <span class="kw">select</span> <span class="kw">id</span>, title, pp(factors()) <span class="kw">from</span> index_no_trigrams</span>
<span id="cb103-2"><a href="#cb103-2"></a>    <span class="op">-&gt;</span> <span class="kw">where</span> match(<span class="st">&#39;Test It&#39;</span>) <span class="kw">limit</span> <span class="dv">1</span></span>
<span id="cb103-3"><a href="#cb103-3"></a>    <span class="op">-&gt;</span> <span class="kw">option</span> ranker<span class="op">=</span>expr(<span class="st">&#39;sum(lcs)*1000+bm15&#39;</span>) \G</span>
<span id="cb103-4"><a href="#cb103-4"></a><span class="op">***************************</span> <span class="fl">1.</span> <span class="kw">row</span> <span class="op">***************************</span></span>
<span id="cb103-5"><a href="#cb103-5"></a>           <span class="kw">id</span>: <span class="dv">2702</span></span>
<span id="cb103-6"><a href="#cb103-6"></a>        title: Flu<span class="op">....</span>test<span class="op">..</span>.</span>
<span id="cb103-7"><a href="#cb103-7"></a>pp(factors()): {</span>
<span id="cb103-8"><a href="#cb103-8"></a>  <span class="ot">&quot;bm15&quot;</span>: <span class="dv">728</span>,</span>
<span id="cb103-9"><a href="#cb103-9"></a><span class="op">..</span>.</span>
<span id="cb103-10"><a href="#cb103-10"></a>  <span class="ot">&quot;fields&quot;</span>: [</span>
<span id="cb103-11"><a href="#cb103-11"></a>    {</span>
<span id="cb103-12"><a href="#cb103-12"></a>      <span class="ot">&quot;field&quot;</span>: <span class="dv">0</span>,</span>
<span id="cb103-13"><a href="#cb103-13"></a>      <span class="ot">&quot;lcs&quot;</span>: <span class="dv">1</span>,</span>
<span id="cb103-14"><a href="#cb103-14"></a><span class="op">..</span>.</span>
<span id="cb103-15"><a href="#cb103-15"></a>      <span class="ot">&quot;is_number_hits&quot;</span>: <span class="dv">0</span>,</span>
<span id="cb103-16"><a href="#cb103-16"></a>      <span class="ot">&quot;has_digit_hits&quot;</span>: <span class="dv">0</span></span>
<span id="cb103-17"><a href="#cb103-17"></a>    },</span>
<span id="cb103-18"><a href="#cb103-18"></a><span class="op">..</span>.</span>
<span id="cb103-19"><a href="#cb103-19"></a>}</span>
<span id="cb103-20"><a href="#cb103-20"></a></span>
<span id="cb103-21"><a href="#cb103-21"></a></span>
<span id="cb103-22"><a href="#cb103-22"></a>mysql<span class="op">&gt;</span> <span class="kw">select</span> <span class="kw">id</span>, title, pp(factors()) <span class="kw">from</span> index_title_trigrams</span>
<span id="cb103-23"><a href="#cb103-23"></a>    <span class="op">-&gt;</span> <span class="kw">where</span> match(<span class="st">&#39;Test It&#39;</span>) <span class="kw">limit</span> <span class="dv">1</span></span>
<span id="cb103-24"><a href="#cb103-24"></a>    <span class="op">-&gt;</span> <span class="kw">option</span> ranker<span class="op">=</span>expr(<span class="st">&#39;sum(lcs)*1000+bm15&#39;</span>) \G</span>
<span id="cb103-25"><a href="#cb103-25"></a><span class="op">***************************</span> <span class="fl">1.</span> <span class="kw">row</span> <span class="op">***************************</span></span>
<span id="cb103-26"><a href="#cb103-26"></a>           <span class="kw">id</span>: <span class="dv">2702</span></span>
<span id="cb103-27"><a href="#cb103-27"></a>        title: Flu<span class="op">....</span>test<span class="op">..</span>.</span>
<span id="cb103-28"><a href="#cb103-28"></a>pp(factors()): {</span>
<span id="cb103-29"><a href="#cb103-29"></a>  <span class="ot">&quot;bm15&quot;</span>: <span class="dv">728</span>,</span>
<span id="cb103-30"><a href="#cb103-30"></a><span class="op">..</span>.</span>
<span id="cb103-31"><a href="#cb103-31"></a>  <span class="ot">&quot;fields&quot;</span>: [</span>
<span id="cb103-32"><a href="#cb103-32"></a>    {</span>
<span id="cb103-33"><a href="#cb103-33"></a>      <span class="ot">&quot;field&quot;</span>: <span class="dv">0</span>,</span>
<span id="cb103-34"><a href="#cb103-34"></a>      <span class="ot">&quot;lcs&quot;</span>: <span class="dv">1</span>,</span>
<span id="cb103-35"><a href="#cb103-35"></a><span class="op">..</span>.</span>
<span id="cb103-36"><a href="#cb103-36"></a>      <span class="ot">&quot;is_number_hits&quot;</span>: <span class="dv">0</span>,</span>
<span id="cb103-37"><a href="#cb103-37"></a>      <span class="ot">&quot;has_digit_hits&quot;</span>: <span class="dv">0</span>,</span>
<span id="cb103-38"><a href="#cb103-38"></a>      <span class="ot">&quot;trf_qt&quot;</span>: <span class="fl">0.666667</span>,</span>
<span id="cb103-39"><a href="#cb103-39"></a>      <span class="ot">&quot;trf_i2u&quot;</span>: <span class="fl">0.181818</span>,</span>
<span id="cb103-40"><a href="#cb103-40"></a>      <span class="ot">&quot;trf_i2q&quot;</span>: <span class="fl">0.666667</span>,</span>
<span id="cb103-41"><a href="#cb103-41"></a>      <span class="ot">&quot;trf_i2f&quot;</span>: <span class="fl">0.200000</span>,</span>
<span id="cb103-42"><a href="#cb103-42"></a>      <span class="ot">&quot;trf_aqt&quot;</span>: <span class="fl">0.666667</span>,</span>
<span id="cb103-43"><a href="#cb103-43"></a>      <span class="ot">&quot;trf_naqt&quot;</span>: <span class="fl">3.000000</span></span>
<span id="cb103-44"><a href="#cb103-44"></a>    },</span>
<span id="cb103-45"><a href="#cb103-45"></a><span class="op">..</span>.</span>
<span id="cb103-46"><a href="#cb103-46"></a>}</span></code></pre></div>
<p>Note how in the super simple example above the ratios are rather as expected, after all. Query and field have just 3 trigrams each (“it” also makes a trigram, despite being short). All text here is alphanumeric, 2 out of 3 trigrams match, and all the respective ratios are 0.666667, as they should.</p>
<h2 id="siege-mode">Operations: “siege mode”, temporary global query limits</h2>
<p>Sphinx <code>searchd</code> now has a so-called “siege mode” that temporarily imposes server-wide limits on <em>all</em> the incoming <code>SELECT</code> queries, for a given amount of time. This is useful when some client is flooding <code>searchd</code> with heavy requests and, for whatever reason, stopping those requests at other levels is complicated.</p>
<p>Siege mode is controlled via a few global server variables. The example just below will introduce a siege mode for 15 seconds, and impose limits of at most 1000 processed documents and at most 0.3 seconds (wall clock) per query:</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb104-1"><a href="#cb104-1"></a><span class="kw">set</span> <span class="kw">global</span> siege<span class="op">=</span><span class="dv">15</span></span>
<span id="cb104-2"><a href="#cb104-2"></a><span class="kw">set</span> <span class="kw">global</span> siege_max_fetched_docs<span class="op">=</span><span class="dv">1000</span></span>
<span id="cb104-3"><a href="#cb104-3"></a><span class="kw">set</span> <span class="kw">global</span> siege_max_query_msec<span class="op">=</span><span class="dv">300</span></span></code></pre></div>
<p>Once the timeout reaches zero, the siege mode will be automatically lifted.</p>
<p>There also are intentionally hardcoded limits you can’t change, namely:</p>
<ul>
<li>upper limit for <code>siege</code> is 300 seconds, i.e. 5 minutes</li>
<li>upper limit for <code>siege_max_fetched_docs</code> is 1,000,000 documents</li>
<li>upper limit for <code>siege_max_query_msec</code> is 1 second, i.e. 1000 msec</li>
</ul>
<p>Note that <strong>current siege limits are reset when the siege stops.</strong> So in the example above, if you start another siege in 20 seconds, then that next siege will be restarted with 1M docs and 1000 msec limits, and <em>not</em> the 1000 docs and 300 msec limits from the previous one.</p>
<p>Siege mode can be turned off at any moment by zeroing out the timeout:</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb105-1"><a href="#cb105-1"></a><span class="kw">set</span> <span class="kw">global</span> siege<span class="op">=</span><span class="dv">0</span></span></code></pre></div>
<p>The current siege duration left (if any) is reported in <code>SHOW STATUS</code>:</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb106-1"><a href="#cb106-1"></a>mysql<span class="op">&gt;</span> show status <span class="kw">like</span> <span class="st">&#39;siege%&#39;</span>;</span>
<span id="cb106-2"><a href="#cb106-2"></a><span class="op">+</span><span class="co">------------------------+---------+</span></span>
<span id="cb106-3"><a href="#cb106-3"></a>| Counter                | <span class="fu">Value</span>   |</span>
<span id="cb106-4"><a href="#cb106-4"></a><span class="op">+</span><span class="co">------------------------+---------+</span></span>
<span id="cb106-5"><a href="#cb106-5"></a>| siege_sec_left         | <span class="dv">296</span>     |</span>
<span id="cb106-6"><a href="#cb106-6"></a><span class="op">+</span><span class="co">------------------------+---------+</span></span>
<span id="cb106-7"><a href="#cb106-7"></a><span class="dv">1</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>And to check the current limits, you can check <code>SHOW VARIABLES</code>:</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb107-1"><a href="#cb107-1"></a>mysql<span class="op">&gt;</span> show variables <span class="kw">like</span> <span class="st">&#39;siege%&#39;</span>;</span>
<span id="cb107-2"><a href="#cb107-2"></a><span class="op">+</span><span class="co">------------------------+---------+</span></span>
<span id="cb107-3"><a href="#cb107-3"></a>| Counter                | <span class="fu">Value</span>   |</span>
<span id="cb107-4"><a href="#cb107-4"></a><span class="op">+</span><span class="co">------------------------+---------+</span></span>
<span id="cb107-5"><a href="#cb107-5"></a>| siege_max_query_msec   | <span class="dv">1000</span>    |</span>
<span id="cb107-6"><a href="#cb107-6"></a>| siege_max_fetched_docs | <span class="dv">1000000</span> |</span>
<span id="cb107-7"><a href="#cb107-7"></a><span class="op">+</span><span class="co">------------------------+---------+</span></span>
<span id="cb107-8"><a href="#cb107-8"></a><span class="dv">2</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>Next order of business, the document limit has a couple interesting details that require explanation.</p>
<p>First, the <code>fetched_docs</code> counter is calculated a bit differently for term and non-term searches. For term searches, it counts all the (non-unique!) rows that were fetched by full-text term readers, batch by batch. For non-term searches, it counts all the (unique) alive rows that were matched (either by an attribute index read, or by a full scan).</p>
<p>Second, for multi-index searches, the <code>siege_max_fetched_docs</code> limit will be split across the local indexes (shards), weighted by their document count.</p>
<p>If you’re really curious, let’s discuss those bits in more detail.</p>
<p>The non-term search case is rather easy. All the actually stored rows (whether coming either from a full scan or an attribute index reads) will be first checked for liveness, then accounted in the <code>fetched_docs</code> counter, then either further processed (with extra calculations, filters, etc). Bottom line, a query limited this way will run “hard” calculations, filter checks, etc on at most N rows. So best case scenario (if all <code>WHERE</code> filters pass), the query will return N rows, and never even a single row more.</p>
<p>Now, the term search case is more interesting. The lowest-level term readers will also emit individual rows, but as opposed to the “scan” case, either the terms or the rows might be duplicated. The <code>fetched_docs</code> counter merely counts those emitted rows, as it needs to limit the total amount of work done. So, for example, with a 2-term query like <code>(foo bar)</code> the processing will stop when <em>both</em> terms fetch N documents total from the full-text index… even if not a single document was <em>matched</em> just yet! If a term is duplicated, for example, like in a <code>(foo foo)</code> query, then <em>both</em> the occurrences will contribute to the counter. Thus, for a query with M required terms all AND-ed together, the upper limit on the <em>matched</em> documents should be roughly equal to N/M, because every matched document will be counted as “processed” M times in every term reader. So either <code>(foo bar)</code> or <code>(foo foo)</code> example queries with a limit of 1000 should result in roughly 500 matches tops.</p>
<p>That “roughly” just above means that, occasionally, there might be slightly more matches. As for performance reasons the term readers work in batches, the actual <code>fetched_docs</code> counter might get slightly bigger than the imposed limit, by the batch size at the most. But that must be insignificant as processing just a single small batch is very quick.</p>
<p>And as for splitting the limit between the indexes, it’s simply pro-rata, based on the per-index document count. For example, assume that <code>siege_max_fetched_docs</code> is set to 1000, and that you have 2 local indexes in your query, one with 1400K docs and one with 600K docs respectively. (It does not matter whether those are referenced directly or via a distributed index.) Then the per-index limits will be set to 700 and 300 documents respectively. Easy.</p>
<p>Last but not least, beware that the entire point of the “siege mode” is to <strong>intentionally degrade the search results for too complex searches</strong>! Use with extreme care; essentially only use it to stomp out cluster fires that can not be quickly alleviated any other way; and at this point we recommend to only <em>ever</em> use it manually.</p>
<h2 id="operations-network-internals">Operations: network internals</h2>
<p>Let’s look into a few various <code>searchd</code> network implementation details that might be useful from an operational standpoint: how it handles incoming client queries, how it handles outgoing queries to other machines in the cluster, etc.</p>
<h3 id="incoming-client-queries">Incoming (client) queries</h3>
<h4 id="threading-and-networking-modes">Threading and networking modes</h4>
<p><code>searchd</code> currently supports two threading modes, <code>threads</code> and <code>thread_pool</code>, and two networking modes are naturally tied to those threading modes.</p>
<p>In the first mode (<code>threads</code>), a separate dedicated per-client thread gets spawned for every incoming network connection. It then handles everything, both network IO and request processing. Having processing and network IO in the same thread is optimal latency-wise, but unfortunately there are several other major issues:</p>
<ul>
<li>classic C10K problem: each inactive client stalls its thread, many inactive clients stall all available threads and DoS the server;</li>
<li>synchronous processing problem: thread that works on a request can’t react to <em>any</em> network events such as client going away;</li>
<li>slow client problem: active but slow client stalls its thread while doing either network request reads or response writes.</li>
</ul>
<p>In the second mode (<code>thread_pool</code>), worker threads are isolated from client IO, and only work on the requests. All client network IO is performed in a dedicated network thread. It runs the so-called <strong>net loop</strong> that multiplexes (many) open connections and handles them (very) efficiently.</p>
<p>What does the network thread actually do? It does all network reads and writes, for all the protocols (SphinxAPI, SphinxQL, HTTP) too, by the way. It also does a tiny bit of its own packet processing (basically parsing just a few required headers). For full packet parsing and request processing, it sends the request packets to worker threads from the pool, and gets the response packets back.</p>
<p>You can create more than 1 network thread using the <code>net_workers</code> directive. That helps when the query pressure is so extreme that 1 thread gets maxed out. On a quick and dirty benchmark with v.3.4 (default <code>searchd</code> settings; 96-core server; 128 clients doing point selects), we got ~110K RPS with 1 thread. Using 2 threads (ie. <code>net_workers = 2</code>) improved that to ~140K RPS, 3 threads got us ~170K RPS, 4 threads got ~180K-190K RPS, and then 5 and 6 threads did not yield any further improvements.</p>
<p>Having a dedicated network thread (with some <code>epoll(7)</code> magic of course) solves all the aforementioned problems. 10K (and more) open connections with reasonable total RPS are now easily handled even with 1 thread, instead of forever blocking 10K OS threads. Ditto for slow clients, also nicely handled by just 1 thread. And last but not least, it asynchronously watches all the sockets even while worker threads process the requests, and signals the workers as needed. Nice!</p>
<p>Of course all those solutions come at a price: there is a rather inevitable <strong>tiny latency impact</strong>, caused by packet data traveling between network and worker threads. On our benchmarks with v.3.4 we observe anywere between 0.0 and 0.4 msec average extra latency per query, depending on specific benchmark setup. Now, given that <em>average</em> full-text queries usually take 20-100 msec and more, in most cases this extra latency impact would be under 2%, if not negligible.</p>
<p>Still, take note that in a <em>borderline</em> case when your <em>average</em> latency is at ~1 msec range, ie. when practically <em>all</em> your queries are quick and tiny, even those 0.4 msec might matter. Our point select benchmark is exactly like that, and <code>threads</code> mode very expectedly shines! At 128 clients we get ~180 Krps in <code>thread_pool</code> mode and ~420 Krps in <code>threads</code> mode. The respective average latencies are 0.304 msec and 0.711 msec, the difference is 0.407 msec, everything computes.</p>
<p>Now, <em>client</em> application approaches to networking are also different:</p>
<ul>
<li>one-off connections, ie. new one established for every query;</li>
<li>small pool, ie. say up to 100-200 “active enough” connections;</li>
<li>huge pool, ie. 1K..10K+ “lazy enough” connections (aka C10K).</li>
</ul>
<p><strong>Net loop mode handles all these cases gracefully</strong> when properly configured, even under suddenly high load. As the workers threads count is limited, incoming requests that we do not have the capacity to process are simply going to be enqueued and and wait for a free worker thread.</p>
<p><strong>Client thread mode does not</strong>. When the <code>max_children</code> thread limit is too small, any connections over the limit are rejected. Even if threads currently using up that limit are sitting doing nothing! And when the limit is too high, <code>searchd</code> is at risk, <code>threads</code> could fail <em>miserably</em> and kill the server. Because if we allow “just” 1000 expectedly lazy clients, then we have to raise <code>max_children</code> to 1000, but then nothing prevents the clients from becoming active and firing a volley of <em>simultaneous</em> heavy queries. Instantly converting 1000 mostly sleeping threads to 1000 very active ones. Boom, your server is dead now, <code>ssh</code> does not work, where was that bloody KVM password?</p>
<p>With net loop, defending the castle is (much) easier. Even 1 network thread can handle network IO for 1000 lazy clients alright. So we can keep <code>max_children</code> reasonable, properly based on the server core count, <em>not</em> the expected open connections count. Of course, a sudden volley of 1000 simultaneous heavy queries will never go completely unnoticed. It will still max out the worker threads. For the sake of example, say we set our limit at 40 threads. Those 40 threads will get instantly busy processing 40 requests, but 960 more requests will be merely enqueued rather than using up 960 more threads. In fact, queue length can also be limited by <code>queue_max_length</code> directive, but the default value is 0 (unlimited). Boom, your server is now quite busy, and the request queue length might be massive. But at least <code>ssh</code> works, and just 40 cores are busy, and there are might be a few spare ones. Much better.</p>
<p>Quick summary?</p>
<p><code>thread_pool</code> threading and net loop networking are better in most of the production scenarios, and hence they are the default mode. Yes, sometimes they <em>might</em> add tiny extra latency, but then again, sometimes they would not.</p>
<p>However, in one very special case (when all your queries are sub-millisecond and you are actually gunning for 500K+ RPS), consider using <code>threads</code> mode, because less overheads and better RPS.</p>
<h4 id="client-disconnects">Client disconnects</h4>
<p>Clients can suddenly disconnect for any reason, at any time. Including while the server is busy processing a heavy read request. Which the server could then cancel, and save itself some CPU and disk.</p>
<p>In client thread mode, we can not do anything about that disconnect, though. Basically, because while the per-client thread is busy processing the request, it can not afford to constantly check the client socket.</p>
<p>In net loop mode, yes we can! Net loop constantly watches <em>all</em> the client sockets using a dedicated thread, catches such disconnects ASAP, and then either automatically raises the early termination flag if there is a respective worker thread (exactly as manual <a href="#kill-syntax"><code>KILL</code> statement</a> would), or removes the previously enqueued request if it was still waiting for a worker.</p>
<p>Therefore, <strong>in net loop mode, client disconnect auto-KILLs its current query</strong>. Which might sounds dangerous but really is not. Basically because the affected queries are reads.</p>
<h3 id="outgoing-distributed-queries">Outgoing (distributed) queries</h3>
<p>Queries that involve remote instances generally work as follows:</p>
<ol type="1">
<li><code>searchd</code> connects to all the required remote <code>searchd</code> instances (we call them “agents”,) and sends the respective queries to those instances.</li>
<li>Then it runs all the required local queries, if any.</li>
<li>Then it waits for the remote responses, and does query retries as needed.</li>
<li>Then it aggregates the final result set, and serves that back to client.</li>
</ol>
<p>Generally quite simple, but of course there are quite a few under-the-hood implementation details and quirks. Let’s cover the bigger ones.</p>
<p>The inter-instance protocol is SphinxAPI, so all instances in the cluster <em>must</em> have a SphinxAPI listener.</p>
<p>By default, a new connection to every agent is created for every query. However, in <code>workers = threads</code> mode we additionally support <code>agent_persistent</code> and <code>persistent_connections_limit</code> directives that tell the master instance to keep and reuse a pool of open persistent connections to every such agent. The limit is per-agent.</p>
<p>Connection step timeout is controlled by <code>agent_connect_timeout</code> directive, and defaults to 1000 msec (1 sec). Also, searches (<code>SELECT</code> queries) might retry on connection failures, upto <code>agent_retry_count</code> times (default is 0 though), and they will sleep for <code>agent_retry_delay</code> msec on each retry.</p>
<p>Note that if network connections attempts to some agent stall and timeout (rather than failing quickly), you can end up with <em>all</em> distributed queries also stalling for at least 1 sec. The root cause here is usually more of a host configuration issue; say, a firewall dropping packets. Still, it makes sense to lower the <code>agent_connect_timeout</code> preemptively, to reduce the overall latency even in the unfortunate event of such configuration issues suddenly popping up. We find that timeouts from 100 to 300 msec work well within a single DC.</p>
<p>Querying step timeout is in turn controlled by <code>agent_query_timeout</code>, and defaults to 3000 msec, or 3 sec. Same retrying rules apply. Except that query timeouts are usually caused by slow queries rather than network issues! Meaning that the default <code>agent_query_timeout</code> should be adjusted with quite more care, taking into account your typical queries, SLAs, etc.</p>
<p>Note that these timeouts can (and sometimes must!) be overriden by the client application on a per-query basis. For instance, what if 99% of the time we run quick searches that must complete say within 0.5 sec according to our SLA, but occasionally we still need to fire an analytical search query taking much more, say up to 1 minute? One solution here would be to set <code>searchd</code> defaults at <code>agent_query_timeout = 500</code> for the majority of the queries, and specify <code>OPTION agent_query_timeout = 60000</code> in the individual special queries.</p>
<p><code>agent_retry_count</code> applies to <em>both</em> connection and querying attempts. Example, <code>agent_retry_count = 1</code> means that either connection <em>or</em> query attempt would be retried, but not both. More verbosely, if <code>connect()</code> failed initially, but then succeeded on retry, and then the query timed out, then the query does <em>not</em> get retried because we were only allowed 1 retry total and we spent it connecting.</p>
<h2 id="sphinxql-reference">SphinxQL reference</h2>
<p>This section should eventually contain the complete SphinxQL reference. If the statement you’re looking for is not yet documented here, please refer to legacy <a href="sphinx2.html#sphinxql-reference">SphinxQL v.2.x reference</a> document.</p>
<p>Here’s a complete list of SphinxQL statements.</p>
<ul>
<li><a href="sphinx2.html#sphinxql-attach">ALTER syntax</a></li>
<li><a href="sphinx2.html#sphinxql-attach-index">ATTACH INDEX syntax</a></li>
<li><a href="sphinx2.html#sphinxql-begin">BEGIN syntax</a></li>
<li><a href="sphinx2.html#sphinxql-commit">BEGIN, COMMIT, and ROLLBACK syntax</a></li>
<li><a href="#bulk-update-syntax">BULK UPDATE syntax</a></li>
<li><a href="sphinx2.html#sphinxql-call-keywords">CALL KEYWORDS syntax</a></li>
<li><a href="sphinx2.html#sphinxql-call-qsuggest">CALL QSUGGEST syntax</a></li>
<li><a href="sphinx2.html#sphinxql-call-snippets">CALL SNIPPETS syntax</a></li>
<li><a href="sphinx2.html#sphinxql-call-suggest">CALL SUGGEST syntax</a></li>
<li><a href="sphinx2.html#sphinxql-create-function">CREATE FUNCTION syntax</a></li>
<li><a href="#create-index-syntax">CREATE INDEX syntax</a></li>
<li><a href="sphinx2.html#sphinxql-create-plugin">CREATE PLUGIN syntax</a></li>
<li><a href="sphinx2.html#sphinxql-delete">DELETE syntax</a></li>
<li><a href="sphinx2.html#sphinxql-describe">DESCRIBE syntax</a></li>
<li><a href="sphinx2.html#sphinxql-drop-function">DROP FUNCTION syntax</a></li>
<li><a href="#drop-index-syntax">DROP INDEX syntax</a></li>
<li><a href="sphinx2.html#sphinxql-drop-plugin">DROP PLUGIN syntax</a></li>
<li><a href="sphinx2.html#sphinxql-flush-attributes">FLUSH ATTRIBUTES syntax</a></li>
<li><a href="sphinx2.html#sphinxql-flush-hostnames">FLUSH HOSTNAMES syntax</a></li>
<li><a href="sphinx2.html#sphinxql-flush-ramchunk">FLUSH RAMCHUNK syntax</a></li>
<li><a href="sphinx2.html#sphinxql-flush-rtindex">FLUSH RTINDEX syntax</a></li>
<li><a href="sphinx2.html#sphinxql-insert">INSERT and REPLACE syntax</a></li>
<li><a href="#kill-syntax">KILL syntax</a></li>
<li><a href="sphinx2.html#sphinxql-optimize-index">OPTIMIZE INDEX syntax</a></li>
<li><a href="sphinx2.html#sphinxql-reload-index">RELOAD INDEX syntax</a></li>
<li><a href="sphinx2.html#sphinxql-reload-plugins">RELOAD PLUGINS syntax</a></li>
<li><a href="sphinx2.html#sphinxql-replace">REPLACE syntax</a></li>
<li><a href="sphinx2.html#sphinxql-rollback">ROLLBACK syntax</a></li>
<li><a href="sphinx2.html#sphinxql-select-sysvar">SELECT ‘system_variable’ syntax</a></li>
<li><a href="sphinx2.html#sphinxql-select">SELECT syntax</a></li>
<li><a href="sphinx2.html#sphinxql-set">SET syntax</a></li>
<li><a href="sphinx2.html#sphinxql-set-transaction">SET TRANSACTION syntax</a></li>
<li><a href="sphinx2.html#sphinxql-show-agent-status">SHOW AGENT STATUS</a></li>
<li><a href="sphinx2.html#sphinxql-show-character-set">SHOW CHARACTER SET syntax</a></li>
<li><a href="sphinx2.html#sphinxql-show-collation">SHOW COLLATION syntax</a></li>
<li><a href="sphinx2.html#sphinxql-show-databases">SHOW DATABASES syntax</a></li>
<li><a href="#show-index-agent-status-syntax">SHOW INDEX AGENT STATUS syntax</a></li>
<li><a href="#show-index-from-syntax">SHOW INDEX FROM syntax</a></li>
<li><a href="sphinx2.html#sphinxql-show-index-settings">SHOW INDEX SETTINGS syntax</a></li>
<li><a href="sphinx2.html#sphinxql-show-index-status">SHOW INDEX STATUS syntax</a></li>
<li><a href="sphinx2.html#sphinxql-show-meta">SHOW META syntax</a></li>
<li><a href="sphinx2.html#sphinxql-show-plan">SHOW PLAN syntax</a></li>
<li><a href="sphinx2.html#sphinxql-show-plugins">SHOW PLUGINS syntax</a></li>
<li><a href="sphinx2.html#sphinxql-show-profile">SHOW PROFILE syntax</a></li>
<li><a href="#show-status-syntax">SHOW STATUS syntax</a></li>
<li><a href="sphinx2.html#sphinxql-show-tables">SHOW TABLES syntax</a></li>
<li><a href="sphinx2.html#sphinxql-threads">SHOW THREADS syntax</a></li>
<li><a href="#show-variables-syntax">SHOW VARIABLES syntax</a></li>
<li><a href="sphinx2.html#sphinxql-show-warnings">SHOW WARNINGS syntax</a></li>
<li><a href="sphinx2.html#sphinxql-truncate-rtindex">TRUNCATE RTINDEX syntax</a></li>
<li><a href="sphinx2.html#sphinxql-update">UPDATE syntax</a></li>
</ul>
<h3 id="bulk-update-syntax">BULK UPDATE syntax</h3>
<div class="sourceCode" id="cb108"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb108-1"><a href="#cb108-1"></a><span class="kw">BULK</span> <span class="kw">UPDATE</span> ftindex (<span class="kw">id</span>, col1 [, col2 [, col3 <span class="op">..</span>.]]) <span class="kw">VALUES</span></span>
<span id="cb108-2"><a href="#cb108-2"></a>(id1, val1_1 [, val1_2 [, val1_3 <span class="op">..</span>.]]),</span>
<span id="cb108-3"><a href="#cb108-3"></a>(id2, val2_1 [, val2_2 [, val2_3 <span class="op">..</span>.]]),</span>
<span id="cb108-4"><a href="#cb108-4"></a><span class="op">..</span>.</span>
<span id="cb108-5"><a href="#cb108-5"></a>(idN, valN_1 [, valN_2 [, valN_3 <span class="op">..</span>.]])</span></code></pre></div>
<p><code>BULK UPDATE</code> lets you update multiple rows with a single statement. Compared to running N individual statements, bulk updates provide both cleaner syntax and better performance.</p>
<p>Overall they are quite similar to regular updates. To summarize quickly:</p>
<ul>
<li>you can update (entire) attributes, naturally keeping their types (even when changing the width, ie. when updating a string, or entire JSON, etc);</li>
<li>you can update numeric values within JSON, also keeping their types (and naturally keeping the width).</li>
</ul>
<p>First column in the list must always be the <code>id</code> column. Rows are uniquely identified by document ids.</p>
<p>Other columns to update can either be regular attributes, or individual JSON keys, also just as with regular <code>UPDATE</code> queries. Here are a couple examples:</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb109-1"><a href="#cb109-1"></a><span class="kw">BULK</span> <span class="kw">UPDATE</span> test1 (<span class="kw">id</span>, price) <span class="kw">VALUES</span> (<span class="dv">1</span>, <span class="fl">100.00</span>), (<span class="dv">2</span>, <span class="fl">123.45</span>), (<span class="dv">3</span>, <span class="fl">299.99</span>)</span>
<span id="cb109-2"><a href="#cb109-2"></a><span class="kw">BULK</span> <span class="kw">UPDATE</span> test2 (<span class="kw">id</span>, json.price) <span class="kw">VALUES</span> (<span class="dv">1</span>, <span class="fl">100.00</span>), (<span class="dv">2</span>, <span class="fl">123.45</span>), (<span class="dv">3</span>, <span class="fl">299.99</span>)</span></code></pre></div>
<p>All value types (numerics, strings, JSON, MVA) are supported.</p>
<p>Bulk updates of existing values <em>must</em> keep the type. This is a natural restriction for regular attributes, but it also applies to JSON values. For example, if you update an integer JSON value with a float, then that float will get converted (truncated) to the current integer type.</p>
<p>Compatible value type conversions will happen. Truncations are allowed.</p>
<p>Incompatible conversions will fail. For example, strings will <em>not</em> be auto-converted to numeric values.</p>
<p>Attempts to update non-existent JSON keys will fail.</p>
<h3 id="create-index-syntax">CREATE INDEX syntax</h3>
<div class="sourceCode" id="cb110"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb110-1"><a href="#cb110-1"></a><span class="kw">CREATE</span> <span class="kw">INDEX</span> [<span class="op">&lt;</span>name<span class="op">&gt;</span>] <span class="kw">ON</span> <span class="op">&lt;</span>ftindex<span class="op">&gt;</span>({<span class="op">&lt;</span>col_name<span class="op">&gt;</span> | <span class="op">&lt;</span>json_field<span class="op">&gt;</span></span>
<span id="cb110-2"><a href="#cb110-2"></a>  | {UINT | BIGINT | <span class="dt">FLOAT</span>}(<span class="op">&lt;</span>json_field<span class="op">&gt;</span>))</span></code></pre></div>
<p><code>CREATE INDEX</code> statement lets you create attribute indexes (aka secondary indexes) either over regular columns, or JSON fields.</p>
<p>Attrbute indexes are identified and managed by names. Names must be unique. You can use either <code>DESCRIBE</code> or <a href="#show-index-from-syntax"><code>SHOW INDEX FROM</code></a> statements to examine what indexes (and names) already exist.</p>
<p>If an explicit attribute index name is not specified, <code>CREATE INDEX</code> will generate one automatically from the indexed value expression. Names generated from JSON expressions are simplified for brevity, and might conflict, even with other autogenerated names. In that case, just use the full syntax, and provide a different attribute index name explicitly.</p>
<p>Upto to 64 attribute indexes per (fulltext) index are allowed.</p>
<p>Currently supported indexable value types are numeric types and integer sets (aka MVA), ie. <code>UINT</code>, <code>BIGINT</code>, <code>FLOAT</code>, <code>MULTI</code>, and <code>MULTI64</code> in SphinxQL terms. Indexing strings is not yet supported.</p>
<p>Indexing both regular columns and JSON fields is pretty straightforward, for example:</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb111-1"><a href="#cb111-1"></a><span class="kw">CREATE</span> <span class="kw">INDEX</span> idx_price <span class="kw">ON</span> products(price)</span>
<span id="cb111-2"><a href="#cb111-2"></a><span class="kw">CREATE</span> <span class="kw">INDEX</span> idx_tags <span class="kw">ON</span> products(tags_mva)</span>
<span id="cb111-3"><a href="#cb111-3"></a><span class="kw">CREATE</span> <span class="kw">INDEX</span> idx_foo <span class="kw">ON</span> product(json.foo)</span>
<span id="cb111-4"><a href="#cb111-4"></a><span class="kw">CREATE</span> <span class="kw">INDEX</span> idx_bar <span class="kw">ON</span> product(json.qux[<span class="dv">0</span>].bar)</span></code></pre></div>
<p>JSON fields are not typed statically, but attributes indexes are, so we <em>must</em> cast JSON field values when indexing. Currently supported casts are <code>UINT</code>, <code>BIGINT</code>, and <code>FLOAT</code> only. Casting from JSON field to integer set is not yet supported. When the explicit type is missing, casting defaults to <code>UINT</code>, and produces a warning:</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb112-1"><a href="#cb112-1"></a>mysql<span class="op">&gt;</span> <span class="kw">CREATE</span> <span class="kw">INDEX</span> idx_foo <span class="kw">ON</span> rt1(j.foo);</span>
<span id="cb112-2"><a href="#cb112-2"></a><span class="kw">Query</span> OK, <span class="dv">0</span> <span class="kw">rows</span> affected, <span class="dv">1</span> warning (<span class="fl">0.08</span> sec)</span>
<span id="cb112-3"><a href="#cb112-3"></a></span>
<span id="cb112-4"><a href="#cb112-4"></a>mysql<span class="op">&gt;</span> show warnings;</span>
<span id="cb112-5"><a href="#cb112-5"></a><span class="op">+</span><span class="co">---------+------+------------------------------------------------------------------------------+</span></span>
<span id="cb112-6"><a href="#cb112-6"></a>| <span class="kw">Level</span>   | Code | Message                                                                      |</span>
<span id="cb112-7"><a href="#cb112-7"></a><span class="op">+</span><span class="co">---------+------+------------------------------------------------------------------------------+</span></span>
<span id="cb112-8"><a href="#cb112-8"></a>| warning | <span class="dv">1000</span> | <span class="kw">index</span> <span class="st">&#39;rt1&#39;</span>: json field <span class="kw">type</span> <span class="kw">not</span> specified <span class="cf">for</span> <span class="st">&#39;j.foo&#39;</span>; defaulting <span class="kw">to</span> <span class="st">&#39;UINT&#39;</span> |</span>
<span id="cb112-9"><a href="#cb112-9"></a><span class="op">+</span><span class="co">---------+------+------------------------------------------------------------------------------+</span></span>
<span id="cb112-10"><a href="#cb112-10"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span>
<span id="cb112-11"><a href="#cb112-11"></a></span>
<span id="cb112-12"><a href="#cb112-12"></a>mysql<span class="op">&gt;</span> <span class="kw">DROP</span> <span class="kw">INDEX</span> idx_foo <span class="kw">ON</span> t1;</span>
<span id="cb112-13"><a href="#cb112-13"></a><span class="kw">Query</span> OK, <span class="dv">0</span> <span class="kw">rows</span> affected (<span class="fl">0.00</span> sec)</span>
<span id="cb112-14"><a href="#cb112-14"></a></span>
<span id="cb112-15"><a href="#cb112-15"></a>mysql<span class="op">&gt;</span> <span class="kw">CREATE</span> <span class="kw">INDEX</span> idx_foo <span class="kw">ON</span> t1(<span class="dt">FLOAT</span>(j.foo));</span>
<span id="cb112-16"><a href="#cb112-16"></a><span class="kw">Query</span> OK, <span class="dv">0</span> <span class="kw">rows</span> affected (<span class="fl">0.09</span> sec)</span></code></pre></div>
<p>Note that <code>CREATE INDEX</code> locks the target fulltext index exclusively, and larger indexes may take a while to create.</p>
<h3 id="drop-index-syntax">DROP INDEX syntax</h3>
<div class="sourceCode" id="cb113"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb113-1"><a href="#cb113-1"></a><span class="kw">DROP</span> <span class="kw">INDEX</span> <span class="op">&lt;</span>name<span class="op">&gt;</span> <span class="kw">ON</span> <span class="op">&lt;</span>ftindex<span class="op">&gt;</span></span></code></pre></div>
<p><code>DROP INDEX</code> statement lets you remove no longer needed attribute index from a given fulltext index.</p>
<p>Note that <code>DROP INDEX</code> locks the target fulltext index exclusively. Usually dropping an index should complete pretty quickly (say a few seconds), but your mileage may vary.</p>
<h3 id="kill-syntax">KILL syntax</h3>
<div class="sourceCode" id="cb114"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb114-1"><a href="#cb114-1"></a><span class="kw">KILL</span> <span class="op">&lt;</span>thread_id<span class="op">&gt;</span></span>
<span id="cb114-2"><a href="#cb114-2"></a><span class="kw">KILL</span> SLOW <span class="op">&lt;</span>min_msec<span class="op">&gt;</span> MSEC</span></code></pre></div>
<p><code>KILL</code> lets you forcibly terminate long-running statements based either on thread ID, or on their current running time.</p>
<p>For the first version, you can obtain the thread IDs using the <a href="sphinx2.html#sphinxql-threads"><code>SHOW THREADS</code></a> statement.</p>
<p>Note that forcibly killed queries are going to return almost as if they completed OK rather than raise an error. They will return a partial result set accumulated so far, and raise a “query was killed” warning. For example:</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb115-1"><a href="#cb115-1"></a>mysql<span class="op">&gt;</span> <span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> rt <span class="kw">LIMIT</span> <span class="dv">3</span>;</span>
<span id="cb115-2"><a href="#cb115-2"></a><span class="op">+</span><span class="co">------+------+</span></span>
<span id="cb115-3"><a href="#cb115-3"></a>| <span class="kw">id</span>   | gid  |</span>
<span id="cb115-4"><a href="#cb115-4"></a><span class="op">+</span><span class="co">------+------+</span></span>
<span id="cb115-5"><a href="#cb115-5"></a>|   <span class="dv">27</span> |  <span class="dv">123</span> |</span>
<span id="cb115-6"><a href="#cb115-6"></a>|   <span class="dv">28</span> |  <span class="dv">123</span> |</span>
<span id="cb115-7"><a href="#cb115-7"></a>|   <span class="dv">29</span> |  <span class="dv">123</span> |</span>
<span id="cb115-8"><a href="#cb115-8"></a><span class="op">+</span><span class="co">------+------+</span></span>
<span id="cb115-9"><a href="#cb115-9"></a><span class="dv">3</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span>, <span class="dv">1</span> warning (<span class="fl">0.54</span> sec)</span>
<span id="cb115-10"><a href="#cb115-10"></a></span>
<span id="cb115-11"><a href="#cb115-11"></a>mysql<span class="op">&gt;</span> SHOW WARNINGS;</span>
<span id="cb115-12"><a href="#cb115-12"></a><span class="op">+</span><span class="co">---------+------+------------------+</span></span>
<span id="cb115-13"><a href="#cb115-13"></a>| <span class="kw">Level</span>   | Code | Message          |</span>
<span id="cb115-14"><a href="#cb115-14"></a><span class="op">+</span><span class="co">---------+------+------------------+</span></span>
<span id="cb115-15"><a href="#cb115-15"></a>| warning | <span class="dv">1000</span> | <span class="kw">query</span> was killed |</span>
<span id="cb115-16"><a href="#cb115-16"></a><span class="op">+</span><span class="co">---------+------+------------------+</span></span>
<span id="cb115-17"><a href="#cb115-17"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>The respective network connections are not going to be forcibly closed.</p>
<p>At the moment, the only statements that can be killed are <code>SELECT</code>, <code>UPDATE</code>, and <code>DELETE</code>. Additional statement types might begin to support <code>KILL</code> in the future.</p>
<p>In both versions, <code>KILL</code> returns the number of threads marked for termination via the affected rows count:</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb116-1"><a href="#cb116-1"></a>mysql<span class="op">&gt;</span> <span class="kw">KILL</span> SLOW <span class="dv">2500</span> MSEC;</span>
<span id="cb116-2"><a href="#cb116-2"></a><span class="kw">Query</span> OK, <span class="dv">3</span> <span class="kw">row</span> affected (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>Threads already marked will not be marked again and reported this way.</p>
<p>There are no limits on the <code>&lt;min_msec&gt;</code> parameter for the second version, and therefore, <code>KILL SLOW 0 MSEC</code> is perfectly legal syntax. That specific statement is going to kill <em>all</em> the currently running queries. So please use with a pinch of care.</p>
<h3 id="select-syntax">SELECT syntax</h3>
<div class="sourceCode" id="cb117"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb117-1"><a href="#cb117-1"></a><span class="kw">SELECT</span> <span class="op">&lt;</span>expr<span class="op">&gt;</span> [<span class="kw">BETWEEN</span> <span class="op">&lt;</span><span class="fu">min</span><span class="op">&gt;</span> <span class="kw">AND</span> <span class="op">&lt;</span><span class="fu">max</span><span class="op">&gt;</span>] [[<span class="kw">AS</span>] <span class="op">&lt;</span>alias<span class="op">&gt;</span>] [, <span class="op">..</span>.]</span>
<span id="cb117-2"><a href="#cb117-2"></a><span class="kw">FROM</span> <span class="op">&lt;</span>ftindex<span class="op">&gt;</span> [, <span class="op">..</span>.]</span>
<span id="cb117-3"><a href="#cb117-3"></a>    [{<span class="kw">USE</span> | IGNORE | <span class="kw">FORCE</span>} <span class="kw">INDEX</span> (<span class="op">&lt;</span>attr_index<span class="op">&gt;</span> [, <span class="op">..</span>.]) [<span class="op">..</span>.]]</span>
<span id="cb117-4"><a href="#cb117-4"></a>[<span class="kw">WHERE</span></span>
<span id="cb117-5"><a href="#cb117-5"></a>    [MATCH(<span class="st">&#39;&lt;text_query&gt;&#39;</span>) [<span class="kw">AND</span>]]</span>
<span id="cb117-6"><a href="#cb117-6"></a>    [<span class="op">&lt;</span>where_condition<span class="op">&gt;</span> [<span class="kw">AND</span> <span class="op">&lt;</span>where_condition<span class="op">&gt;</span> [<span class="op">..</span>.]]]]</span>
<span id="cb117-7"><a href="#cb117-7"></a>[<span class="kw">GROUP</span> [<span class="op">&lt;</span>N<span class="op">&gt;</span>] <span class="kw">BY</span> <span class="op">&lt;</span><span class="kw">column</span><span class="op">&gt;</span> [, <span class="op">..</span>.]</span>
<span id="cb117-8"><a href="#cb117-8"></a>    [WITHIN <span class="kw">GROUP</span> <span class="kw">ORDER</span> <span class="kw">BY</span> <span class="op">&lt;</span><span class="kw">column</span><span class="op">&gt;</span> {<span class="kw">ASC</span> | <span class="kw">DESC</span>} [, <span class="op">..</span>.]]</span>
<span id="cb117-9"><a href="#cb117-9"></a>    [<span class="kw">HAVING</span> <span class="op">&lt;</span>having_condition<span class="op">&gt;</span>]]</span>
<span id="cb117-10"><a href="#cb117-10"></a>[<span class="kw">ORDER</span> <span class="kw">BY</span> <span class="op">&lt;</span><span class="kw">column</span><span class="op">&gt;</span> {<span class="kw">ASC</span> | <span class="kw">DESC</span>} [, <span class="op">..</span>.]]</span>
<span id="cb117-11"><a href="#cb117-11"></a>[<span class="kw">LIMIT</span> [<span class="op">&lt;</span>offset<span class="op">&gt;</span>,] <span class="op">&lt;</span>row_count<span class="op">&gt;</span>]</span>
<span id="cb117-12"><a href="#cb117-12"></a>[<span class="kw">OPTION</span> <span class="op">&lt;</span>opt_name<span class="op">&gt;</span> <span class="op">=</span> <span class="op">&lt;</span>opt_value<span class="op">&gt;</span> [, <span class="op">..</span>.]]</span>
<span id="cb117-13"><a href="#cb117-13"></a>[FACET <span class="op">&lt;</span>facet_options<span class="op">&gt;</span> [<span class="op">..</span>.]]</span></code></pre></div>
<p><code>SELECT</code> is the main querying workhorse, and as such, comes with a rather extensive (and perhaps a little complicated) syntax. There are many different parts (aka clauses) in that syntax. Thankfully, most of them are optional.</p>
<p>Briefly, they are as follows:</p>
<ul>
<li>required <code>SELECT</code> columns list (aka items list, aka expressions list)</li>
<li>required <code>FROM</code> clause, with the full-text index list</li>
<li>optional <code>&lt;hint&gt; INDEX</code> clauses, with the attribute index usage hints</li>
<li>optional <code>WHERE</code> condition clause, with the row filtering conditions</li>
<li>optional <code>GROUP BY</code> clause, with the row grouping conditions</li>
<li>optional <code>ORDER BY</code> clause, with the row sorting conditions</li>
<li>optional <code>LIMIT</code> clause, with the result set size and offset</li>
<li>optional <code>OPTION</code> clause, with all the special options</li>
<li>optional <code>FACET</code> clauses, with a list of requested additional facets</li>
</ul>
<p>The most notable differences from regular SQL are these:</p>
<ul>
<li><code>FROM</code> list is <strong>NOT</strong> an implicit <code>JOIN</code>, but more like a <code>UNION</code></li>
<li><code>ORDER BY</code> is always present, default is <code>ORDER BY WEIGHT() DESC, id ASC</code></li>
<li><code>LIMIT</code> is always present, default is <code>LIMIT 0,20</code></li>
<li><code>GROUP BY</code> always picks a specific “best” row to represent the group</li>
</ul>
<h4 id="index-hints-clause">Index hints clause</h4>
<p>Index hints can be used to tweak query optimizer behavior and attribute index usage, for either performance or debugging reasons. Note that usually you should <em>not</em> have to use them.</p>
<p>Multiple hints can be used, and multiple attribute indexes can be listed, in any order. For example, the following syntax is legal:</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb118-1"><a href="#cb118-1"></a><span class="kw">SELECT</span> <span class="kw">id</span> <span class="kw">FROM</span> test1</span>
<span id="cb118-2"><a href="#cb118-2"></a><span class="kw">USE</span> <span class="kw">INDEX</span> (idx_lat)</span>
<span id="cb118-3"><a href="#cb118-3"></a><span class="kw">FORCE</span> <span class="kw">INDEX</span> (idx_price)</span>
<span id="cb118-4"><a href="#cb118-4"></a>IGNORE <span class="kw">INDEX</span> (idx_time)</span>
<span id="cb118-5"><a href="#cb118-5"></a><span class="kw">USE</span> <span class="kw">INDEX</span> (idx_lon) <span class="op">..</span>.</span></code></pre></div>
<p>All flavors of <code>&lt;hint&gt; INDEX</code> clause take an index list as their argument, for example:</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb119-1"><a href="#cb119-1"></a><span class="op">..</span>. <span class="kw">USE</span> <span class="kw">INDEX</span> (idx_lat, idx_lon, idx_price)</span></code></pre></div>
<p>Summarily, hints work this way:</p>
<ul>
<li><code>USE INDEX</code> limits the optimizer to only use a subset of given indexes;</li>
<li><code>IGNORE INDEX</code> strictly forbids given indexes from being used;</li>
<li><code>FORCE INDEX</code> strictly forces the given indexes to be used.</li>
</ul>
<p><code>USE INDEX</code> tells the optimizer that it must only consider the given indexes, rather than <em>all</em> the applicable ones. In other words, in the absence of the <code>USE</code> clause, all indexes are fair game. In its presence, only those that were mentioned in the <code>USE</code> list are. The optimizer still decides whether to actually to use or ignore any specific index. In the example above it still might choose to use <code>idx_lat</code> only, but it must never use <code>idx_time</code>, on the grounds that it was not mentioned explicitly.</p>
<p><code>IGNORE INDEX</code> completely forbids the optimizer from using the given indexes. Ignores take priority, they override both <code>USE INDEX</code> and <code>FORCE INDEX</code>. Thus, while it is legal to <code>USE INDEX (foo, bar) IGNORE INDEX (bar)</code>, it is way too verbose. Simple <code>USE INDEX (foo)</code> achieves exactly the same result.</p>
<p><code>FORCE INDEX</code> makes the optimizer forcibly use the given indexes (that is, if they are applicable at all) despite the query cost estimates.</p>
<p>For more discussion and details on attributes indexes and hints, refer to <a href="#using-attribute-indexes">“Using attribute indexes”</a>.</p>
<h3 id="show-index-agent-status-syntax">SHOW INDEX AGENT STATUS syntax</h3>
<div class="sourceCode" id="cb120"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb120-1"><a href="#cb120-1"></a>SHOW <span class="kw">INDEX</span> <span class="op">&lt;</span>distindex<span class="op">&gt;</span> <span class="kw">AGENT</span> STATUS [<span class="kw">LIKE</span> <span class="st">&#39;...&#39;</span>]</span></code></pre></div>
<p><code>SHOW INDEX AGENT STATUS</code> lets you examine a number internal per-agent counters associated with every agent (and then every mirror host of an agent) in a given distributed index.</p>
<p>The agents are numbered in the config order. The mirrors within each agent are also numbered in the config order. All timers must internally have microsecond precision, but should be displayed as floats and in milliseconds, for example:</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb121-1"><a href="#cb121-1"></a>mysql<span class="op">&gt;</span> SHOW <span class="kw">INDEX</span> dist1 <span class="kw">AGENT</span> STATUS <span class="kw">LIKE</span> <span class="st">&#39;%que%&#39;</span>;</span>
<span id="cb121-2"><a href="#cb121-2"></a><span class="op">+</span><span class="co">--------------------------------+-------+</span></span>
<span id="cb121-3"><a href="#cb121-3"></a>| Variable_name                  | <span class="fu">Value</span> |</span>
<span id="cb121-4"><a href="#cb121-4"></a><span class="op">+</span><span class="co">--------------------------------+-------+</span></span>
<span id="cb121-5"><a href="#cb121-5"></a>| agent1_host1_query_timeouts    | <span class="dv">0</span>     |</span>
<span id="cb121-6"><a href="#cb121-6"></a>| agent1_host1_succeeded_queries | <span class="dv">1</span>     |</span>
<span id="cb121-7"><a href="#cb121-7"></a>| agent1_host1_total_query_msec  | <span class="fl">2.943</span> |</span>
<span id="cb121-8"><a href="#cb121-8"></a>| agent2_host1_query_timeouts    | <span class="dv">0</span>     |</span>
<span id="cb121-9"><a href="#cb121-9"></a>| agent2_host1_succeeded_queries | <span class="dv">1</span>     |</span>
<span id="cb121-10"><a href="#cb121-10"></a>| agent2_host1_total_query_msec  | <span class="fl">3.586</span> |</span>
<span id="cb121-11"><a href="#cb121-11"></a><span class="op">+</span><span class="co">--------------------------------+-------+</span></span>
<span id="cb121-12"><a href="#cb121-12"></a><span class="dv">6</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>As we can see from the output, there was just 1 query sent to each agent since <code>searchd</code> start, that query went well on both agents, and it took approx 2.9 ms and 3.6 ms respectively. The specific agents are addresses are intentionally not part of this status output to avoid clutter; they can in turn be examined using <code>DESCRIBE</code> statement:</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb122-1"><a href="#cb122-1"></a>mysql<span class="op">&gt;</span> <span class="kw">DESC</span> dist1</span>
<span id="cb122-2"><a href="#cb122-2"></a><span class="op">+</span><span class="co">---------------------+----------+</span></span>
<span id="cb122-3"><a href="#cb122-3"></a>| <span class="kw">Agent</span>               | <span class="kw">Type</span>     |</span>
<span id="cb122-4"><a href="#cb122-4"></a><span class="op">+</span><span class="co">---------------------+----------+</span></span>
<span id="cb122-5"><a href="#cb122-5"></a>| <span class="dv">127</span>.<span class="dv">0</span>.<span class="fl">0.1</span><span class="ch">:7013:loc1</span> | remote_1 |</span>
<span id="cb122-6"><a href="#cb122-6"></a>| <span class="dv">127</span>.<span class="dv">0</span>.<span class="fl">0.1</span><span class="ch">:7015:loc2</span> | remote_2 |</span>
<span id="cb122-7"><a href="#cb122-7"></a><span class="op">+</span><span class="co">---------------------+----------+</span></span>
<span id="cb122-8"><a href="#cb122-8"></a><span class="dv">2</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>In this case (ie. without mirrors) the mapping is straightforward, we can see that we only have two agents, <code>agent1</code> on port 7013 and <code>agent2</code> on port 7015, and we now know what statistics are associated with which agent exactly. Easy.</p>
<h3 id="show-index-from-syntax">SHOW INDEX FROM syntax</h3>
<div class="sourceCode" id="cb123"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb123-1"><a href="#cb123-1"></a>SHOW <span class="kw">INDEX</span> <span class="kw">FROM</span> <span class="op">&lt;</span>ftindex<span class="op">&gt;</span></span></code></pre></div>
<p><code>SHOW INDEX</code> lists all attribute indexes from the given FT index, along with their types, and column names or JSON paths (where applicable). For example:</p>
<pre><code>mysql&gt; SHOW INDEX FROM test;
+------+----------------+----------+-------+-------------+
| No   | IndexName      | AttrName | Type  | Expr        |
+------+----------------+----------+-------+-------------+
| 1    | idx_json       | tag_json | uint  | tag_json[0] |
| 2    | idx_json_float | tag_json | float | tag_json[1] |
+------+----------------+----------+-------+-------------+
2 rows in set (0.00 sec)</code></pre>
<p>Note that just the attribute indexes names for the given FT index can be listed by both <code>SHOW INDEX</code> and <code>DESCRIBE</code> statements:</p>
<pre><code>mysql&gt; DESCRIBE test;
+----------+--------+------------+--------------------------+
| Field    | Type   | Properties | Key                      |
+----------+--------+------------+--------------------------+
| id       | bigint |            |                          |
| title    | field  | indexed    |                          |
| tag_json | json   |            | idx_json, idx_json_float |
+----------+--------+------------+--------------------------+
3 rows in set (0.00 sec)</code></pre>
<p>However, <code>SHOW INDEX</code> also provides additional details, namely the value type, and the exact JSON expression indexed. (As a side note, for “simple” indexes on non-JSON columns, <code>Expr</code> just equals <code>AttrName</code>.)</p>
<h3 id="show-status-syntax">SHOW STATUS syntax</h3>
<div class="sourceCode" id="cb126"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb126-1"><a href="#cb126-1"></a>SHOW [INTERNAL] STATUS [<span class="kw">LIKE</span> <span class="st">&#39;&lt;varmask&gt;&#39;</span>]</span></code></pre></div>
<p><code>SHOW STATUS</code> displays a number of useful server-wide performance and statistics counters. Those are (briefly) documented just below, and should be generally useful for health checks, monitoring, etc.</p>
<p>In <code>SHOW INTERNAL STATUS</code> mode, however, it only displays a few currently experimental internal counters. Those counters might or might not later make it into GA releases, and are intentionally <strong>not</strong> documented here.</p>
<p>All the aggregate counters (ie. total this, average that) are since startup.</p>
<p>Several IO and CPU counters are only available when you start <code>searchd</code> with explicit <code>--iostats</code> and <code>--cpustats</code> accounting switches, respectively. Those are not enabled by default because of a measurable performance impact.</p>
<p>Zeroed out or disabled counters can be intentionally omitted from the output, for brevity. For instance, if the server did not ever see any <code>REPLACE</code> queries via SphinxQL, the respective <code>sql_replace</code> counter will be omitted.</p>
<p><code>LIKE '&lt;varmask&gt;'</code> condition is supported and functional, for instance:</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb127-1"><a href="#cb127-1"></a>mysql<span class="op">&gt;</span> show status <span class="kw">like</span> <span class="st">&#39;local%&#39;</span>;</span>
<span id="cb127-2"><a href="#cb127-2"></a><span class="op">+</span><span class="co">------------------------+---------+</span></span>
<span id="cb127-3"><a href="#cb127-3"></a>| Counter                | <span class="fu">Value</span>   |</span>
<span id="cb127-4"><a href="#cb127-4"></a><span class="op">+</span><span class="co">------------------------+---------+</span></span>
<span id="cb127-5"><a href="#cb127-5"></a>| local_indexes          | <span class="dv">6</span>       |</span>
<span id="cb127-6"><a href="#cb127-6"></a>| local_indexes_disabled | <span class="dv">5</span>       |</span>
<span id="cb127-7"><a href="#cb127-7"></a>| local_docs             | <span class="dv">2866967</span> |</span>
<span id="cb127-8"><a href="#cb127-8"></a>| local_disk_mb          | <span class="fl">2786.2</span>  |</span>
<span id="cb127-9"><a href="#cb127-9"></a>| local_ram_mb           | <span class="fl">1522.0</span>  |</span>
<span id="cb127-10"><a href="#cb127-10"></a><span class="op">+</span><span class="co">------------------------+---------+</span></span>
<span id="cb127-11"><a href="#cb127-11"></a><span class="dv">5</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>Quick counters reference is as follows.</p>
<table>
<colgroup>
<col style="width: 20%" />
<col style="width: 79%" />
</colgroup>
<thead>
<tr class="header">
<th>Counter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>agent_connect</td>
<td>Total remote agent connection attemps</td>
</tr>
<tr class="even">
<td>agent_retry</td>
<td>Total remote agent query retry attempts</td>
</tr>
<tr class="odd">
<td>avg_dist_local</td>
<td>Average time spent querying local indexes in queries to distributed indexes, in seconds</td>
</tr>
<tr class="even">
<td>avg_dist_wait</td>
<td>Average time spent waiting for remote agents in queries to distributed indexes, in seconds</td>
</tr>
<tr class="odd">
<td>avg_dist_wall</td>
<td>Average overall time spent in queries to distributed indexes, in seconds</td>
</tr>
<tr class="even">
<td>avg_query_cpu</td>
<td>Average CPU time spent per query (as reported by OS; requires <code>--cpustats</code>)</td>
</tr>
<tr class="odd">
<td>avg_query_readkb</td>
<td>Average bytes read from disk per query, in KiB (KiB is 1024 bytes; requires <code>--iostats</code>)</td>
</tr>
<tr class="even">
<td>avg_query_reads</td>
<td>Average disk <code>read()</code> calls per query (requires <code>--iostats</code>)</td>
</tr>
<tr class="odd">
<td>avg_query_readtime</td>
<td>Average time per <code>read()</code> call, in seconds (requires <code>--iostats</code>)</td>
</tr>
<tr class="even">
<td>avg_query_wall</td>
<td>Average elapsed query time, in seconds</td>
</tr>
<tr class="odd">
<td>command_XXX</td>
<td>Total number of SphinxAPI “XXX” commands (for example, <code>command_search</code>)</td>
</tr>
<tr class="even">
<td>connections</td>
<td>Total accepted network connections</td>
</tr>
<tr class="odd">
<td>dist_local</td>
<td>Total time spent querying local indexes in queries to distributed indexes, in seconds</td>
</tr>
<tr class="even">
<td>dist_predicted_time</td>
<td>Total predicted query time (in msec) reported by remote agents</td>
</tr>
<tr class="odd">
<td>dist_queries</td>
<td>Total queries to distributed indexes</td>
</tr>
<tr class="even">
<td>dist_wait</td>
<td>Total time spent waiting for remote agents in queries to distributed indexes, in seconds</td>
</tr>
<tr class="odd">
<td>dist_wall</td>
<td>Total time spent in queries to distributed indexes, in seconds</td>
</tr>
<tr class="even">
<td>killed_queries</td>
<td>Total queries that were auto-killed on client network failure</td>
</tr>
<tr class="odd">
<td>local_disk_mb</td>
<td>Total disk use over all enabled local indexes, in MB (MB is 1 million bytes)</td>
</tr>
<tr class="even">
<td>local_docs</td>
<td>Total document count over all enabled local indexes</td>
</tr>
<tr class="odd">
<td>local_indexes</td>
<td>Total enabled local indexes (both plain and RT)</td>
</tr>
<tr class="even">
<td>local_indexes_disabled</td>
<td>Total disabled local indexes</td>
</tr>
<tr class="odd">
<td>local_ram_mb</td>
<td>Total RAM use over all enabled local indexes, in MB (MB is 1 million bytes)</td>
</tr>
<tr class="even">
<td>maxed_out</td>
<td>Total accepted network connections forcibly closed because the server was maxed out</td>
</tr>
<tr class="odd">
<td>predicted_time</td>
<td>Total predicted query time (in msec) report by local searches</td>
</tr>
<tr class="even">
<td>qcache_cached_queries</td>
<td>Current number of queries stored in the query cache</td>
</tr>
<tr class="odd">
<td>qcache_hits</td>
<td>Total number of query cache hits</td>
</tr>
<tr class="even">
<td>qcache_used_bytes</td>
<td>Current query cache storage size, in bytes</td>
</tr>
<tr class="odd">
<td>queries</td>
<td>Total number of search queries served (either via SphinxAPI or SphinxQL)</td>
</tr>
<tr class="even">
<td>query_cpu</td>
<td>Total CPU time spent on search queries, in seconds (as reported by OS; requires <code>--cpustats</code>)</td>
</tr>
<tr class="odd">
<td>query_readkb</td>
<td>Total bytes read from disk by queries, in KiB (KiB is 1024 bytes; requires <code>--iostats</code>)</td>
</tr>
<tr class="even">
<td>query_reads</td>
<td>Total disk <code>read()</code> calls by queries (requires <code>--iostats</code>)</td>
</tr>
<tr class="odd">
<td>query_readtime</td>
<td>Total time spend in <code>read()</code> call by queries, in seconds (requires <code>--iostats</code>)</td>
</tr>
<tr class="even">
<td>query_wall</td>
<td>Total elapsed search queries time, in seconds</td>
</tr>
<tr class="odd">
<td>siege_sec_left</td>
<td>Current time left until “siege mode” auto-expires, in seconds</td>
</tr>
<tr class="even">
<td>sql_XXX</td>
<td>Total number of SphinxQL “XXX” statements (for example, <code>sql_select</code>)</td>
</tr>
<tr class="odd">
<td>uptime</td>
<td>Uptime, in seconds</td>
</tr>
<tr class="even">
<td>work_queue_length</td>
<td>Current thread pool work queue length (ie. number of jobs waiting for workers)</td>
</tr>
<tr class="odd">
<td>workers_active</td>
<td>Current number of active thread pool workers</td>
</tr>
<tr class="even">
<td>workers_total</td>
<td>Total thread pool workers count</td>
</tr>
</tbody>
</table>
<p>Last but not least, here goes some example output, taken from v.3.4. Beware, it’s a bit longish.</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb128-1"><a href="#cb128-1"></a>mysql<span class="op">&gt;</span> SHOW STATUS;</span>
<span id="cb128-2"><a href="#cb128-2"></a><span class="op">+</span><span class="co">------------------------+---------+</span></span>
<span id="cb128-3"><a href="#cb128-3"></a>| Counter                | <span class="fu">Value</span>   |</span>
<span id="cb128-4"><a href="#cb128-4"></a><span class="op">+</span><span class="co">------------------------+---------+</span></span>
<span id="cb128-5"><a href="#cb128-5"></a>| uptime                 | <span class="dv">25</span>      |</span>
<span id="cb128-6"><a href="#cb128-6"></a>| connections            | <span class="dv">1</span>       |</span>
<span id="cb128-7"><a href="#cb128-7"></a>| maxed_out              | <span class="dv">0</span>       |</span>
<span id="cb128-8"><a href="#cb128-8"></a>| command_search         | <span class="dv">0</span>       |</span>
<span id="cb128-9"><a href="#cb128-9"></a>| command_snippet        | <span class="dv">0</span>       |</span>
<span id="cb128-10"><a href="#cb128-10"></a>| command_update         | <span class="dv">0</span>       |</span>
<span id="cb128-11"><a href="#cb128-11"></a>| command_delete         | <span class="dv">0</span>       |</span>
<span id="cb128-12"><a href="#cb128-12"></a>| command_keywords       | <span class="dv">0</span>       |</span>
<span id="cb128-13"><a href="#cb128-13"></a>| command_persist        | <span class="dv">0</span>       |</span>
<span id="cb128-14"><a href="#cb128-14"></a>| command_status         | <span class="dv">3</span>       |</span>
<span id="cb128-15"><a href="#cb128-15"></a>| command_flushattrs     | <span class="dv">0</span>       |</span>
<span id="cb128-16"><a href="#cb128-16"></a>| agent_connect          | <span class="dv">0</span>       |</span>
<span id="cb128-17"><a href="#cb128-17"></a>| agent_retry            | <span class="dv">0</span>       |</span>
<span id="cb128-18"><a href="#cb128-18"></a>| queries                | <span class="dv">0</span>       |</span>
<span id="cb128-19"><a href="#cb128-19"></a>| dist_queries           | <span class="dv">0</span>       |</span>
<span id="cb128-20"><a href="#cb128-20"></a>| killed_queries         | <span class="dv">0</span>       |</span>
<span id="cb128-21"><a href="#cb128-21"></a>| workers_total          | <span class="dv">20</span>      |</span>
<span id="cb128-22"><a href="#cb128-22"></a>| workers_active         | <span class="dv">1</span>       |</span>
<span id="cb128-23"><a href="#cb128-23"></a>| work_queue_length      | <span class="dv">0</span>       |</span>
<span id="cb128-24"><a href="#cb128-24"></a>| query_wall             | <span class="fl">0.000</span>   |</span>
<span id="cb128-25"><a href="#cb128-25"></a>| query_cpu              | <span class="kw">OFF</span>     |</span>
<span id="cb128-26"><a href="#cb128-26"></a>| dist_wall              | <span class="fl">0.000</span>   |</span>
<span id="cb128-27"><a href="#cb128-27"></a>| dist_local             | <span class="fl">0.000</span>   |</span>
<span id="cb128-28"><a href="#cb128-28"></a>| dist_wait              | <span class="fl">0.000</span>   |</span>
<span id="cb128-29"><a href="#cb128-29"></a>| query_reads            | <span class="kw">OFF</span>     |</span>
<span id="cb128-30"><a href="#cb128-30"></a>| query_readkb           | <span class="kw">OFF</span>     |</span>
<span id="cb128-31"><a href="#cb128-31"></a>| query_readtime         | <span class="kw">OFF</span>     |</span>
<span id="cb128-32"><a href="#cb128-32"></a>| avg_query_wall         | <span class="fl">0.000</span>   |</span>
<span id="cb128-33"><a href="#cb128-33"></a>| avg_query_cpu          | <span class="kw">OFF</span>     |</span>
<span id="cb128-34"><a href="#cb128-34"></a>| avg_dist_wall          | <span class="fl">0.000</span>   |</span>
<span id="cb128-35"><a href="#cb128-35"></a>| avg_dist_local         | <span class="fl">0.000</span>   |</span>
<span id="cb128-36"><a href="#cb128-36"></a>| avg_dist_wait          | <span class="fl">0.000</span>   |</span>
<span id="cb128-37"><a href="#cb128-37"></a>| avg_query_reads        | <span class="kw">OFF</span>     |</span>
<span id="cb128-38"><a href="#cb128-38"></a>| avg_query_readkb       | <span class="kw">OFF</span>     |</span>
<span id="cb128-39"><a href="#cb128-39"></a>| avg_query_readtime     | <span class="kw">OFF</span>     |</span>
<span id="cb128-40"><a href="#cb128-40"></a>| qcache_cached_queries  | <span class="dv">0</span>       |</span>
<span id="cb128-41"><a href="#cb128-41"></a>| qcache_used_bytes      | <span class="dv">0</span>       |</span>
<span id="cb128-42"><a href="#cb128-42"></a>| qcache_hits            | <span class="dv">0</span>       |</span>
<span id="cb128-43"><a href="#cb128-43"></a>| sql_parse_error        | <span class="dv">1</span>       |</span>
<span id="cb128-44"><a href="#cb128-44"></a>| sql_show_status        | <span class="dv">3</span>       |</span>
<span id="cb128-45"><a href="#cb128-45"></a>| local_indexes          | <span class="dv">6</span>       |</span>
<span id="cb128-46"><a href="#cb128-46"></a>| local_indexes_disabled | <span class="dv">5</span>       |</span>
<span id="cb128-47"><a href="#cb128-47"></a>| local_docs             | <span class="dv">2866967</span> |</span>
<span id="cb128-48"><a href="#cb128-48"></a>| local_disk_mb          | <span class="fl">2786.2</span>  |</span>
<span id="cb128-49"><a href="#cb128-49"></a>| local_ram_mb           | <span class="fl">1522.0</span>  |</span>
<span id="cb128-50"><a href="#cb128-50"></a><span class="op">+</span><span class="co">------------------------+---------+</span></span>
<span id="cb128-51"><a href="#cb128-51"></a><span class="dv">44</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<h3 id="show-variables-syntax">SHOW VARIABLES syntax</h3>
<div class="sourceCode" id="cb129"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb129-1"><a href="#cb129-1"></a>SHOW [{<span class="kw">GLOBAL</span> | <span class="kw">SESSION</span>}] VARIABLES</span>
<span id="cb129-2"><a href="#cb129-2"></a>    [{<span class="kw">WHERE</span> variable_name<span class="op">=</span><span class="st">&#39;&lt;varname&gt;&#39;</span> [<span class="kw">OR</span> <span class="op">..</span>.] |</span>
<span id="cb129-3"><a href="#cb129-3"></a>    <span class="kw">LIKE</span> <span class="st">&#39;&lt;varmask&gt;&#39;</span>}]</span></code></pre></div>
<p><code>SHOW VARIABLES</code> statement serves two very different purposes:</p>
<ul>
<li>to provide compatibility with 3rd party MySQL clients;</li>
<li>to examine the current status of <code>searchd</code> server variables.</li>
</ul>
<p>Compatibility mode is required to support connections from certain MySQL clients that automatically run <code>SHOW VARIABLES</code> on connection and fail if that statement raises an error.</p>
<p>Optional <code>GLOBAL</code> or <code>SESSION</code> scope condition is for compatibility only at the moment, and the scope is ignored. All variables, both global and per-session, are always displayed.</p>
<p><code>WHERE variable_name ...</code> condition is also for compatibility only, and also ignored.</p>
<p><code>LIKE '&lt;varmask&gt;'</code> condition is supported and functional, for instance:</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb130-1"><a href="#cb130-1"></a>mysql<span class="op">&gt;</span> show variables <span class="kw">like</span> <span class="st">&#39;%comm%&#39;</span>;</span>
<span id="cb130-2"><a href="#cb130-2"></a><span class="op">+</span><span class="co">---------------+-------+</span></span>
<span id="cb130-3"><a href="#cb130-3"></a>| Variable_name | <span class="fu">Value</span> |</span>
<span id="cb130-4"><a href="#cb130-4"></a><span class="op">+</span><span class="co">---------------+-------+</span></span>
<span id="cb130-5"><a href="#cb130-5"></a>| autocommit    | <span class="dv">1</span>     |</span>
<span id="cb130-6"><a href="#cb130-6"></a><span class="op">+</span><span class="co">---------------+-------+</span></span>
<span id="cb130-7"><a href="#cb130-7"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<p>Some of the variables displayed in <code>SHOW VARIABLES</code> are <em>mutable</em>, and can be changed on the fly using the <code>SET GLOBAL</code> statement. For example, you can tweak <code>log_level</code> or <code>sql_log_file</code> on the fly.</p>
<p>Some are <em>read-only</em> though, that is, they can be changed, but only by editing the config file and restarting the daemon. For example, <code>max_allowed_packet</code> and <code>listen</code> are read-only. You can only change them in <code>sphinx.conf</code> and restart.</p>
<p>And finally, some of the variiables are <em>constant</em>, compiled into the binary and never changed, such as <code>version</code> and a few more informational variables.</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb131-1"><a href="#cb131-1"></a>mysql<span class="op">&gt;</span> show variables;</span>
<span id="cb131-2"><a href="#cb131-2"></a><span class="op">+</span><span class="co">------------------------------+-------------------------------------+</span></span>
<span id="cb131-3"><a href="#cb131-3"></a>| Variable_name                | <span class="fu">Value</span>                               |</span>
<span id="cb131-4"><a href="#cb131-4"></a><span class="op">+</span><span class="co">------------------------------+-------------------------------------+</span></span>
<span id="cb131-5"><a href="#cb131-5"></a>| agent_connect_timeout        | <span class="dv">1000</span>                                |</span>
<span id="cb131-6"><a href="#cb131-6"></a>| agent_query_timeout          | <span class="dv">3000</span>                                |</span>
<span id="cb131-7"><a href="#cb131-7"></a>| agent_retry_delay            | <span class="dv">500</span>                                 |</span>
<span id="cb131-8"><a href="#cb131-8"></a>| attrindex_thresh             | <span class="dv">1024</span>                                |</span>
<span id="cb131-9"><a href="#cb131-9"></a>| autocommit                   | <span class="dv">1</span>                                   |</span>
<span id="cb131-10"><a href="#cb131-10"></a>| binlog_flush_mode            | <span class="dv">2</span>                                   |</span>
<span id="cb131-11"><a href="#cb131-11"></a>| binlog_max_log_size          | <span class="dv">0</span>                                   |</span>
<span id="cb131-12"><a href="#cb131-12"></a>| binlog_path                  |                                     |</span>
<span id="cb131-13"><a href="#cb131-13"></a>| character_set_client         | utf8                                |</span>
<span id="cb131-14"><a href="#cb131-14"></a>| character_set_connection     | utf8                                |</span>
<span id="cb131-15"><a href="#cb131-15"></a>| client_timeout               | <span class="dv">300</span>                                 |</span>
<span id="cb131-16"><a href="#cb131-16"></a>| collation_connection         | libc_ci                             |</span>
<span id="cb131-17"><a href="#cb131-17"></a>| collation_libc_locale        |                                     |</span>
<span id="cb131-18"><a href="#cb131-18"></a>| dist_threads                 | <span class="dv">0</span>                                   |</span>
<span id="cb131-19"><a href="#cb131-19"></a>| docstore_cache_size          | <span class="dv">10485760</span>                            |</span>
<span id="cb131-20"><a href="#cb131-20"></a>| expansion_limit              | <span class="dv">0</span>                                   |</span>
<span id="cb131-21"><a href="#cb131-21"></a>| ha_period_karma              | <span class="dv">60</span>                                  |</span>
<span id="cb131-22"><a href="#cb131-22"></a>| ha_ping_interval             | <span class="dv">1000</span>                                |</span>
<span id="cb131-23"><a href="#cb131-23"></a>| hostname_lookup              | <span class="dv">0</span>                                   |</span>
<span id="cb131-24"><a href="#cb131-24"></a>| listen                       | <span class="dv">9380</span><span class="ch">:http</span>                           |</span>
<span id="cb131-25"><a href="#cb131-25"></a>| listen                       | <span class="dv">9306</span><span class="ch">:mysql41</span>                        |</span>
<span id="cb131-26"><a href="#cb131-26"></a>| listen                       | <span class="dv">9312</span>                                |</span>
<span id="cb131-27"><a href="#cb131-27"></a>| listen_backlog               | <span class="dv">64</span>                                  |</span>
<span id="cb131-28"><a href="#cb131-28"></a>| <span class="fu">log</span>                          | .<span class="op">/</span><span class="kw">data</span><span class="op">/</span>searchd.<span class="fu">log</span>                  |</span>
<span id="cb131-29"><a href="#cb131-29"></a>| log_debug_filter             |                                     |</span>
<span id="cb131-30"><a href="#cb131-30"></a>| log_level                    | info                                |</span>
<span id="cb131-31"><a href="#cb131-31"></a>| max_allowed_packet           | <span class="dv">8388608</span>                             |</span>
<span id="cb131-32"><a href="#cb131-32"></a>| max_batch_queries            | <span class="dv">32</span>                                  |</span>
<span id="cb131-33"><a href="#cb131-33"></a>| max_children                 | <span class="dv">20</span>                                  |</span>
<span id="cb131-34"><a href="#cb131-34"></a>| max_filter_values            | <span class="dv">4096</span>                                |</span>
<span id="cb131-35"><a href="#cb131-35"></a>| max_filters                  | <span class="dv">256</span>                                 |</span>
<span id="cb131-36"><a href="#cb131-36"></a>| my_net_address               |                                     |</span>
<span id="cb131-37"><a href="#cb131-37"></a>| mysql_version_string         | <span class="dv">3</span>.<span class="fl">4.1</span><span class="op">-</span>dev (<span class="kw">commit</span> 6d01467e1)        |</span>
<span id="cb131-38"><a href="#cb131-38"></a>| net_spin_msec                | <span class="dv">10</span>                                  |</span>
<span id="cb131-39"><a href="#cb131-39"></a>| net_throttle_accept          | <span class="dv">0</span>                                   |</span>
<span id="cb131-40"><a href="#cb131-40"></a>| net_throttle_action          | <span class="dv">0</span>                                   |</span>
<span id="cb131-41"><a href="#cb131-41"></a>| net_workers                  | <span class="dv">1</span>                                   |</span>
<span id="cb131-42"><a href="#cb131-42"></a>| ondisk_attrs_default         | <span class="dv">0</span>                                   |</span>
<span id="cb131-43"><a href="#cb131-43"></a>| persistent_connections_limit | <span class="dv">0</span>                                   |</span>
<span id="cb131-44"><a href="#cb131-44"></a>| pid_file                     |                                     |</span>
<span id="cb131-45"><a href="#cb131-45"></a>| plugin_dir                   |                                     |</span>
<span id="cb131-46"><a href="#cb131-46"></a>| predicted_time_costs         | doc<span class="op">=</span><span class="dv">64</span>, hit<span class="op">=</span><span class="dv">48</span>, <span class="kw">skip</span><span class="op">=</span><span class="dv">2048</span>, match<span class="op">=</span><span class="dv">64</span> |</span>
<span id="cb131-47"><a href="#cb131-47"></a>| preopen_indexes              | <span class="dv">0</span>                                   |</span>
<span id="cb131-48"><a href="#cb131-48"></a>| qcache_max_bytes             | <span class="dv">0</span>                                   |</span>
<span id="cb131-49"><a href="#cb131-49"></a>| qcache_thresh_msec           | <span class="dv">3000</span>                                |</span>
<span id="cb131-50"><a href="#cb131-50"></a>| qcache_ttl_sec               | <span class="dv">60</span>                                  |</span>
<span id="cb131-51"><a href="#cb131-51"></a>| query_log                    | .<span class="op">/</span><span class="kw">data</span><span class="op">/</span><span class="kw">query</span>.<span class="fu">log</span>                    |</span>
<span id="cb131-52"><a href="#cb131-52"></a>| query_log_format             | sphinxql                            |</span>
<span id="cb131-53"><a href="#cb131-53"></a>| query_log_min_msec           | <span class="dv">0</span>                                   |</span>
<span id="cb131-54"><a href="#cb131-54"></a>| queue_max_length             | <span class="dv">0</span>                                   |</span>
<span id="cb131-55"><a href="#cb131-55"></a>| read_buffer                  | <span class="dv">0</span>                                   |</span>
<span id="cb131-56"><a href="#cb131-56"></a>| read_timeout                 | <span class="dv">5</span>                                   |</span>
<span id="cb131-57"><a href="#cb131-57"></a>| read_unhinted                | <span class="dv">0</span>                                   |</span>
<span id="cb131-58"><a href="#cb131-58"></a>| rt_flush_period              | <span class="dv">36000</span>                               |</span>
<span id="cb131-59"><a href="#cb131-59"></a>| rt_merge_iops                | <span class="dv">0</span>                                   |</span>
<span id="cb131-60"><a href="#cb131-60"></a>| rt_merge_maxiosize           | <span class="dv">0</span>                                   |</span>
<span id="cb131-61"><a href="#cb131-61"></a>| seamless_rotate              | <span class="dv">0</span>                                   |</span>
<span id="cb131-62"><a href="#cb131-62"></a>| shutdown_timeout             | <span class="dv">3000000</span>                             |</span>
<span id="cb131-63"><a href="#cb131-63"></a>| siege                        | <span class="dv">0</span>                                   |</span>
<span id="cb131-64"><a href="#cb131-64"></a>| siege_max_fetched_docs       | <span class="dv">1000000</span>                             |</span>
<span id="cb131-65"><a href="#cb131-65"></a>| siege_max_query_msec         | <span class="dv">1000</span>                                |</span>
<span id="cb131-66"><a href="#cb131-66"></a>| snippets_file_prefix         |                                     |</span>
<span id="cb131-67"><a href="#cb131-67"></a>| sphinxql_state               | state.sql                           |</span>
<span id="cb131-68"><a href="#cb131-68"></a>| sphinxql_timeout             | <span class="dv">900</span>                                 |</span>
<span id="cb131-69"><a href="#cb131-69"></a>| sql_fail_filter              |                                     |</span>
<span id="cb131-70"><a href="#cb131-70"></a>| sql_log_file                 |                                     |</span>
<span id="cb131-71"><a href="#cb131-71"></a>| thread_stack                 | <span class="dv">131072</span>                              |</span>
<span id="cb131-72"><a href="#cb131-72"></a>| unlink_old                   | <span class="dv">1</span>                                   |</span>
<span id="cb131-73"><a href="#cb131-73"></a>| version                      | <span class="dv">3</span>.<span class="fl">4.1</span><span class="op">-</span>dev (<span class="kw">commit</span> 6d01467e1)        |</span>
<span id="cb131-74"><a href="#cb131-74"></a>| version_api_master           | <span class="dv">23</span>                                  |</span>
<span id="cb131-75"><a href="#cb131-75"></a>| version_api_search           | <span class="fl">1.34</span>                                |</span>
<span id="cb131-76"><a href="#cb131-76"></a>| version_binlog_format        | <span class="dv">8</span>                                   |</span>
<span id="cb131-77"><a href="#cb131-77"></a>| version_index_format         | <span class="dv">55</span>                                  |</span>
<span id="cb131-78"><a href="#cb131-78"></a>| version_udf_api              | <span class="dv">17</span>                                  |</span>
<span id="cb131-79"><a href="#cb131-79"></a>| watchdog                     | <span class="dv">1</span>                                   |</span>
<span id="cb131-80"><a href="#cb131-80"></a>| workers                      | <span class="dv">1</span>                                   |</span>
<span id="cb131-81"><a href="#cb131-81"></a><span class="op">+</span><span class="co">------------------------------+-------------------------------------+</span></span></code></pre></div>
<p>Specific per-variable documentation can be found in the <a href="#server-variables-reference">“Server variables reference”</a> section.</p>
<h2 id="functions-reference">Functions reference</h2>
<p>This section should eventually contain the complete reference on functions that are supported in <code>SELECT</code> and other applicable places. If the function you’re looking for is not yet documented here, please refer to legacy <a href="sphinx2.html#expressions">Sphinx v.2.x expressions reference</a> document.</p>
<p>Here’s a complete list of builtin Sphinx functions.</p>
<ul>
<li><a href="sphinx2.html#expr-func-abs">ABS</a></li>
<li><a href="sphinx2.html#expr-func-all">ALL</a></li>
<li><a href="sphinx2.html#expr-func-any">ANY</a></li>
<li><a href="sphinx2.html#expr-func-atan2">ATAN2</a></li>
<li><a href="sphinx2.html#expr-func-bigint">BIGINT</a></li>
<li><a href="sphinx2.html#expr-func-bitcount">BITCOUNT</a></li>
<li><a href="sphinx2.html#expr-func-bitdot">BITDOT</a></li>
<li><a href="sphinx2.html#expr-func-bm25f">BM25F</a></li>
<li><a href="sphinx2.html#expr-func-ceil">CEIL</a></li>
<li><a href="#coalesce-function">COALESCE</a></li>
<li><a href="sphinx2.html#expr-func-connection-id">CONNECTION_ID</a></li>
<li><a href="sphinx2.html#expr-func-contains">CONTAINS</a></li>
<li><a href="sphinx2.html#expr-func-cos">COS</a></li>
<li><a href="sphinx2.html#expr-func-crc32">CRC32</a></li>
<li><a href="sphinx2.html#expr-func-current-user">CURRENT_USER</a></li>
<li><a href="sphinx2.html#expr-func-curtime">CURTIME</a></li>
<li><a href="sphinx2.html#expr-func-day">DAY</a></li>
<li><a href="sphinx2.html#expr-func-document">DOCUMENT</a></li>
<li><a href="#dot-function">DOT</a></li>
<li><a href="sphinx2.html#expr-func-double">DOUBLE</a></li>
<li><a href="sphinx2.html#expr-func-exist">EXIST</a></li>
<li><a href="sphinx2.html#expr-func-exp">EXP</a></li>
<li><a href="sphinx2.html#expr-func-factors">FACTORS</a></li>
<li><a href="sphinx2.html#expr-func-fibonacci">FIBONACCI</a></li>
<li><a href="sphinx2.html#expr-func-floor">FLOOR</a></li>
<li><a href="#fvec-function">FVEC</a></li>
<li><a href="sphinx2.html#expr-func-geodist">GEODIST</a></li>
<li><a href="sphinx2.html#expr-func-geopoly2d">GEOPOLY2D</a></li>
<li><a href="sphinx2.html#expr-func-greatest">GREATEST</a></li>
<li><a href="sphinx2.html#expr-func-hour">HOUR</a></li>
<li><a href="sphinx2.html#expr-func-idiv">IDIV</a></li>
<li><a href="sphinx2.html#expr-func-if">IF</a></li>
<li><a href="sphinx2.html#expr-func-in">IN</a></li>
<li><a href="sphinx2.html#expr-func-indexof">INDEXOF</a></li>
<li><a href="sphinx2.html#expr-func-interval">INTERVAL</a></li>
<li><a href="sphinx2.html#expr-func-least">LEAST</a></li>
<li><a href="sphinx2.html#expr-func-length">LENGTH</a></li>
<li><a href="sphinx2.html#expr-func-ln">LN</a></li>
<li><a href="sphinx2.html#expr-func-log10">LOG10</a></li>
<li><a href="sphinx2.html#expr-func-log2">LOG2</a></li>
<li><a href="sphinx2.html#expr-func-madd">MADD</a></li>
<li><a href="sphinx2.html#expr-func-max">MAX</a></li>
<li><a href="sphinx2.html#expr-func-min">MIN</a></li>
<li><a href="sphinx2.html#expr-func-min-top-sortval">MIN_TOP_SORTVAL</a></li>
<li><a href="sphinx2.html#expr-func-min-top-weight">MIN_TOP_WEIGHT</a></li>
<li><a href="sphinx2.html#expr-func-minute">MINUTE</a></li>
<li><a href="sphinx2.html#expr-func-month">MONTH</a></li>
<li><a href="sphinx2.html#expr-func-mul3">MUL3</a></li>
<li><a href="sphinx2.html#expr-func-now">NOW</a></li>
<li><a href="sphinx2.html#expr-func-packedfactors">PACKEDFACTORS</a></li>
<li><a href="sphinx2.html#expr-func-poly2d">POLY2D</a></li>
<li><a href="sphinx2.html#expr-func-pow">POW</a></li>
<li><a href="#pp-function">PP</a></li>
<li><a href="sphinx2.html#expr-func-query">QUERY</a></li>
<li><a href="sphinx2.html#expr-func-rand">RAND</a></li>
<li><a href="sphinx2.html#expr-func-rankfactors">RANKFACTORS</a></li>
<li><a href="sphinx2.html#expr-func-remap">REMAP</a></li>
<li><a href="sphinx2.html#expr-func-second">SECOND</a></li>
<li><a href="sphinx2.html#expr-func-sin">SIN</a></li>
<li><a href="sphinx2.html#expr-func-sint">SINT</a></li>
<li><a href="#slice-functions">SLICEAVG</a></li>
<li><a href="#slice-functions">SLICEMAX</a></li>
<li><a href="#slice-functions">SLICEMIN</a></li>
<li><a href="sphinx2.html#expr-func-sqrt">SQRT</a></li>
<li><a href="#strpos-function">STRPOS</a></li>
<li><a href="sphinx2.html#expr-func-timediff">TIMEDIFF</a></li>
<li><a href="sphinx2.html#expr-func-to-string">TO_STRING</a></li>
<li><a href="#uint-function">UINT</a></li>
<li><a href="sphinx2.html#expr-func-utc-time">UTC_TIME</a></li>
<li><a href="sphinx2.html#expr-func-utc-timestamp">UTC_TIMESTAMP</a></li>
<li><a href="sphinx2.html#expr-func-year">YEAR</a></li>
<li><a href="sphinx2.html#expr-func-yearmonth">YEARMONTH</a></li>
<li><a href="sphinx2.html#expr-func-yearmonthday">YEARMONTHDAY</a></li>
<li><a href="sphinx2.html#expr-func-zonespanlist">ZONESPANLIST</a></li>
</ul>
<h3 id="coalesce-function"><code>COALESCE()</code> function</h3>
<div class="sourceCode" id="cb132"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb132-1"><a href="#cb132-1"></a><span class="fu">COALESCE</span>(json.<span class="kw">key</span>, numeric_expr)</span></code></pre></div>
<p><code>COALESCE()</code> function returns either the first argument if it is not <code>NULL</code>, or the second argument otherwise.</p>
<p>As pretty much everything except JSON is not nullable in Sphinx, the first argument must be a JSON key.</p>
<p>The second argument is currently limited to numeric types. Moreover, at the moment <code>COALESCE()</code> always returns <code>float</code> typed result, thus forcibly casting whatever argument it returns to float. Beware that this looses precision when returning bigger integer values from either argument!</p>
<p>The second argument does <em>not</em> need to be a constant. An arbitrary expression is allowed.</p>
<p>Examples:</p>
<pre><code>mysql&gt; select coalesce(j.existing, 123) val
    -&gt; from test1 where id=1;
+-----------+
| val       |
+-----------+
| 1107024.0 |
+-----------+
1 row in set (0.00 sec)

mysql&gt; select coalesce(j.missing, 123) val
    -&gt; from test1 where id=1;
+-------+
| val   |
+-------+
| 123.0 |
+-------+
1 row in set (0.00 sec)

mysql&gt; select coalesce(j.missing, 16777217) val
    -&gt; from test1 where id=1;
+------------+
| val        |
+------------+
| 16777216.0 |
+------------+
1 row in set (0.00 sec)

mysql&gt; select coalesce(j.missing, sin(id)+3) val from lj where id=1;
+------------+
| val        |
+------------+
| 3.84147096 |
+------------+
1 row in set (0.00 sec)</code></pre>
<h3 id="dot-function"><code>DOT()</code> function</h3>
<div class="sourceCode" id="cb134"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb134-1"><a href="#cb134-1"></a>DOT(vector1, vector2)</span>
<span id="cb134-2"><a href="#cb134-2"></a>vector <span class="op">=</span> {json.<span class="kw">key</span> | array_attr | FVEC(<span class="op">..</span>.)}</span></code></pre></div>
<p><code>DOT()</code> function computes a dot product over two vector arguments.</p>
<p>Vectors can be taken either from JSON, or from array attributes, or specified as constants using <code>FVEC()</code> function. All combinations should generally work.</p>
<p>The result type is always <code>FLOAT</code> for consistency and simplicity. (According to our benchmarks, performance gain from using <code>UINT</code> or <code>BIGINT</code> for the result type, where applicable, is pretty much nonexistent anyway.)</p>
<p>Note that <em>internal</em> calculations are optimized for specific input argument types anyway. For instance, <code>int8</code> vs <code>int8</code> vectors should be quite noticeably faster than <code>float</code> by <code>double</code> vectors containing the same data, both because integer multiplication is less expensive, and because <code>int8</code> would utilize 6x less memory.</p>
<p>So as a rule of thumb, use the narrowest possible type, that yields both better RAM use and better performance.</p>
<p>When one of the arguments is either NULL, or not a numeric vector (that can very well happen with JSON), or when both arguments are vectors of different sizes, <code>DOT()</code> returns 0.</p>
<h3 id="fvec-function"><code>FVEC()</code> function</h3>
<div class="sourceCode" id="cb135"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb135-1"><a href="#cb135-1"></a>FVEC(const1 [, const2, <span class="op">..</span>.])</span>
<span id="cb135-2"><a href="#cb135-2"></a>FVEC(json.<span class="kw">key</span>)</span></code></pre></div>
<p><code>FVEC()</code> function lets you define a vector of floats. Two current usecases are:</p>
<ul>
<li>to define a constant vector for subsequent use with <a href="#dot-function"><code>DOT()</code></a></li>
<li>to pass optimized float vectors stored in JSON to UDFs</li>
</ul>
<p><strong>Constant vector form.</strong></p>
<p>In the first form, the arguments are a list of numeric constants. And note that there <em>can</em> be a difference whether we use integers or floats here!</p>
<p>When both arguments to <code>DOT()</code> are integer vectors, <code>DOT()</code> can use an optimized integer implementation, and to define such a vector using <code>FVEC()</code>, you should only use integers.</p>
<p>The rule of thumb with vectors generally is: just use the narrowest possible type. Because that way, extra optimizations just might kick in. And the other way, they very definitely will not.</p>
<p>For instance, the optimizer is allowed to widen <code>FVEC(1,2,3,4)</code> from integers to floats alright, no surprise there. Now, in <em>this</em> case it is also allowed to narrow the resulting <code>float</code> vector back to integers where applicable, because we can know that all the <em>original</em> values were integers before widening.</p>
<p>And narrowing down from the floating point form like <code>FVEC(1.0, 2.0, 3.0, 4.0)</code> to integers is strictly prohibited. So even though the values actually are the same, in the first case additional integer-only optimization can be engaged, and in the second case they can’t.</p>
<p><strong>UDF argument wrapper form.</strong></p>
<p>In the second form, the only argument must be a JSON key, and the output is only intended for UDF functions (because otherwise this <code>FVEC()</code> wrapper should not be needed and you would just use the key itself). The associated value type gets checked, optimized float vectors get wrapped and passed to UDF, and any other types are replaced with a null vector (zero length and no data pointer) in the UDF call. The respective UDF type is <code>SPH_UDF_TYPE_FLOAT_VEC</code>.</p>
<p>Note that this case is intentionally designed as a fast accessor for UDFs that just passes <code>float</code> vectors to them, and avoids any data copying and conversion.</p>
<p>So if you attempt to wrap and pass anything else, null vector will be passed to the UDF. Could be a generic mixed vector with numeric values of differnt types, could be an optimized <code>int8</code> vector, could be a <code>double</code> vector - but in all these cases, despite the fact that they are compatible and <em>could</em> technically be converted to some temporary <code>float</code> vector and then passed down, that kind of a conversion just does not happen. Intentionally, for performance reasons.</p>
<h3 id="pp-function"><code>PP()</code> function</h3>
<div class="sourceCode" id="cb136"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb136-1"><a href="#cb136-1"></a>PP(FACTORS())</span>
<span id="cb136-2"><a href="#cb136-2"></a>PP(json.<span class="kw">key</span>)</span></code></pre></div>
<p><code>PP()</code> function pretty-prints JSON output (which by default would be compact rather than prettified). It can be used either with JSON columns (and fields), or with <code>FACTORS()</code> function. For example:</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb137-1"><a href="#cb137-1"></a>mysql<span class="op">&gt;</span> <span class="kw">select</span> <span class="kw">id</span>, j <span class="kw">from</span> lj <span class="kw">limit</span> <span class="dv">1</span> \G</span>
<span id="cb137-2"><a href="#cb137-2"></a><span class="op">***************************</span> <span class="fl">1.</span> <span class="kw">row</span> <span class="op">***************************</span></span>
<span id="cb137-3"><a href="#cb137-3"></a><span class="kw">id</span>: <span class="dv">1</span></span>
<span id="cb137-4"><a href="#cb137-4"></a> j: {<span class="ot">&quot;gid&quot;</span><span class="ch">:1107024</span>, <span class="ot">&quot;urlcrc&quot;</span><span class="ch">:2557061282</span>}</span>
<span id="cb137-5"><a href="#cb137-5"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.01</span> sec)</span>
<span id="cb137-6"><a href="#cb137-6"></a></span>
<span id="cb137-7"><a href="#cb137-7"></a>mysql<span class="op">&gt;</span> <span class="kw">select</span> <span class="kw">id</span>, pp(j) <span class="kw">from</span> lj <span class="kw">limit</span> <span class="dv">1</span> \G</span>
<span id="cb137-8"><a href="#cb137-8"></a><span class="op">***************************</span> <span class="fl">1.</span> <span class="kw">row</span> <span class="op">***************************</span></span>
<span id="cb137-9"><a href="#cb137-9"></a>   <span class="kw">id</span>: <span class="dv">1</span></span>
<span id="cb137-10"><a href="#cb137-10"></a>pp(j): {</span>
<span id="cb137-11"><a href="#cb137-11"></a>  <span class="ot">&quot;gid&quot;</span>: <span class="dv">1107024</span>,</span>
<span id="cb137-12"><a href="#cb137-12"></a>  <span class="ot">&quot;urlcrc&quot;</span>: <span class="dv">2557061282</span></span>
<span id="cb137-13"><a href="#cb137-13"></a>}</span>
<span id="cb137-14"><a href="#cb137-14"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.01</span> sec)</span>
<span id="cb137-15"><a href="#cb137-15"></a></span>
<span id="cb137-16"><a href="#cb137-16"></a>mysql<span class="op">&gt;</span> <span class="kw">select</span> <span class="kw">id</span>, factors() <span class="kw">from</span> lj <span class="kw">where</span> match(<span class="st">&#39;hello world&#39;</span>)</span>
<span id="cb137-17"><a href="#cb137-17"></a>    <span class="op">-&gt;</span> <span class="kw">limit</span> <span class="dv">1</span> <span class="kw">option</span> ranker<span class="op">=</span>expr(<span class="st">&#39;1&#39;</span>) \G</span>
<span id="cb137-18"><a href="#cb137-18"></a><span class="op">***************************</span> <span class="fl">1.</span> <span class="kw">row</span> <span class="op">***************************</span></span>
<span id="cb137-19"><a href="#cb137-19"></a>       <span class="kw">id</span>: <span class="dv">5332</span></span>
<span id="cb137-20"><a href="#cb137-20"></a>factors(): {<span class="ot">&quot;bm15&quot;</span><span class="ch">:735</span>, <span class="ot">&quot;bm25a&quot;</span><span class="ch">:0</span><span class="fl">.898329</span>, <span class="ot">&quot;field_mask&quot;</span><span class="ch">:2</span>, <span class="op">..</span>.}</span>
<span id="cb137-21"><a href="#cb137-21"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span>
<span id="cb137-22"><a href="#cb137-22"></a></span>
<span id="cb137-23"><a href="#cb137-23"></a>mysql<span class="op">&gt;</span> <span class="kw">select</span> <span class="kw">id</span>, pp(factors()) <span class="kw">from</span> lj <span class="kw">where</span> match(<span class="st">&#39;hello world&#39;</span>)</span>
<span id="cb137-24"><a href="#cb137-24"></a>    <span class="op">-&gt;</span> <span class="kw">limit</span> <span class="dv">1</span> <span class="kw">option</span> ranker<span class="op">=</span>expr(<span class="st">&#39;1&#39;</span>) \G</span>
<span id="cb137-25"><a href="#cb137-25"></a><span class="op">***************************</span> <span class="fl">1.</span> <span class="kw">row</span> <span class="op">***************************</span></span>
<span id="cb137-26"><a href="#cb137-26"></a>       <span class="kw">id</span>: <span class="dv">5332</span></span>
<span id="cb137-27"><a href="#cb137-27"></a>pp(factors()): {</span>
<span id="cb137-28"><a href="#cb137-28"></a>  <span class="ot">&quot;bm15&quot;</span>: <span class="dv">735</span>,</span>
<span id="cb137-29"><a href="#cb137-29"></a>  <span class="ot">&quot;bm25a&quot;</span>: <span class="fl">0.898329</span>,</span>
<span id="cb137-30"><a href="#cb137-30"></a>  <span class="ot">&quot;field_mask&quot;</span>: <span class="dv">2</span>,</span>
<span id="cb137-31"><a href="#cb137-31"></a>  <span class="ot">&quot;doc_word_count&quot;</span>: <span class="dv">2</span>,</span>
<span id="cb137-32"><a href="#cb137-32"></a>  <span class="ot">&quot;fields&quot;</span>: [</span>
<span id="cb137-33"><a href="#cb137-33"></a>    {</span>
<span id="cb137-34"><a href="#cb137-34"></a>      <span class="ot">&quot;field&quot;</span>: <span class="dv">1</span>,</span>
<span id="cb137-35"><a href="#cb137-35"></a>      <span class="ot">&quot;lcs&quot;</span>: <span class="dv">2</span>,</span>
<span id="cb137-36"><a href="#cb137-36"></a>      <span class="ot">&quot;hit_count&quot;</span>: <span class="dv">2</span>,</span>
<span id="cb137-37"><a href="#cb137-37"></a>      <span class="ot">&quot;word_count&quot;</span>: <span class="dv">2</span>,</span>
<span id="cb137-38"><a href="#cb137-38"></a>      <span class="op">..</span>.</span>
<span id="cb137-39"><a href="#cb137-39"></a><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</span></code></pre></div>
<h3 id="slice-functions">Slice functions</h3>
<div class="sourceCode" id="cb138"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb138-1"><a href="#cb138-1"></a>SLICEAVG(json.<span class="kw">key</span>, min_index, sup_index)</span>
<span id="cb138-2"><a href="#cb138-2"></a>SLICEMAX(json.<span class="kw">key</span>, min_index, sup_index)</span>
<span id="cb138-3"><a href="#cb138-3"></a>SLICEMIN(json.<span class="kw">key</span>, min_index, sup_index)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th>Function call example</th>
<th>Info</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>SLICEAVG(j.prices, 3, 7)</code></td>
<td>Computes average value in a slice</td>
</tr>
<tr class="even">
<td><code>SLICEMAX(j.prices, 3, 7)</code></td>
<td>Computes minimum value in a slice</td>
</tr>
<tr class="odd">
<td><code>SLICEMIN(j.prices, 3, 7)</code></td>
<td>Computes maximum value in a slice</td>
</tr>
</tbody>
</table>
<p>Slice functions (<code>SLICEAVG</code>, <code>SLICEMAX</code>, and <code>SLICEMIN</code>) expect a JSON array as their 1st argument, and two constant integer indexes A and B as their 2nd and 3rd arguments, respectively. Then they compute an aggregate value over the array elements in the respective slice, that is, from index A inclusive to index B exclusive (just like in Python and Golang). For instance, in the example above elements 3, 4, 5, and 6 will be processed, but not element 7. The indexes are, of course, 0-based.</p>
<p>The returned value is <code>float</code>, even when all the input values are actually integer.</p>
<p>Non-arrays and slices with non-numeric items will return a value of <code>0.0</code> (subject to change to <code>NULL</code> eventually).</p>
<h3 id="strpos-function"><code>STRPOS()</code> function</h3>
<div class="sourceCode" id="cb139"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb139-1"><a href="#cb139-1"></a>STRPOS(haystack, const_needle)</span></code></pre></div>
<p><code>STRPOS()</code> returns the index of the first occurence of its second argument (“needle”) in its first argument (“haystack”), or <code>-1</code> if there are no occurrences.</p>
<p>The index is counted in bytes (rather that Unicode codepoints).</p>
<p>At the moment, needle must be a constant string. If needle is an empty string, then 0 will be returned.</p>
<h3 id="uint-function"><code>UINT()</code> function</h3>
<div class="sourceCode" id="cb140"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb140-1"><a href="#cb140-1"></a>UINT(arg)</span></code></pre></div>
<p>This function converts its argument to <code>UINT</code> type, ie. 32-bit unsigned integer.</p>
<h2 id="server-variables-reference">Server variables reference</h2>
<p><code>searchd</code> has a number of server variables that can be changed on the fly using the <code>SET GLOBAL var = value</code> statement. This section provides a reference on all those variables.</p>
<ul>
<li><a href="#attrindex_thresh-variable"><code>attrindex_thresh</code></a></li>
<li><a href="#log_debug_filter-variable"><code>log_debug_filter</code></a></li>
<li><a href="#log_level-variable"><code>log_level</code></a></li>
<li><a href="#net_wait-variable"><code>net_wait</code></a></li>
<li><a href="sphinx2.html#qcache"><code>qcache_max_bytes</code></a></li>
<li><a href="sphinx2.html#qcache"><code>qcache_thresh_msec</code></a></li>
<li><a href="sphinx2.html#qcache"><code>qcache_ttl_sec</code></a></li>
<li><a href="#query_log_format-variable"><code>query_log_format</code></a></li>
<li><a href="#query_log_min_msec-variable"><code>query_log_min_msec</code></a></li>
<li><a href="#siege-mode"><code>siege</code></a></li>
<li><a href="#siege-mode"><code>siege_max_fetched_docs</code></a></li>
<li><a href="#sql_fail_filter-variable"><code>sql_fail_filter</code></a></li>
<li><a href="#sql_log_file-variable"><code>sql_log_file</code></a></li>
</ul>
<h3 id="attrindex_thresh-variable"><code>attrindex_thresh</code> variable</h3>
<div class="sourceCode" id="cb141"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb141-1"><a href="#cb141-1"></a><span class="kw">SET</span> <span class="kw">GLOBAL</span> attrindex_thresh <span class="op">=</span> <span class="dv">256</span></span></code></pre></div>
<p>Minimum segment size required to enable building the <a href="#using-attribute-indexes">attribute indexes</a>, counted in rows. Default is 1024.</p>
<p>Sphinx will only create attribute indexes for “large enough” segments (be those RAM or disk segments). As a corollary, if the entire FT index is small enough, ie. under this threshold, attribute indexes will not be engaged at all.</p>
<p>At the moment, this setting seem useful for testing and debugging only, and normally you must not need to tweak it in production.</p>
<h3 id="log_debug_filter-variable"><code>log_debug_filter</code> variable</h3>
<div class="sourceCode" id="cb142"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb142-1"><a href="#cb142-1"></a><span class="kw">SET</span> <span class="kw">GLOBAL</span> log_debug_filter <span class="op">=</span> <span class="st">&#39;ReadLock&#39;</span></span></code></pre></div>
<p>Supresses debug-level log entries that start with a given prefix. Default is empty string, ie. do not suppress any entries.</p>
<p>This makes <code>searchd</code> less chatty at <code>debug</code> and higher <code>log_level</code> levels.</p>
<p>At the moment, this setting seem useful for testing and debugging only, and normally you must not need to tweak it in production.</p>
<h3 id="log_level-variable"><code>log_level</code> variable</h3>
<div class="sourceCode" id="cb143"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb143-1"><a href="#cb143-1"></a><span class="kw">SET</span> <span class="kw">GLOBAL</span> log_level <span class="op">=</span> {info | <span class="kw">debug</span> | debugv | debugvv}<span class="st">&#39;</span></span></code></pre></div>
<p>Sets the current logging level. Default (and minimum) level is <code>info</code>.</p>
<p>This variable is useful to temporarily enable debug logging in <code>searchd</code>, with this or that verboseness level.</p>
<p>At the moment, this setting seem useful for testing and debugging only, and normally you must not need to tweak it in production.</p>
<h3 id="net_spin_msec-variable"><code>net_spin_msec</code> variable</h3>
<div class="sourceCode" id="cb144"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb144-1"><a href="#cb144-1"></a><span class="kw">SET</span> <span class="kw">GLOBAL</span> net_spin_msec <span class="op">=</span> <span class="dv">30</span></span></code></pre></div>
<p>Sets the poller spinning period in the network thread. Default is 10 msec.</p>
<p>The usual thread CPU slice is basically in 5-10 msec range. (For the really curious, a rather good starting point are the lines mentioning “targeted preemption latency” and “minimal preemption granularity” in <code>kernel/sched/fair.c</code> sources.)</p>
<p>Therefore, if a heavily loaded network thread calls <code>epoll_wait()</code> with even a seemingly tiny 1 msec timeout, that thread could occasionally get preempted and waste precious microseconds. According to an ancient internal benchmark that we can neither easily reproduce nor disavow these days (or in other words: under certain circumstances), that can result in quite a significant difference. More specifically, internal notes report ~3000 rps without spinning (ie. with <code>net_spin_msec = 0</code>) vs ~5000 rps with spinning.</p>
<p>Therefore, by default we choose to call <code>epoll_wait()</code> with zero timeouts for the duration of <code>net_spin_msec</code>, so that our “actual” slice for network thread is closer to those 10 msec, just in case we get a lot of incoming queries.</p>
<h3 id="query_log_format-variable"><code>query_log_format</code> variable</h3>
<div class="sourceCode" id="cb145"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb145-1"><a href="#cb145-1"></a><span class="kw">SET</span> <span class="kw">GLOBAL</span> query_log_format <span class="op">=</span> {plain | sphinxql}</span></code></pre></div>
<p>Changes the search query logging format on the fly. Default is <code>plain</code>, and the other option is <code>sphinxql</code>.</p>
<h3 id="query_log_min_msec-variable"><code>query_log_min_msec</code> variable</h3>
<div class="sourceCode" id="cb146"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb146-1"><a href="#cb146-1"></a><span class="kw">SET</span> <span class="kw">GLOBAL</span> query_log_min_msec <span class="op">=</span> <span class="dv">1000</span></span></code></pre></div>
<p>Changes the minimum elapsed time threshold for the search queries to get logged. Default is 0 msec, ie. log all queries.</p>
<h3 id="sql_fail_filter-variable"><code>sql_fail_filter</code> variable</h3>
<div class="sourceCode" id="cb147"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb147-1"><a href="#cb147-1"></a><span class="kw">SET</span> <span class="kw">GLOBAL</span> sql_fail_filter <span class="op">=</span> <span class="st">&#39;insert&#39;</span></span></code></pre></div>
<p>The “fail filter” is a simple early stage filter imposed on all the incoming SphinxQL queries. Any incoming queries that match a given non-empty substring will immediately fail with an error.</p>
<p>This is useful for emergency maintenance, just as <a href="#siege-mode">siege mode</a>. The two mechanisms are independent of each other, ie. both fail filter and siege mode can be turned on simultaneously.</p>
<p>As of v.3.2, the matching is simple, case-sensitive and bytewise. This is likely to change in the future.</p>
<p>To remove the filter, set the value to an empty string.</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb148-1"><a href="#cb148-1"></a><span class="kw">SET</span> <span class="kw">GLOBAL</span> sql_fail_filter <span class="op">=</span> <span class="st">&#39;&#39;</span></span></code></pre></div>
<h3 id="sql_log_file-variable"><code>sql_log_file</code> variable</h3>
<div class="sourceCode" id="cb149"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb149-1"><a href="#cb149-1"></a><span class="kw">SET</span> <span class="kw">GLOBAL</span> sql_log_file <span class="op">=</span> <span class="st">&#39;/tmp/sphinxlog.sql&#39;</span></span></code></pre></div>
<p>SQL log lets you (temporarily) enable logging all the incoming SphinxQL queries, in (almost) raw form. Compared to <code>query_log</code> directive, this logger:</p>
<ul>
<li>logs <em>all</em> SphinxQL queries, not just searches;</li>
<li>does <em>not</em> log any SphinxAPI calls;</li>
<li>does <em>not</em> have any noticeable performance impact;</li>
<li>is stopped by default.</li>
</ul>
<p>Queries are stored as received. A hardcoded <code>; /* EOQ */</code> separator and then a newline are stored after every query, for parsing convenience. It’s useful to capture and later replay a stream of all client SphinxQL queries.</p>
<p>For performance reasons, SQL logging uses a rather big buffer (to the tune of a few megabytes), so don’t be alarmed when <code>tail</code> does not immediately display something after your start this log.</p>
<p>To stop SQL logging (and close and flush the log file), set the value to an empty string.</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb150-1"><a href="#cb150-1"></a><span class="kw">SET</span> <span class="kw">GLOBAL</span> sql_log_file <span class="op">=</span> <span class="st">&#39;&#39;</span></span></code></pre></div>
<p>We do <em>not</em> recommend keeping SQL logging on for prolonged periods on loaded systems, as it might use a lot of disk space.</p>
<h2 id="changes-in-3.x">Changes in 3.x</h2>
<h3 id="version-3.4.1-09-jul-2021">Version 3.4.1, 09 jul 2021</h3>
<p>New features:</p>
<ul>
<li>completely refactored our text processing pipeline (morphology etc), added <a href="#using-mappings"><code>mappings</code></a> and <a href="#using-morphdict"><code>morphdict</code></a> directives that replace now-deprecated <code>wordforms</code></li>
<li>added 2 new <a href="#phrase_decay10">phrase decay based</a> based ranking signals</li>
<li>added 6 new <a href="#ranking-trigrams">trigram based</a> ranking signals, and indexing time Bloom filters that enable those</li>
<li>added <a href="#using-attribute-indexes">attribute index support for MVA columns</a></li>
<li>added query auto-kill on client disconnect (only in <code>thread_pool</code> mode), see the <a href="#client-disconnects">network internals</a> section</li>
<li>added fixed-size arrays support to <a href="#dot-function"><code>DOT()</code> function</a></li>
<li>added <a href="#show-index-from-syntax"><code>SHOW INDEX FROM</code></a> statement to examine attribute indexes</li>
<li>added support for <code>BETWEEN</code> as in <code>(expr BETWEEN &lt;min&gt; AND &lt;max&gt;)</code> syntax to <a href="#select-syntax"><code>SELECT</code></a></li>
<li>added <a href="#show-status-syntax"><code>SHOW INTERNAL STATUS</code></a> mode to <code>SHOW STATUS</code> statement to observe any experimental, not-yet-official internal counters</li>
<li>added <code>killed_queries</code> and <code>local_XXX</code> counters (such as <code>local_disk_mb</code>, <code>local_docs</code>, etc) to <a href="#show-status-syntax"><code>SHOW STATUS</code></a> statement.</li>
<li>added <code>--profile</code> switch to <code>indexer</code> (initially for SQL data sources only)</li>
</ul>
<p>Deprecations:</p>
<ul>
<li>deprecated <code>wordforms</code> directive, see <a href="#using-mappings"><code>mappings</code></a></li>
<li>deprecated <code>INT</code> and <code>INTEGER</code> types in SphinxQL, use <code>UINT</code> instead</li>
<li>deprecated <code>OPTION idf</code>, <a href="#how-sphinx-computes-idf">IDFs are now unified</a></li>
<li>removed legacy <code>FACTORS()</code> output format, always using JSON now</li>
<li>removed support for embedded stopwords hashes (deprecated since v.3.2), indexes with those will now fail to load</li>
</ul>
<p>Changes and improvements:</p>
<ul>
<li>changed <a href="#how-sphinx-computes-idf">IDFs to use unified unscaled range</a>, so now they are (basically) computed as <code>idf = min(log(N/n), 20.0)</code></li>
<li>added UDF versioning, <code>searchd</code> now also attempts loading <code>myudf.so.VER</code> if <code>myudf.so</code> fails (this helps manage UDF API version mismatches)</li>
<li>added automatic <code>ranker=none</code> when <code>WEIGHT()</code> is not used, to skip ranking and improve performance (note that this does not affect SphinxQL queries at all, but some legacy SphinxAPI queries might need slight changes)</li>
<li>improved double value formatting, mostly in SphinxQL and/or JSON output</li>
<li>improved multi-index searches, all local indexes must be unique now, and a few locking issues were fixed</li>
<li>improved that siege mode now computes per-local-shard limits more precisely</li>
<li>increased <a href="#using-mappings"><code>mappings</code></a> line size limit from ~750 bytes to 32K</li>
<li>optimized queries vs indexes with many static attributes, 1.15x faster on 250-column synthetic test, 3-5% savings in our prod</li>
<li>optimized <code>atc</code> signal (upto 3.2x faster in extreme stops-only test case)</li>
<li>optimized <code>ZONE</code> searches (upto 3x faster on average, 50x+ in extreme cases)</li>
<li>optimized indexing about 3-5% with a few small internal optimizations</li>
<li>disabled query cache by default</li>
<li>disabled arithmetic and other inapplicable operations over array attributes</li>
</ul>
<p>Fixes:</p>
<ul>
<li>fixed overlong (40+ chars) tokens handling in phrases and similar operators</li>
<li>fixed error handling for UDFs that return <code>STRING</code></li>
<li>fixed that RT RAM flush could occasionally drop JSON attrbute index(es)</li>
<li>fixed missing dict fileinfos after <code>ATTACH</code> and a subsequent flush</li>
<li>fixed <code>GEODIST()</code> vs extreme argument value deltas</li>
<li>fixed that searches failed to access docstore after plain-to-RT <code>ATTACH</code></li>
<li>fixed <code>exact_hit</code> signal calculations vs non-ranked fields</li>
<li>fixed pretty-printing in pure distributed case (for <code>FACTORS()</code>, JSON, etc)</li>
<li>fixed that template index name was not properly reported in errors/warnings</li>
<li>fixed <code>SHOW PROFILE</code> within multi-statement requests</li>
<li>fixed attribute indexes on signed columns</li>
<li>fixed that <code>DESCRIBE</code> only printed out one attribute index per column</li>
<li>fixed a race and a crash in <code>SHOW TABLES</code></li>
<li>fixed <code>FACTORS()</code> vs missing <code>MATCH()</code> crash</li>
<li>fixed a rare crash in token len calculation</li>
<li>fixed a number of leaks and races</li>
</ul>
<h3 id="version-3.3.1-06-jul-2020">Version 3.3.1, 06 jul 2020</h3>
<p>New features:</p>
<ul>
<li>added <a href="#udf-call-batching">UDF call batching</a> that enables UDFs to process multiple matched rows at a time</li>
<li>added <a href="#pp-function"><code>PP()</code></a> pretty-printing function for <code>FACTORS()</code> and JSON values</li>
<li>added multi-threaded index loading</li>
<li>added <a href="#kill-syntax"><code>KILL &lt;tid&gt;</code></a> SphinxQL statement</li>
<li>added <a href="#show-index-agent-status-syntax"><code>SHOW INDEX &lt;idx&gt; AGENT STATUS</code></a> SphinxQL statement, and moved per-agent counters there from <code>SHOW STATUS</code></li>
</ul>
<p>Minor new additions:</p>
<ul>
<li>added a number of runtime <a href="#server-variables-reference">server variables</a> to <a href="#show-variables-syntax"><code>SHOW VARIABLES</code></a>, namely
<ul>
<li>added <code>log_debug_filter</code>, <code>net_spin_msec</code>, <code>query_log_min_msec</code>, <code>sql_fail_filter</code>, and <code>sql_log_file</code></li>
<li>moved <code>attrindex_thresh</code>, <code>siege_max_fetched_docs</code>, <code>siege_max_query_msec</code>, <code>qcache_max_bytes</code>, <code>qcache_thresh_msec</code>, and <code>qcache_ttl_sec</code> from <code>SHOW STATUS</code></li>
</ul></li>
<li>added support for <code>SET GLOBAL server_var</code> in <code>sphinxql_state</code> startup script</li>
</ul>
<p>Changes and improvements:</p>
<ul>
<li>removed <code>timestamp</code> columns support, use <code>uint</code> type instead (existing indexes are still supported; <code>timestamp</code> should automatically work as <code>uint</code> in those)</li>
<li>removed <code>OPTION idf</code> and unified IDF calculations, see <a href="#how-sphinx-computes-idf">“How Sphinx computes IDF”</a></li>
<li>changed <code>WEIGHT()</code> from integer to float</li>
<li>changed <code>global_idf</code> behavior; now missing terms get local IDF instead of zero</li>
<li>changed <code>OPTION cutoff</code> to properly account all processed matches</li>
<li>changed directives deprecated in v.3.1 and earlier to hard errors</li>
<li>optimized indexing a little (about 1-2% faster)</li>
<li>optimized <code>DOT()</code> over <code>int8</code> vectors, upto 1.3x faster</li>
<li>optimized query throughput on fast read-only queries upto 350+ Krps (various internal locking and performance changes, aka “highload optimizations”)</li>
<li>improved float value formatting, mostly in SphinxQL output</li>
<li>improved <code>UPDATE</code> handling, updates can now execute in parallel (again)</li>
<li>improved index schema checks (more checks for invalid names, etc)</li>
<li>increased <code>SHOW THREADS</code> query limit from 512 to 2048 bytes</li>
</ul>
<p>Fixes:</p>
<ul>
<li>fixed UDF memory leak when using a <code>FACTORS()</code> argument, and optimized that case a little</li>
<li>fixed <code>sql_log_file</code> race that caused (rare-ish) crashes under high query load</li>
<li>fixed that facets with expressions could occasionally yield either missing or incorrect resulting rows</li>
<li>fixed an overflow in docid hash (triggered on rather huge indexes)</li>
<li>fixed that <code>CALL KEYWORDS</code> did not use normalized term on <code>global_idf</code> lookup</li>
<li>fixed expression types issue when doing mixed int/float const promotion</li>
<li>fixed that RAM segments did not account the docid hash size</li>
<li>fixed that <code>INSERT</code> only checked RAM segments for duplicate docids</li>
<li>fixed an internal error on <code>COUNT(*)</code> vs empty RT</li>
</ul>
<h3 id="version-3.2.1-31-jan-2020">Version 3.2.1, 31 jan 2020</h3>
<p>New features:</p>
<ul>
<li>added <a href="#term-or-operator">term-OR operator</a> for proper query-level synonyms, for example <code>(red || green || blue) pixel</code></li>
<li>added <a href="#using-wordforms">document-only wordforms</a>, for example <code>!indexme =&gt; differently</code></li>
<li>added several <a href="#searching-vector-searches">vector search</a> improvements
<ul>
<li>added int8/int/float fixed-width <a href="#using-array-attributes">array attributes</a> support, for example <code>sql_attr_int8_array = myvec[128]</code></li>
<li>added <a href="#dot-function"><code>DOT()</code></a> support for all those new array types</li>
<li>added int8 vectors support to JSON, and <code>int8[]</code> and <code>float[]</code> <a href="#using-json">JSON syntax extensions</a></li>
<li>added <a href="#fvec-function"><code>FVEC(json.field)</code></a> support to expressions, and the respective <code>SPH_UDF_TYPE_FLOAT_VEC</code> support to UDFs</li>
</ul></li>
<li>added <a href="#bulk-update-syntax"><code>BULK UPDATE</code></a> SphinxQL statement</li>
<li>added attribute index reads for multi-GEODIST-OR queries, upto 15x+ speedup (see section on <a href="#searching-geosearches">geosearches</a> for details)</li>
<li>added <a href="#siege-mode">siege mode</a>, temporary global query limits with <code>SET GLOBAL siege</code></li>
<li>added <code>sum_idf_boost</code>, <code>is_noun_hits</code>, <code>is_latin_hits</code>, <code>is_number_hits</code>, <code>has_digit_hits</code> per-field ranking factors](#ranking-factors)</li>
<li>added <code>is_noun</code>, <code>is_latin</code>, <code>is_number</code>, and <code>has_digit</code> per-term flags; added the respective <code>is_noun_words</code>, <code>is_latin_words</code>, <code>is_number_words</code>, and <code>has_digit_words</code> per-query ranking factors; and added query factors support to UDFs (see <code>sphinxudf.h</code>)</li>
<li>added online query stream filtering with <a href="#sql_fail_filter-variable"><code>SET GLOBAL sql_fail_filter</code></a></li>
<li>added online query stream logging with <a href="#sql_log_file-variable"><code>SET GLOBAL sql_log_file</code></a></li>
<li>added <a href="#slice-functions"><code>SLICEAVG</code>, <code>SLICEMAX</code>, <code>SLICEMIN</code></a> functions, and <a href="#strpos-function"><code>STRPOS(str,conststr)</code></a> function</li>
</ul>
<p>Minor new additions:</p>
<ul>
<li>added hash-comment support to <code>exceptions</code> files</li>
<li>added <code>--dummy &lt;arg&gt;</code> switch to <code>searchd</code> (useful to quickly identify specific instances in the process list)</li>
<li>added IDF info, term flags, and JSON format output to <code>CALL KEYWORDS</code> (for JSON output, call it with <code>CALL KEYWORDS(..., 1 AS json)</code></li>
<li>added <code>IS NULL</code> and <code>IS NOT NULL</code> checks to <code>ALL()</code> and <code>ANY()</code> JSON iterators</li>
<li>added <code>last_good_id</code> to TSV indexing error reporting</li>
<li>added <code>ram_segments</code> counter to <code>SHOW INDEX STATUS</code>, and renamed two counters (<code>ram_chunk</code> to <code>ram_segments_bytes</code>, <code>disk_chunks</code> to <code>disk_segments</code>)</li>
<li>added <code>sql_query_kbatch</code> directive, deprecated <code>sql_query_killlist</code> directive</li>
<li>added <code>&lt;sphinx:kbatch&gt;</code> support to XML source</li>
<li>documented a few semi-hidden options (<code>net_spin_msec</code> for example)</li>
</ul>
<p>Changes and improvements:</p>
<ul>
<li>improved parsing of long constant lists in expressions, requires much less <code>thread_stack</code> now</li>
<li>improved <code>stopwords</code> handling, fixed the hash collisions issue</li>
<li>improved <code>stopwords</code> directive, made it multi-valued</li>
<li>improved <code>global_idf</code> handling, made global IDFs totally independent from per-index DFs</li>
<li>improved <code>EXPLAIN</code>, ensured that it always reports real query plan and stats</li>
<li>improved stats precision output for query times under 1 msec, and generally increased internal query timing precision</li>
<li>improved argument types checking in expressions, and fixed a bunch of missed cases (issues on <code>GEODIST()</code> vs JSON, crash in <code>COALESCE()</code> args check, etc)</li>
<li>improved <code>FACET</code> handling, single-search optimization must now always engage</li>
<li>changed <code>indexer --nohup</code> to rename index files to <code>.new</code> on success</li>
<li>changed <code>query_time</code> metric behaviour for distributed indexes, now it will account wall time</li>
<li>removed “search all indexes” syntax leftovers that were possible via API</li>
<li>removed umask on <code>searchd.log</code></li>
</ul>
<p>Major optimizations:</p>
<ul>
<li>optimized frequent 1-part and 2-part <code>ORDER BY</code> clauses, upto 1.1x speedup</li>
<li>optimized full scan queries, upto 1.2x+ speedup</li>
<li>optimized <code>DOT()</code> for a few cases like <code>int8</code> vectors, upto 2x+ speedup</li>
<li>optimized facets, upto 1.1x speedup</li>
</ul>
<p>Fixes:</p>
<ul>
<li>fixed that <code>ORDER BY RAND()</code> was breaking <code>WEIGHT()</code> (also, enabled it for grouping queries)</li>
<li>fixed hash-comment syntax in wordforms</li>
<li>fixed a couple races in wordforms</li>
<li>fixed a couple deadlocks related to <code>ATTACH</code></li>
<li>fixes a few issues with <code>max_window_hits()</code> and <code>exact_order</code> factors</li>
<li>fixed a rare B-tree crash when inserting duplicate values</li>
<li>fixed a rare TSV indexing issue (well-formed file could fail indexing because of a very rare buffer boundary issue)</li>
<li>fixed occasional crashes on distributed searches on some CPU and glibc combos (double release)</li>
<li>fixed incorrect <code>SHOW META</code> after index-less <code>SELECT</code></li>
<li>fixed <code>ALL()</code> and <code>ANY()</code> vs optimized JSON vectors, and fixed optimized int64 JSON vector accessor</li>
<li>fixed that <code>SHOW THREADS ... OPTION columns=X</code> limit permanently clipped the thread descriptions</li>
<li>fixed <code>/searchd</code> HTTP endpoint error format</li>
<li>fixed per-index query stats vs RT indexes</li>
<li>fixed that query parser could occasionally fail on high ASCII codes</li>
<li>fixed a few issues causing incorrect or unexpected handling of <code>cutoff</code> and other query limits</li>
<li>fixed a few <code>json_packed_keys</code> issues</li>
<li>fixed MVA64 values clipping on <code>INSERT</code></li>
<li>fixed occasional crashes and/or memory corruption on <code>UPDATE</code> and <code>INSERT</code></li>
<li>fixed <code>SNIPPET(field,QUERY())</code> case to some extent (we now filter out query syntax and treat <code>QUERY()</code> as a bag of words in this case)</li>
<li>fixed that index reads on JSON in RT could erroneously disable other <code>WHERE</code> conditions from the query</li>
<li>fixed a number of facets-related issues (occasionally non-working parallel execution, occasional crashes, etc)</li>
<li>fixed a crash on empty index list via SphinxAPI</li>
<li>fixed schema attributes order for XML/TSV/CSV sources</li>
<li>fixed sticky <code>regexp_filter</code> vs <code>ATTACH</code></li>
</ul>
<h3 id="version-3.1.1-17-oct-2018">Version 3.1.1, 17 oct 2018</h3>
<ul>
<li>added <code>indexer --dump-rows-tsv</code> switch, and renamed <code>--dump-rows</code> to <code>--dump-rows-sql</code></li>
<li>added initial <code>COALESCE()</code> function support for JSONs (beware that it will compute everything in floats!)</li>
<li>added support for <code>!=</code>, <code>IN</code>, and <code>NOT IN</code> syntax to expressions</li>
<li>added <code>prefix_tokens</code> and <code>suffix_tokens</code> options to <code>blend_mode</code> directive</li>
<li>added <code>OPTION rank_fields</code>, lets you specify fields to use for ranking with either expression or ML (UDF) rankers</li>
<li>added explicit duplicate documents (docids) suppression back into <code>indexer</code></li>
<li>added <code>batch_size</code> variable to <code>SHOW META</code></li>
<li>added <code>csvpipe_header</code> and <code>tsvpipe_header</code> directives</li>
<li>added <code>sql_xxx</code> counters to <code>SHOW STATUS</code>, generally cleaned up counters</li>
<li>added mixed codes indexing, available via <code>blend_mixed_codes</code> and <code>mixed_codes_fields</code> directives</li>
<li>added <code>OPTION inner_limit_per_index</code> to explicitly control reordering in a nested sharded select</li>
<li>added a hard limit for <code>max_matches</code> (must be under 100M)</li>
<li>optimized Postgres indexing CPU and RAM use quite significantly</li>
<li>optimized <code>FACET</code> queries with expressions and simple by-attribute (no aliases!) facets; multi-sort optmization now works in that case</li>
<li>optimized <code>id</code> lookups (queries like <code>UPDATE ... WHERE id=123</code> should now be much faster)</li>
<li>optimized result set aggregation vs nested sharded selects</li>
<li>optimized <code>PACKEDFACTORS()</code> storage a lot (upto 60x speedup with <code>max_matches=50000</code>)</li>
<li>improved UDF error handling, the error argument is now a message buffer instead of just a 1-char flag</li>
<li>improved the nested sharded select reordering, less confusing now (by default, does <em>not</em> scale the inner <code>LIMIT</code> anymore)</li>
<li>improved <code>searchd --listen</code> switch, multiple <code>--listen</code> instances are now allowed, and <code>--console</code> is <em>not</em> required anymore</li>
<li>improved failed allocation reporting, and added huge allocation tracking</li>
<li>removed legacy <code>@count</code>, <code>@weight</code>, <code>@expr</code>, <code>@geodist</code> syntax support</li>
<li>removed legacy <code>SetWeights()</code>, <code>SetMatchMode()</code>, <code>SetOverride()</code>, <code>SetGeoAnchor()</code> calls, <code>SPH_MATCH_xxx</code> constants, and <code>SPH_SORT_EXPR</code> sorting mode from APIs</li>
<li>removed legacy <code>spelldump</code> utility</li>
<li>removed unused <code>.sha</code> index files</li>
<li>removed extraneous “no extra index definitions” warning</li>
</ul>
<p>Major fixes:</p>
<ul>
<li>fixed 9+ crashes caused by certain complex (and usually rare) conditions and/or settings combinations</li>
<li>fixed 2 crashes caused by broken index data (in vrows and dictionaries)</li>
<li>fixed plain index locking issues on Windows</li>
<li>fixed JSON fields handling vs strings and NULLs (no more corner cases like NULL objects passing a test for json.col=0)</li>
<li>fixed matches loss issue in positional (phrase/order/sentence etc) operators and modifiers under certain conditions</li>
<li>fixed hashing-related hangups under certain (rather rare) occasions</li>
<li>fixed several type inference issues in expressions when using JSON fields</li>
</ul>
<p>Other fixes:</p>
<ul>
<li>fixed that <code>min_best_span_pos</code> was sometimes off</li>
<li>fixed the behavior on missing <code>global_idf</code> file</li>
<li>fixed <code>indextool --check</code> vs string attributes, and vs empty JSONs</li>
<li>fixed blended vs multiforms behavior (works much more predictably now)</li>
<li>fixed query parser vs wildcard-only tokens</li>
<li>fixed that MySQL 8.0+ clients failed to connect</li>
<li>fixed occasional semaphore races on startup</li>
<li>fixed <code>OPTIMIZE</code> vs <code>UPDATE</code> race; <code>UPDATE</code> can now fail with a timeout</li>
<li>fixed <code>indexer --merge --rotate</code> vs kbatches</li>
<li>fixed occasional rotation-related deadlock</li>
<li>fixed a few memory leaks</li>
</ul>
<h3 id="version-3.0.3-30-mar-2018">Version 3.0.3, 30 mar 2018</h3>
<ul>
<li>added <code>BITCOUNT()</code> function and bitwise-NOT operator, eg <code>SELECT BITCOUNT(~3)</code></li>
<li>made <code>searchd</code> config section completely optional</li>
<li>improved <code>min_infix_len</code> behavior, required 2-char minimum is now enforced</li>
<li>improved docs, added a few sections</li>
<li>fixed binary builds performance</li>
<li>fixed several crashes (related to docstore, snippets, threading, <code>json_packed_keys</code> in RT)</li>
<li>fixed docid-less SQL sources, forbidden those for now (docid still required)</li>
<li>fixed int-vs-float precision issues in expressions in certain cases</li>
<li>fixed <code>uptime</code> counter in <code>SHOW STATUS</code></li>
<li>fixed query cache vs <code>PACKEDFACTORS()</code></li>
</ul>
<h3 id="version-3.0.2-25-feb-2018">Version 3.0.2, 25 feb 2018</h3>
<ul>
<li>added <code>full_field_hit</code> ranking factor</li>
<li>added <code>bm15</code> ranking factor name (legacy <code>bm25</code> name misleading, to be removed)</li>
<li>optimized RT inserts significantly (upto 2-6x on certain benchmarks vs 3.0.1)</li>
<li>optimized <code>exact_field_hit</code> ranking factor, impact now negligible (approx 2-4%)</li>
<li>improved <code>indexer</code> output, less visual noise</li>
<li>improved <code>searchd --safetrace</code> option, now skips <code>addr2line</code> to avoid occasional freezes</li>
<li>improved <code>indexer</code> MySQL driver lookup, now also checking for <code>libmariadb.so</code></li>
<li>fixed rare occasional <code>searchd</code> crash caused by attribute indexes</li>
<li>fixed <code>indexer</code> crash on missing SQL drivers, and improved error reporting</li>
<li>fixed <code>searchd</code> crash on multi-index searches with docstore</li>
<li>fixed that expression parser failed on field-shadowing attributes in <code>BM25F()</code> weights map</li>
<li>fixed that <code>ALTER</code> failed on field-shadowing attributes vs <code>index_field_lengths</code> case</li>
<li>fixed junk data writes (seemingly harmless but anyway) in certain cases</li>
<li>fixed rare occasional <code>searchd</code> startup failures (threading related)</li>
</ul>
<h3 id="version-3.0.1-18-dec-2017">Version 3.0.1, 18 dec 2017</h3>
<ul>
<li>first public release of 3.x branch</li>
</ul>
<h2 id="changes-since-v.2.x">Changes since v.2.x</h2>
<blockquote>
<p>WIP: the biggest change to rule them all is yet to come. The all new, fully RT index format is still in progress, and not yet available. Do not worry, ETL via <code>indexer</code> will <em>not</em> be going anywhere. Moreover, despite being fully and truly RT, the new format is actually already <em>faster</em> at batch indexing.</p>
</blockquote>
<p>The biggest changes since Sphinx v.2.x are:</p>
<ul>
<li>added DocStore, document storage
<ul>
<li>original document contents can now be stored into the index</li>
<li>disk based storage, RAM footprint should be minimal</li>
<li>goodbye, <em>having</em> to query Another Database to fetch data</li>
</ul></li>
<li>added new attributes storage format
<ul>
<li>arbitrary updates support (including MVA and JSON)</li>
<li>goodbye, sudden size limits</li>
</ul></li>
<li>added attribute indexes, with JSON support
<ul>
<li>… <code>WHERE gid=123</code> queries can now utilize A-indexes</li>
<li>… <code>WHERE MATCH('hello') AND gid=123</code> queries can now efficiently intersect FT-indexes and A-indexes</li>
<li>goodbye, <em>having</em> to use fake keywords</li>
</ul></li>
<li>added compressed JSON keys</li>
<li>switched to rowids internally, and forced all docids to 64 bits</li>
</ul>
<p>Another two big changes that are already available but still in pre-alpha are:</p>
<ul>
<li>added “zero config” mode (<code>./sphinxdata</code> folder)</li>
<li>added index replication</li>
</ul>
<p>The additional smaller niceties are:</p>
<ul>
<li>added always-on support for xmlpipe, snowball stemmers, and re2 (regexp filters)</li>
<li>added <code>blend_mode=prefix_tokens</code>, and enabled empty <code>blend_mode</code></li>
<li>added <code>kbatch_source</code> directive, to auto-generate k-batches from source docids (in addition to explicit queries)</li>
<li>added <code>SHOW OPTIMIZE STATUS</code> statement</li>
<li>added <code>exact_field_hit</code> ranking factor</li>
<li>added <code>123.45f</code> value syntax in JSON, optimized support for float32 vectors, and <code>FVEC()</code> and <code>DOT()</code> functions</li>
<li>added preindexed data in document storage to speed up <code>SNIPPETS()</code> (via <code>hl_fields</code> directive)</li>
<li>changed field weights, zero and negative weights are now allowed</li>
<li>changed stemming, keywords with digits are now excluded</li>
</ul>
<p>A bunch of legacy things were removed:</p>
<ul>
<li>removed <code>dict</code>, <code>docinfo</code>, <code>infix_fields</code>, <code>prefix_fields</code> directives</li>
<li>removed <code>attr_flush_period</code>, <code>hit_format</code>, <code>hitless_words</code>, <code>inplace_XXX</code>, <code>max_substring_len</code>, <code>mva_updates_pool</code>, <code>phrase_boundary_XXX</code>, <code>sql_joined_field</code>, <code>subtree_XXX</code> directives</li>
<li>removed legacy id32 and id64 modes, mysqlSE plugin, and <code>indexer --keep-attrs</code> switch</li>
</ul>
<p>And last but not least, the new config directives to play with are:</p>
<ul>
<li><code>docstore_type</code>, <code>docstore_block</code>, <code>docstore_comp</code>, <code>docstore_cache_size</code> (per-index) let you generally configure DocStore</li>
<li><code>stored_fields</code>, <code>stored_only_fields</code>, <code>hl_fields</code> (per-index) let you configure what to put in DocStore</li>
<li><code>kbatch</code>, <code>kbatch_source</code> (per-index) update the legacy k-lists-related directives</li>
<li><code>updates_pool</code> (per-index) sets vrow file growth step</li>
<li><code>json_packed_keys</code> (<code>common</code> section) enables the JSON keys compression</li>
<li><code>binlog_flush_mode</code> (<code>searchd</code> section) changes the per-op flushing mode (0=none, 1=fsync, 2=fwrite)</li>
</ul>
<p>Quick update caveats:</p>
<ul>
<li>if you were using <code>sql_query_killlist</code> then you now <em>must</em> explicitly specify <code>kbatch</code> and list all the indexes that the k-batch should be applied to:</li>
</ul>
<div class="sourceCode" id="cb151"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb151-1"><a href="#cb151-1"></a>sql_query_killlist <span class="op">=</span> <span class="kw">SELECT</span> deleted_id <span class="kw">FROM</span> my_deletes_log</span>
<span id="cb151-2"><a href="#cb151-2"></a>kbatch <span class="op">=</span> main</span>
<span id="cb151-3"><a href="#cb151-3"></a></span>
<span id="cb151-4"><a href="#cb151-4"></a># <span class="kw">or</span> perhaps:</span>
<span id="cb151-5"><a href="#cb151-5"></a># kbatch <span class="op">=</span> shard1,shard2,shard3,shard4</span></code></pre></div>
<h2 id="copyrights">Copyrights</h2>
<p>This documentation is copyright (c) 2017-2021, Andrew Aksyonoff. The author hereby grants you the right to redistribute it in a verbatim form, along with the respective copy of Sphinx it came bundled with. All other rights are reserved.</p>
</div>
</body>
</html>
